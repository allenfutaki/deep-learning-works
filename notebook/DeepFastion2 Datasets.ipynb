{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "def to_pil(cv_img):\n",
    "    img = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)\n",
    "    return Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'train'\n",
    "imgsrc = '/media/allen/mass/DeepFashion/{}/image'.format(split)\n",
    "annosrc = '/media/allen/mass/DeepFashion/{}/annos'.format(split)\n",
    "imgpaths = sorted([osp.join(root, f) for root, _, files in os.walk(imgsrc) for f in files if 'jpg' in f or 'png' in f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "annos = []\n",
    "for path in imgpaths:\n",
    "    img = cv2.imread(path)\n",
    "    fname = osp.splitext(osp.basename(path))[0]\n",
    "    f = open(osp.join(annosrc, \"{}.json\".format(fname)))\n",
    "    raw_anno = json.loads(f.readline())\n",
    "    num_objs = len(raw_anno) - 2\n",
    "    anno = defaultdict(dict)\n",
    "    for k in range(1, num_objs+1):\n",
    "        for key in ['landmarks', 'bounding_box', 'category_id', 'occlusion', 'category_name']:\n",
    "            anno[k-1][key] = raw_anno[\"item{}\".format(k)][key]\n",
    "    annos.append(anno)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {0: {'landmarks': [238,\n",
       "               195,\n",
       "               1,\n",
       "               219,\n",
       "               189,\n",
       "               1,\n",
       "               225,\n",
       "               197,\n",
       "               1,\n",
       "               238,\n",
       "               200,\n",
       "               2,\n",
       "               251,\n",
       "               197,\n",
       "               1,\n",
       "               260,\n",
       "               190,\n",
       "               1,\n",
       "               201,\n",
       "               202,\n",
       "               2,\n",
       "               213,\n",
       "               218,\n",
       "               1,\n",
       "               213,\n",
       "               239,\n",
       "               1,\n",
       "               0,\n",
       "               0,\n",
       "               0,\n",
       "               0,\n",
       "               0,\n",
       "               0,\n",
       "               0,\n",
       "               0,\n",
       "               0,\n",
       "               274,\n",
       "               243,\n",
       "               2,\n",
       "               282,\n",
       "               223,\n",
       "               2,\n",
       "               287,\n",
       "               196,\n",
       "               2],\n",
       "              'bounding_box': [199, 190, 287, 269],\n",
       "              'category_id': 5,\n",
       "              'occlusion': 2,\n",
       "              'category_name': 'vest'},\n",
       "             1: {'landmarks': [247,\n",
       "               260,\n",
       "               1,\n",
       "               0,\n",
       "               0,\n",
       "               0,\n",
       "               0,\n",
       "               0,\n",
       "               0,\n",
       "               0,\n",
       "               0,\n",
       "               0,\n",
       "               0,\n",
       "               0,\n",
       "               0,\n",
       "               0,\n",
       "               0,\n",
       "               0,\n",
       "               210,\n",
       "               195,\n",
       "               1,\n",
       "               0,\n",
       "               0,\n",
       "               0,\n",
       "               0,\n",
       "               0,\n",
       "               0,\n",
       "               214,\n",
       "               268,\n",
       "               2,\n",
       "               209,\n",
       "               327,\n",
       "               2,\n",
       "               213,\n",
       "               397,\n",
       "               2,\n",
       "               248,\n",
       "               404,\n",
       "               2,\n",
       "               282,\n",
       "               400,\n",
       "               2,\n",
       "               281,\n",
       "               322,\n",
       "               2,\n",
       "               274,\n",
       "               263,\n",
       "               2,\n",
       "               0,\n",
       "               0,\n",
       "               0,\n",
       "               0,\n",
       "               0,\n",
       "               0,\n",
       "               268,\n",
       "               191,\n",
       "               1],\n",
       "              'bounding_box': [204, 189, 293, 414],\n",
       "              'category_id': 13,\n",
       "              'occlusion': 2,\n",
       "              'category_name': 'sling dress'},\n",
       "             'category_id': {}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import pycocotools.coco as coco\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "import torch.utils.data as data\n",
    "\n",
    "class DeepFashion2KP(data.Dataset):\n",
    "    def __init__(self, coco_handle):\n",
    "        self.coco = coco_handle\n",
    "        cats = self.coco.loadCats(self.coco.getCatIds())\n",
    "        self.num_classes = len(cats)\n",
    "    \n",
    "    flip_idx = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], \n",
    "                [11, 12], [13, 14], [15, 16]]\n",
    "    def __init__(self, opt, split):\n",
    "      super(COCOHP, self).__init__()\n",
    "      self.edges = [[0, 1], [0, 2], [1, 3], [2, 4], \n",
    "                    [4, 6], [3, 5], [5, 6], \n",
    "                    [5, 7], [7, 9], [6, 8], [8, 10], \n",
    "                    [6, 12], [5, 11], [11, 12], \n",
    "                    [12, 14], [14, 16], [11, 13], [13, 15]]\n",
    "      \n",
    "      self.acc_idxs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
    "      self.data_dir = os.path.join(opt.data_dir, 'coco')\n",
    "      self.img_dir = os.path.join(self.data_dir, '{}2017'.format(split))\n",
    "      if split == 'test':\n",
    "        self.annot_path = os.path.join(\n",
    "            self.data_dir, 'annotations', \n",
    "            'image_info_test-dev2017.json').format(split)\n",
    "      else:\n",
    "        self.annot_path = os.path.join(\n",
    "          self.data_dir, 'annotations', \n",
    "          'person_keypoints_{}2017.json').format(split)\n",
    "      self.max_objs = 32\n",
    "      self._data_rng = np.random.RandomState(123)\n",
    "      self._eig_val = np.array([0.2141788, 0.01817699, 0.00341571],\n",
    "                               dtype=np.float32)\n",
    "      self._eig_vec = np.array([\n",
    "          [-0.58752847, -0.69563484, 0.41340352],\n",
    "          [-0.5832747, 0.00994535, -0.81221408],\n",
    "          [-0.56089297, 0.71832671, 0.41158938]\n",
    "      ], dtype=np.float32)\n",
    "      self.split = split\n",
    "      self.opt = opt\n",
    "  \n",
    "      print('==> initializing coco 2017 {} data.'.format(split))\n",
    "      self.coco = coco.COCO(self.annot_path)\n",
    "      image_ids = self.coco.getImgIds()\n",
    "  \n",
    "      if split == 'train':\n",
    "        self.images = []\n",
    "        for img_id in image_ids:\n",
    "          idxs = self.coco.getAnnIds(imgIds=[img_id])\n",
    "          if len(idxs) > 0:\n",
    "            self.images.append(img_id)\n",
    "      else:\n",
    "        self.images = image_ids\n",
    "      self.num_samples = len(self.images)\n",
    "      print('Loaded {} {} samples'.format(split, self.num_samples))\n",
    "  \n",
    "    def _to_float(self, x):\n",
    "      return float(\"{:.2f}\".format(x))\n",
    "  \n",
    "    def convert_eval_format(self, all_bboxes):\n",
    "      # import pdb; pdb.set_trace()\n",
    "      detections = []\n",
    "      for image_id in all_bboxes:\n",
    "        for cls_ind in all_bboxes[image_id]:\n",
    "          category_id = 1\n",
    "          for dets in all_bboxes[image_id][cls_ind]:\n",
    "            bbox = dets[:4]\n",
    "            bbox[2] -= bbox[0]\n",
    "            bbox[3] -= bbox[1]\n",
    "            score = dets[4]\n",
    "            bbox_out  = list(map(self._to_float, bbox))\n",
    "            keypoints = np.concatenate([\n",
    "              np.array(dets[5:39], dtype=np.float32).reshape(-1, 2), \n",
    "              np.ones((17, 1), dtype=np.float32)], axis=1).reshape(51).tolist()\n",
    "            keypoints  = list(map(self._to_float, keypoints))\n",
    "  \n",
    "            detection = {\n",
    "                \"image_id\": int(image_id),\n",
    "                \"category_id\": int(category_id),\n",
    "                \"bbox\": bbox_out,\n",
    "                \"score\": float(\"{:.2f}\".format(score)),\n",
    "                \"keypoints\": keypoints\n",
    "            }\n",
    "            detections.append(detection)\n",
    "      return detections\n",
    "  \n",
    "    def __len__(self):\n",
    "      return self.num_samples\n",
    "  \n",
    "    def save_results(self, results, save_dir):\n",
    "      json.dump(self.convert_eval_format(results), \n",
    "                open('{}/results.json'.format(save_dir), 'w'))\n",
    "  \n",
    "  \n",
    "    def run_eval(self, results, save_dir):\n",
    "      # result_json = os.path.join(opt.save_dir, \"results.json\")\n",
    "      # detections  = convert_eval_format(all_boxes)\n",
    "      # json.dump(detections, open(result_json, \"w\"))\n",
    "      self.save_results(results, save_dir)\n",
    "      coco_dets = self.coco.loadRes('{}/results.json'.format(save_dir))\n",
    "      coco_eval = COCOeval(self.coco, coco_dets, \"keypoints\")\n",
    "      coco_eval.evaluate()\n",
    "      coco_eval.accumulate()\n",
    "      coco_eval.summarize()\n",
    "      coco_eval = COCOeval(self.coco, coco_dets, \"bbox\")\n",
    "      coco_eval.evaluate()\n",
    "      coco_eval.accumulate()\n",
    "      coco_eval.summarize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
