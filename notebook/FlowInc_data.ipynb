{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import re\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image, ImageOps\n",
    "def to_pil(cv_img):\n",
    "    img = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)\n",
    "    return Image.fromarray(img)\n",
    "src = \"/media/acer/5f45949f-0fc7-4475-965b-e61989afcc10/FlowInc_data\"\n",
    "branch = \"Yilan_03\"\n",
    "cam = int(branch.split(\"_\")[-1])\n",
    "img_list = [osp.join(root, f) for root, _, files in os.walk(osp.join(src, branch)) for f in files if 'jpg' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = osp.join(src, f\"images_{cam:02}_clean\")\n",
    "if not osp.exists(dst):\n",
    "    os.mkdir(osp.join(src, f\"images_{cam:02}_clean\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = osp.join(src, f\"sample_images_{cam:02}\")\n",
    "if not osp.exists(dst):\n",
    "    os.mkdir(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(osp.join(src, f\"{branch}_clean.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['fname'] = pd.Series(index=df.index, dtype=str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "sample = np.random.randint(0, len(df), 264)\n",
    "df = df.loc[sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rotate_angle(dx, dy):\n",
    "    if dy == 0:\n",
    "        return 0\n",
    "    angle = np.arctan(np.abs(dx/dy)) / math.pi * 180\n",
    "    if dx > 0 and dy < 0:\n",
    "        return angle\n",
    "    elif dx < 0 and dy < 0:\n",
    "        return -1 * angle\n",
    "    elif dx > 0 and dy > 0:\n",
    "        return 180 - angle\n",
    "    else:\n",
    "        return -1 * (180 - angle)\n",
    "\n",
    "def _get_normalized_img(crop, pos):\n",
    "    pil_img = to_pil(crop)\n",
    "    crop_w, crop_h = pil_img.size\n",
    "    x1, y1, x2, y2 = pos\n",
    "    x, y = (x1+x2) / 2, (y1+y2) / 2\n",
    "    diag_len = np.sqrt(crop_w**2 + crop_h**2)\n",
    "    delta_h = diag_len - crop_h\n",
    "    padding = (0, int(delta_h//2), 0, int(delta_h//2))\n",
    "    pil_img = ImageOps.expand(pil_img, padding)\n",
    "    angle = get_rotate_angle(x-cx, y-cy)\n",
    "    pil_img = pil_img.rotate(angle)\n",
    "    return angle, pil_img\n",
    "def get_normalized_img(crop, pos):\n",
    "    pil_img = to_pil(crop)\n",
    "    crop_w, crop_h = pil_img.size\n",
    "    x1, y1, x2, y2 = pos\n",
    "    x, y = (x1+x2) / 2, (y1+y2) / 2\n",
    "    angle = get_rotate_angle(x-cx, y-cy)\n",
    "    pil_img = pil_img.rotate(angle)\n",
    "    return angle, pil_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def rotate_A(level, shape):\n",
    "    # copy from https://pillow.readthedocs.io/en/stable/_modules/PIL/Image.html#Image.rotate\n",
    "    angle = level % 360.0\n",
    "\n",
    "    w, h = shape\n",
    "\n",
    "    post_trans = (0, 0)\n",
    "    rotn_center = (w / 2.0, h / 2.0)\n",
    "    angle = math.radians(angle)\n",
    "    matrix = [\n",
    "        round(math.cos(angle), 15),\n",
    "        round(math.sin(angle), 15),\n",
    "        0.0,\n",
    "        round(-math.sin(angle), 15),\n",
    "        round(math.cos(angle), 15),\n",
    "        0.0,\n",
    "    ]\n",
    "\n",
    "    def transform(x, y, matrix):\n",
    "        (a, b, c, d, e, f) = matrix\n",
    "        return a * x + b * y + c, d * x + e * y + f\n",
    "\n",
    "    matrix[2], matrix[5] = transform(\n",
    "        -rotn_center[0] - post_trans[0], -rotn_center[1] - post_trans[1], matrix\n",
    "    )\n",
    "    matrix[2] += rotn_center[0]\n",
    "    matrix[5] += rotn_center[1]\n",
    "\n",
    "    return np.array(matrix).reshape(2, 3).astype(np.float)\n",
    "def apply_A(pt, A):\n",
    "    new_pt = np.array([pt[0], pt[1], 1.], dtype=np.float32).T\n",
    "    new_pt = np.dot(A, new_pt)\n",
    "    return new_pt[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 1300/1300 [02:53<00:00,  7.51it/s]\n"
    }
   ],
   "source": [
    "pattern = re.compile(r'(\\d{4})(\\d{2})(\\d{2})(\\d{2})(\\d{2})(\\d{2})')\n",
    "# f = open(osp.join(src, f'{branch}.txt'), 'w')\n",
    "normalized_imgs = []\n",
    "temp_timestamp = 0\n",
    "ready = False\n",
    "radius = 320 #170,240\n",
    "for path in tqdm(sorted(img_list)):\n",
    "    img = cv2.imread(path)\n",
    "    h, w = img.shape[:2]\n",
    "    cx, cy = w * 0.5, h * 0.5\n",
    "    fname = osp.basename(path)\n",
    "    labels = df[df['file_name']==fname]\n",
    "    fname = osp.splitext(fname)[0]\n",
    "    if len(labels) == 0:\n",
    "        # print(fname)\n",
    "        continue\n",
    "\n",
    "    for i in labels.index:\n",
    "        x1 = int(labels.loc[i]['x1_label'])\n",
    "        y1 = int(labels.loc[i]['y1_label'])\n",
    "        x2 = int(labels.loc[i]['x2_label'])\n",
    "        y2 = int(labels.loc[i]['y2_label'])\n",
    "        sx = int(labels.loc[i]['stand_x'])\n",
    "        sy = int(labels.loc[i]['stand_y'])\n",
    "        occlude = int(labels.loc[i]['occlude_label'])\n",
    "        # f.writelines(f\"{fname} -1 {x1} {y1} {x2} {y2} {sx} {sy}\\n\")\n",
    "        pid = labels.loc[i]['tracking_id_label']\n",
    "        if pid == '-1':\n",
    "            continue\n",
    "        pid = pid.split(\"_\")[-1]\n",
    "        if x2-x1 != 0 and y2-y1 != 0:\n",
    "            angle, pil_img = get_normalized_img(img, (x1, y1, x2, y2))\n",
    "            A = rotate_A(angle, (img.shape[1], img.shape[0]))\n",
    "            rx1, ry1 = apply_A([x1, y1], A)\n",
    "            rx2, ry2 = apply_A([x2, y2], A)\n",
    "            rx3, ry3 = apply_A([x2, y1], A)\n",
    "            rx4, ry4 = apply_A([x1, y2], A)\n",
    "            np_img = np.array(pil_img)\n",
    "            tr_x = int(min(rx1, rx2, rx3, rx4))\n",
    "            tr_y = int(min(ry1, ry2, ry3, ry4))\n",
    "            bl_x = int(max(rx1, rx2, rx3, rx4))\n",
    "            bl_y = int(max(ry1, ry2, ry3, ry4))\n",
    "            crop_w = bl_x - tr_x\n",
    "            crop_h = bl_y - tr_y\n",
    "            if crop_w < 80 and crop_h < 80:\n",
    "                continue\n",
    "            if crop_h / crop_w < 1.3:\n",
    "                bcx = (tr_x + bl_y) / 2\n",
    "                bcy = (tr_y + bl_y) / 2\n",
    "                if bcx > cx-radius and bcx < cx+radius and bcy > cy-radius and bcy < cy+radius:\n",
    "                    pass\n",
    "                else:\n",
    "                    if occlude != 0:\n",
    "                        continue\n",
    "                    tr_x += int(crop_w/4.5)\n",
    "                    bl_x -= int(crop_w/4.5)\n",
    "            \n",
    "            crop = Image.fromarray(np_img[tr_y:bl_y, tr_x:bl_x,:])\n",
    "            img_name = labels.loc[i]['fname']\n",
    "            crop.save(osp.join(dst, img_name))\n",
    "        else:\n",
    "            print(fname)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "pattern = re.compile(r'(\\d{4})(\\d{2})(\\d{2})(\\d{2})(\\d{2})(\\d{2})')\n",
    "# f = open(osp.join(src, f'{branch}.txt'), 'w')\n",
    "normalized_imgs = []\n",
    "temp_timestamp = 0\n",
    "ready = False\n",
    "for path in tqdm(sorted(img_list)):\n",
    "    img = cv2.imread(path)\n",
    "    h, w = img.shape[:2]\n",
    "    cx, cy = w * 0.5, h * 0.5\n",
    "    fname = osp.basename(path)\n",
    "    labels = df[df['file_name']==fname]\n",
    "    fname = osp.splitext(fname)[0]\n",
    "    if len(labels) == 0:\n",
    "        # print(fname)\n",
    "        continue\n",
    "\n",
    "    for i in labels.index:\n",
    "        x1 = int(labels.loc[i]['x1_label'])\n",
    "        y1 = int(labels.loc[i]['y1_label'])\n",
    "        x2 = int(labels.loc[i]['x2_label'])\n",
    "        y2 = int(labels.loc[i]['y2_label'])\n",
    "        sx = int(labels.loc[i]['stand_x'])\n",
    "        sy = int(labels.loc[i]['stand_y'])\n",
    "        # f.writelines(f\"{fname} -1 {x1} {y1} {x2} {y2} {sx} {sy}\\n\")\n",
    "        uniform = int(labels.loc[i]['uniform_label'])\n",
    "        occlude = int(labels.loc[i]['occlude_label'])\n",
    "        pid = labels.loc[i]['tracking_id_label'].split(\"_\")[-1]\n",
    "        color = (0,255,0)\n",
    "        if uniform:\n",
    "            color = (0,0,255)\n",
    "        if occlude == 2:\n",
    "            color = (0,0,0)\n",
    "        if x2-x1 != 0 and y2-y1 != 0:\n",
    "            ready = True\n",
    "            # cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "            _, normalized_img = get_normalized_img(img[y1:y2, x1:x2, :], (x1, y1, x2, y2))\n",
    "            crop_w, crop_h = normalized_img.size\n",
    "            if crop_w < 50 and crop_h < 100:\n",
    "                df[\"tracking_id_label\"].loc[i] = \"-1\"\n",
    "                continue\n",
    "            if occlude == 2:\n",
    "                df[\"tracking_id_label\"].loc[i] = \"-1\"\n",
    "                continue\n",
    "            date_str = fname.split(\"_\")[-1]\n",
    "            year, month, day, hour, minute, second = map(int, pattern.search(date_str).groups())\n",
    "            date = datetime(year, month, day, hour, minute, second)\n",
    "            timestamp = int(datetime.timestamp(date))\n",
    "            img_name = f\"{pid}_c{cam}s1_{uniform}_{timestamp}_{i:04}.jpg\"\n",
    "            df[\"tracking_id_label\"].loc[i] = f\"01_{pid}\"\n",
    "            df['fname'].loc[i] = img_name\n",
    "            # break\n",
    "            # normalized_img.save(osp.join(dst, img_name))\n",
    "        else:\n",
    "            print(fname)\n",
    "    if ready:\n",
    "        break\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_img = np.array(pil_img)\n",
    "tr_x = int(min(rx1, rx2, rx3, rx4))\n",
    "tr_y = int(min(ry1, ry2, ry3, ry4))\n",
    "bl_x = int(max(rx1, rx2, rx3, rx4))\n",
    "bl_y = int(max(ry1, ry2, ry3, ry4))\n",
    "cv2.rectangle(np_img, (tr_x, tr_y), (bl_x, bl_y), color, 2)\n",
    "Image.fromarray(np_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_img_list = [osp.join(root, f) for root, _, files in os.walk(dst) for f in files if 'jpg' in f]\n",
    "clean_dst = osp.join(src, f\"images_{cam:02}_1th_clean\")\n",
    "if not osp.exists(clean_dst):\n",
    "    os.mkdir(osp.join(src, f\"images_{cam:02}_1th_clean\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(crop_img_list) == len(df['fname'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "temp_timestamp = -1\n",
    "temp_pid = -1\n",
    "num = 1\n",
    "for path in tqdm(sorted(crop_img_list)):\n",
    "    fname = osp.basename(path)\n",
    "    fname = osp.splitext(fname)[0]\n",
    "    try:\n",
    "        pid, _, uniform, timestamp, index = fname.split(\"_\")\n",
    "        index = int(index)\n",
    "    except:\n",
    "        print(fname)\n",
    "        break\n",
    "    pid = int(pid)\n",
    "    uniform = int(uniform)\n",
    "    timestamp = int(timestamp)\n",
    "    if pid != temp_pid and temp_pid > 0:\n",
    "        num += 1\n",
    "    else:\n",
    "        if np.abs(timestamp - temp_timestamp) > 50 and temp_timestamp > 0:\n",
    "            num += 1\n",
    "    temp_pid = pid\n",
    "    temp_timestamp = timestamp\n",
    "    img_name = f\"{num:04}_c{cam}s1_{uniform}_{timestamp}_{index}.jpg\"\n",
    "    df[\"tracking_id_label\"].loc[index] = f\"01_{num:04}\"\n",
    "    df['fname'].loc[index] = img_name\n",
    "    shutil.copy(path, osp.join(clean_dst, img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pids = {\n",
    "    1:[18,6,81],\n",
    "    2:[31,78],\n",
    "    4:[15,36,69],\n",
    "    5:[14,26,59,70],\n",
    "    7:[13,27,39,65,75],\n",
    "    8:[11,42,72],\n",
    "    9:[19,32,62,73],\n",
    "    10:[12],\n",
    "    16:[23,24,66,74],\n",
    "    }\n",
    "pid_map = {}\n",
    "for pid in pids:\n",
    "    for copy in pids[pid]:\n",
    "        pid_map[copy] = pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pids = {\n",
    "    1:[4,12,21,22,37],\n",
    "    2:[3,13],\n",
    "    5:[6,17],\n",
    "    8:[29],\n",
    "    38:[74]\n",
    "    }\n",
    "pid_map = {}\n",
    "for pid in pids:\n",
    "    for copy in pids[pid]:\n",
    "        pid_map[copy] = pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pids = {\n",
    "    1:[2,3,4],\n",
    "    6:[30],\n",
    "    9:[15,17,35],\n",
    "    10:[28],\n",
    "    12:[25],\n",
    "    14:[27],\n",
    "    }\n",
    "pid_map = {}\n",
    "for pid in pids:\n",
    "    for copy in pids[pid]:\n",
    "        pid_map[copy] = pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_img_list2 = [osp.join(root, f) for root, _, files in os.walk(clean_dst) for f in files if 'jpg' in f]\n",
    "clean_dst2 = osp.join(src, f\"images_{cam:02}_2th_clean\")\n",
    "if not osp.exists(clean_dst2):\n",
    "    os.mkdir(osp.join(src, f\"images_{cam:02}_2th_clean\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pid_map = {10:3, 18:3, 8:4, 25:5, 11:5, 9:6, 27:13, 22:13, 29:15, 23:15, 24:16, 21:17, 26:7, 20:7}\n",
    "for path in tqdm(sorted(crop_img_list2)):\n",
    "    fname = osp.basename(path)\n",
    "    fname = osp.splitext(fname)[0]\n",
    "    pid, _, uniform, timestamp, index = fname.split(\"_\")\n",
    "    index = int(index)\n",
    "    pid = int(pid)\n",
    "    uniform = int(uniform)\n",
    "    timestamp = int(timestamp)\n",
    "    if pid in pid_map:\n",
    "        pid = pid_map[pid]\n",
    "    img_name = f\"{pid:04}_c{cam}s1_{uniform}_{timestamp}{index}.jpg\"\n",
    "    df[\"tracking_id_label\"].loc[index] = f\"01_{pid:04}\"\n",
    "    df['fname'].loc[index] = img_name\n",
    "    shutil.copy(path, osp.join(clean_dst2, img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(osp.join(src, f\"{branch}_clean.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tracking_id_label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osp.join(dst, f\"{fname}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "pattern = re.compile(r'(\\d{4})(\\d{2})(\\d{2})(\\d{2})(\\d{2})(\\d{2})')\n",
    "for path in tqdm(sorted(img_list)):\n",
    "    img = cv2.imread(path)\n",
    "    h, w = img.shape[:2]\n",
    "    cx, cy = w * 0.5, h * 0.5\n",
    "    fname = osp.basename(path)\n",
    "    labels = df[df['file_name']==fname]\n",
    "    fname = osp.splitext(fname)[0]\n",
    "    if len(labels) == 0:\n",
    "        continue\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        x1 = int(labels.iloc[i]['x1_label'])\n",
    "        y1 = int(labels.iloc[i]['y1_label'])\n",
    "        x2 = int(labels.iloc[i]['x2_label'])\n",
    "        y2 = int(labels.iloc[i]['y2_label'])\n",
    "        uniform = int(labels.iloc[i]['uniform_label'])\n",
    "        occlude = int(labels.iloc[i]['occlude_label'])\n",
    "        pid = int(labels.iloc[i]['tracking_id_label'].split(\"_\")[-1])\n",
    "        spt_x = int(labels.iloc[i]['stand_x']) \n",
    "        spt_y = int(labels.iloc[i]['stand_y'])\n",
    "        color = (0,255,0)\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.circle(img, (spt_x, spt_y), 7, (255,255,255), -1)\n",
    "        cv2.circle(img, (spt_x, spt_y), 5, (0,0,255), -1)\n",
    "        cv2.putText(img, f\"p[{pid}]\", (x2+5, y1+5), cv2.FONT_HERSHEY_DUPLEX, 0.7, (255,255,255), 2)\n",
    "        cv2.putText(img, f\"u[{uniform}]\", (x2+5, y1+30), cv2.FONT_HERSHEY_DUPLEX, 0.7, (255,255,255), 2)\n",
    "        cv2.putText(img, f\"o[{occlude}]\", (x2+5, y1+55), cv2.FONT_HERSHEY_DUPLEX, 0.7, (255,255,255), 2)\n",
    "        cv2.putText(img, f\"p[{pid}]\", (x2+5, y1+5), cv2.FONT_HERSHEY_DUPLEX, 0.7, (0,0,0), 1)\n",
    "        cv2.putText(img, f\"u[{uniform}]\", (x2+5, y1+30), cv2.FONT_HERSHEY_DUPLEX, 0.7, (0,0,0), 1)\n",
    "        cv2.putText(img, f\"o[{occlude}]\", (x2+5, y1+55), cv2.FONT_HERSHEY_DUPLEX, 0.7, (0,0,0), 1)\n",
    "    cv2.imwrite(osp.join(dst, f\"{fname}.jpg\"), img)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycocotools.coco as coco\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "data_path = \"/media/acer/5f45949f-0fc7-4475-965b-e61989afcc10/FlowInc_data\"\n",
    "coco_branch = 'flow_03'\n",
    "\n",
    "coco_src = osp.join(data_path, coco_branch)\n",
    "train_dst = osp.join(coco_src, 'train2017')\n",
    "val_dst = osp.join(coco_src, 'val2017')\n",
    "if not osp.exists(coco_src):\n",
    "    os.mkdir(coco_src)\n",
    "if not osp.exists(train_dst):\n",
    "    os.mkdir(train_dst)\n",
    "if not osp.exists(val_dst):\n",
    "    os.mkdir(val_dst)\n",
    "label_src = osp.join(src, f\"{branch}.csv\")\n",
    "df = pd.read_csv(label_src)\n",
    "\n",
    "img_paths = [osp.join(root, f) for root, _, files in os.walk(osp.join(src, branch)) for f in files if '.jpg' in f or '.png' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reid_train_dst = osp.join(coco_src, f\"bounding_box_train\")\n",
    "if not osp.exists(reid_train_dst):\n",
    "    os.mkdir(reid_train_dst)\n",
    "reid_test_dst = osp.join(coco_src, f\"bounding_box_test\")\n",
    "if not osp.exists(reid_test_dst):\n",
    "    os.mkdir(reid_test_dst)\n",
    "reid_query_dst = osp.join(coco_src, f\"query\")\n",
    "if not osp.exists(reid_query_dst):\n",
    "    os.mkdir(reid_query_dst)\n",
    "\n",
    "cam = 3\n",
    "reid_src = osp.join(data_path, f\"images_{cam:02}_2th_clean\")\n",
    "reid_img_list = [osp.join(root, f) for root, _, files in os.walk(reid_src) for f in files if 'jpg' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pids = defaultdict(int)\n",
    "for path in reid_img_list:\n",
    "    img = Image.open(path)\n",
    "    w, h = img.size\n",
    "    if w < 80 or h < 80:\n",
    "        continue\n",
    "    fname = osp.basename(path)\n",
    "    pid = int(fname[:4])\n",
    "    pids[pid] += 1\n",
    "for path in reid_img_list:\n",
    "    img = Image.open(path)\n",
    "    w, h = img.size\n",
    "    if w < 80 or h < 80:\n",
    "        continue\n",
    "    fname = osp.basename(path)\n",
    "    pid = int(fname[:4])\n",
    "    if pid in pids and pids[pid] < 4:\n",
    "        continue\n",
    "    fname = f\"{pid:04}\" + fname[4:]\n",
    "    shutil.copy(path, osp.join(reid_train_dst, fname))\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    \"info\": {},\n",
    "    \"licenses\": [],\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": []\n",
    "}\n",
    "dataset['categories'].append({\n",
    "    'id': 1,\n",
    "    'name': \"person\",\n",
    "    'supercategory': \"people\",\n",
    "    'keypoints': [0],\n",
    "    'skeleton': []\n",
    "})\n",
    "\n",
    "# anno_paths = [osp.join(root, f) for root, _, files in os.walk(src) for f in files if '.txt' in f]\n",
    "\n",
    "sub_index = 0\n",
    "idx = 0\n",
    "for path in tqdm(img_paths):\n",
    "    img = cv2.imread(path)\n",
    "    h, w = img.shape[:2]\n",
    "    dst = osp.basename(path)\n",
    "    anns = df[df['file_name']==dst]\n",
    "    dst = osp.join(train_dst, dst)\n",
    "    if len(anns) > 0:\n",
    "        shutil.copy(path, dst)\n",
    "    else:\n",
    "        continue\n",
    "    idx += 1\n",
    "    dataset['images'].append({\n",
    "        'coco_url': '',\n",
    "        'date_captured': '',\n",
    "        'file_name': osp.basename(dst),\n",
    "        'flickr_url': '',\n",
    "        'id': idx,\n",
    "        'license': 0,\n",
    "        'width': w,\n",
    "        'height': h\n",
    "    })\n",
    "\n",
    "    for i in range(len(anns)):\n",
    "        sub_index += 1\n",
    "        x1 = int(anns.iloc[i]['x1_label'])\n",
    "        y1 = int(anns.iloc[i]['y1_label'])\n",
    "        x2 = int(anns.iloc[i]['x2_label'])\n",
    "        y2 = int(anns.iloc[i]['y2_label'])\n",
    "        sx = int(anns.iloc[i]['stand_x'])\n",
    "        sy = int(anns.iloc[i]['stand_y'])\n",
    "        uniform = int(anns.iloc[i]['uniform_label'])\n",
    "        occlude = int(anns.iloc[i]['occlude_label'])\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "        identity = int(anns.iloc[i]['tracking_id_label'].split(\"_\")[-1])\n",
    "        # if width < 50 and height < 100:\n",
    "        #     identity = -1\n",
    "        # if occlude == 2:\n",
    "        #     identity = -1\n",
    "\n",
    "        dataset['annotations'].append({\n",
    "            'area': int(width*height),\n",
    "            'bbox': [int(x1),int(y1),int(width),int(height)],\n",
    "            'category_id': 1,\n",
    "            'pid': identity,\n",
    "            'id': sub_index,\n",
    "            'image_id': idx,\n",
    "            'iscrowd': 0,\n",
    "            'num_keypoints':1,\n",
    "            'keypoints': [[sx, sy]],\n",
    "            'segmentation': [],\n",
    "        })\n",
    "    # shutil.copy(path, osp.join(val_dst, osp.basename(path)))\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dst = osp.join(coco_src, 'original')\n",
    "if not osp.exists(json_dst):\n",
    "    os.mkdir(json_dst)\n",
    "with open(osp.join(json_dst, 'instances_train2017.json'), 'w') as f:\n",
    "    json.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dst"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36864bitpy368venv96aa759879e8443787e614586faca138",
   "display_name": "Python 3.6.8 64-bit ('py368': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}