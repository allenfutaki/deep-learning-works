{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from src.factory.config_factory import cfg, show_configs, build_output\n",
    "from src.factory.data_factory import DataFactory\n",
    "from src.factory.data_format_factory import DataFormatFactory\n",
    "from src.factory.transform_factory import TransformFactory\n",
    "from src.factory.loader_factory import LoaderFactory\n",
    "from src.base_data import BaseData\n",
    "from tools.logger import setup_logger\n",
    "from tqdm import tqdm\n",
    "logger = setup_logger(\"./external/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.merge_from_file(\"./configs/shufflenetv2_fsaf.yml\")\n",
    "# build_output(cfg, \"./configs/person.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.NUM_WORKERS = 1\n",
    "cfg.DB.PATH = \"/media/acer/5f45949f-0fc7-4475-965b-e61989afcc10/Downloads\"\n",
    "cfg.DB.DATA = \"crowdhuman\"\n",
    "cfg.DB.DATA_FORMAT = \"coco\"\n",
    "cfg.DB.TARGET_FORMAT = \"centernet\"\n",
    "cfg.DB.LOADER = \"coco\"\n",
    "cfg.DB.USE_TRAIN = True\n",
    "cfg.DB.USE_TEST = True\n",
    "cfg.INPUT.SIZE = (512, 512)\n",
    "cfg.INPUT.TEST_BS = 4\n",
    "# cfg.MODEL.STRIDES = [4]\n",
    "cfg.DB.TRAIN_TRANSFORM = \"ResizeKeepAspectRatio Tensorize\"\n",
    "cfg.DB.TEST_TRANSFORM = \"ResizeKeepAspectRatio Tensorize\"\n",
    "cfg.COCO.TARGET = \"person\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "loading annotations into memory...\nDone (t=0.47s)\ncreating index...\nindex created!\n2020-06-03 14:54:09,108 4661 coco.py INFO: => CROWDHUMAN VAL is loaded\n2020-06-03 14:54:09,108 4661 coco.py INFO:   Dataset statistics:\n2020-06-03 14:54:09,109 4661 coco.py INFO:   -----------------------------\n2020-06-03 14:54:09,110 4661 coco.py INFO:   subset   | #id     | # images\n2020-06-03 14:54:09,110 4661 coco.py INFO:   -----------------------------\n2020-06-03 14:54:09,111 4661 coco.py INFO:   val    |       0 |     4368\n2020-06-03 14:54:09,112 4661 coco.py INFO:   -----------------------------\n[ResizeKeepAspectRatio, Tensorize]\n"
    }
   ],
   "source": [
    "loader = LoaderFactory.produce(cfg)\n",
    "branch = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycocotools.coco as coco\n",
    "import json\n",
    "import os\n",
    "import os.path as osp\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import shutil\n",
    "import cv2\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from tools.centernet_utils import centernet_det_decode, centernet_det_post_process\n",
    "from tools.scopehead_utils import scopehead_det_decode\n",
    "from tools.oracle_utils import gen_oracle_map\n",
    "from tools.image import get_affine_transform\n",
    "from copy import deepcopy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "for i, batch in enumerate(loader[branch]):\n",
    "    batch['bboxes']\n",
    "    bboxes = np.vstack(batch['bboxes'])\n",
    "    bboxes[:, [0,2]] *= 128\n",
    "    bboxes[:, [1,3]] *= 128\n",
    "    break\n",
    "    fname = loader[branch].dataset.coco[0].loadImgs(batch['img_id'][0].item())[0]['file_name']\n",
    "    fname = osp.join(cfg.DB.PATH, cfg.DB.DATA, \"val2017\", fname)\n",
    "    np_img = cv2.imread(fname)\n",
    "    # np_img = (batch['inp']*255).squeeze().permute(1,2,0).numpy().astype(np.uint8)\n",
    "    # np_img = cv2.resize(np_img, (512,512))\n",
    "    \n",
    "    Image.fromarray(np_img)\n",
    "    candidates = []\n",
    "    for b in bboxes:\n",
    "        x1, y1, x2, y2 = b\n",
    "        candidates.append([x1, y1, x2, y2, 1.0, 0])\n",
    "    dets = np.array([candidates])\n",
    "    dets_out = centernet_det_post_process(\n",
    "        dets.copy(), \n",
    "        batch['c'].cpu().numpy(), \n",
    "        batch['s'].cpu().numpy(), \n",
    "        batch[(128,128)]['hm'].shape[2], \n",
    "        batch[(128,128)]['hm'].shape[3], \n",
    "        batch[(128,128)]['hm'].shape[1]\n",
    "    )[0]\n",
    "    results[batch['img_id'][0]] = dets_out\n",
    "#     for b in dets_out[1]:\n",
    "#         x1, y1, x2, y2, score = b\n",
    "#         if score > 0.5:\n",
    "#             cv2.rectangle(np_img, (int(x1), int(y1)), (int(x2), int(y2)), (255,255,0), 2)\n",
    "#     if i == 3:\n",
    "#         break\n",
    "# Image.fromarray(np_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for i, batch in enumerate(loader[branch]):\n",
    "    feat = {}\n",
    "    out_size = (128,128)\n",
    "    feat['hm']  = batch[out_size]['hm']\n",
    "    feat['wh']  = torch.from_numpy(\n",
    "        gen_oracle_map(\n",
    "            batch[out_size]['wh'].detach().cpu().numpy(), \n",
    "            batch[out_size]['ind'].detach().cpu().numpy(), \n",
    "            batch['inp'].shape[3] // cfg.MODEL.STRIDES[0], \n",
    "            batch['inp'].shape[2] // cfg.MODEL.STRIDES[0]\n",
    "        )\n",
    "    )\n",
    "    feat['reg'] = torch.from_numpy(\n",
    "        gen_oracle_map(\n",
    "            batch[out_size]['reg'].detach().cpu().numpy(), \n",
    "            batch[out_size]['ind'].detach().cpu().numpy(), \n",
    "            batch['inp'].shape[3] // cfg.MODEL.STRIDES[0], \n",
    "            batch['inp'].shape[2] // cfg.MODEL.STRIDES[0]\n",
    "        )\n",
    "    )\n",
    "    break\n",
    "    dets, inds = scopehead_det_decode(feat['hm'], feat['wh'], reg=feat['reg'], K=100, return_inds=True)\n",
    "    dets = dets.detach().cpu().numpy().reshape(2, 100, -1)\n",
    "    break\n",
    "    dets_out = centernet_det_post_process(\n",
    "        dets.copy(), \n",
    "        batch['c'].cpu().numpy(), \n",
    "        batch['s'].cpu().numpy(), \n",
    "        feat['hm'].shape[2], \n",
    "        feat['hm'].shape[3], \n",
    "        feat['hm'].shape[1]\n",
    "    )[0]\n",
    "    fname = loader[branch].dataset.coco[0].loadImgs(batch['img_id'][0].item())[0]['file_name']\n",
    "    fname = osp.join(cfg.DB.PATH, cfg.DB.DATA, \"val2017\", fname)\n",
    "    np_img = cv2.imread(fname)\n",
    "    results[batch['img_id'][0]] = dets_out\n",
    "#     for b in dets_out[1]:\n",
    "#         x1, y1, x2, y2, score = b\n",
    "#         if score > 0.5:\n",
    "#             cv2.rectangle(np_img, (int(x1), int(y1)), (int(x2), int(y2)), (255,255,0), 2)\n",
    "#     if i == 3:\n",
    "#         break\n",
    "# Image.fromarray(np_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_wh = batch[out_size]['wh']\n",
    "p_reg = batch[out_size]['reg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor(1.1132e-07)"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "ciou_loss = CIOULoss()\n",
    "ciou_loss(p_wh, p_reg, batch[out_size]['ind'], batch['bboxes'], gt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[ 11.5200,  48.3200,  37.6000, 127.7500,   1.0000],\n        [ 31.8400,  44.8000,  54.8800, 124.6400,   1.0000],\n        [ 49.6000,  48.0000,  75.5200, 127.5200,   1.0000],\n        [ 66.7200,  45.1200,  88.9600, 127.7500,   1.0000],\n        [ 68.6400,  43.3600, 104.4800, 125.1200,   1.0000]])"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "t[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[ 11.5200,  48.3200,  37.6000, 127.7500],\n        [ 31.8400,  44.8000,  54.8800, 124.6400],\n        [ 49.6000,  48.0000,  75.5200, 127.5200],\n        [ 66.7200,  45.1200,  88.9600, 127.7500],\n        [ 68.6400,  43.3600, 104.4800, 125.1200]])"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "p[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.utils import _tranpose_and_gather_feat\n",
    "import math\n",
    "class CIOULoss(nn.Module):\n",
    "    '''\n",
    "    Reference\n",
    "         Complete-IOU loss ( https://arxiv.org/abs/1911.08287 )\n",
    "    Code\n",
    "        https://github.com/Zzh-tju/DIoU-SSD-pytorch/blob/master/utils/box/box_utils.py#L47\n",
    "    Args\n",
    "        p_wh : prediced wh in centernet\n",
    "        p_reg : prediced reg in centernet\n",
    "        t_inds : ind generated by scopehead or centernet\n",
    "        t_hm : hm generated by scopehead or centernet\n",
    "        t_dets : grountruth of bboxes\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CIOULoss, self).__init__()\n",
    "\n",
    "    def forward(self, p_wh, p_reg, t_inds, t_dets, gt=False):\n",
    "        num_bins=5\n",
    "        n = p_wh.size(0)\n",
    "        h, w = 128, 128\n",
    "        if not gt:\n",
    "            p_reg = _tranpose_and_gather_feat(p_reg, t_inds)\n",
    "            p_wh = _tranpose_and_gather_feat(p_wh, t_inds)\n",
    "\n",
    "        p_reg = p_reg[t_inds>0,:]\n",
    "        p_wh = p_wh[t_inds>0,:].view(-1, 2)\n",
    "\n",
    "        t_dets = torch.cat(t_dets, dim=0)\n",
    "        t_dets = t_dets[t_dets[:,-1] > 0]\n",
    "        t_dets[:,[0, 2]] *= w\n",
    "        t_dets[:,[1, 3]] *= h\n",
    "\n",
    "        cx = ((t_dets[:,0] + t_dets[:,2]) / 2).int() + p_reg[:, 0]\n",
    "        cy = ((t_dets[:,1] + t_dets[:,3]) / 2).int() + p_reg[:, 1]\n",
    "    \n",
    "        p_dets = torch.stack([cx - p_wh[..., 0] / 2, \n",
    "                              cy - p_wh[..., 1] / 2,\n",
    "                              cx + p_wh[..., 0] / 2, \n",
    "                              cy + p_wh[..., 1] / 2], dim=-1).view(-1, 4)\n",
    "        ciou = self.bbox_overlaps_ciou(p_dets, t_dets)\n",
    "        return (1 - ciou).mean()\n",
    "\n",
    "    @staticmethod\n",
    "    def bbox_overlaps_ciou(bboxes1, bboxes2):\n",
    "        rows = bboxes1.shape[0]\n",
    "        cols = bboxes2.shape[0]\n",
    "        cious = torch.zeros((rows, cols))\n",
    "        if rows * cols == 0:\n",
    "            return cious\n",
    "        exchange = False\n",
    "        if bboxes1.shape[0] > bboxes2.shape[0]:\n",
    "            bboxes1, bboxes2 = bboxes2, bboxes1\n",
    "            cious = torch.zeros((cols, rows))\n",
    "            exchange = True\n",
    "\n",
    "        w1 = bboxes1[:, 2] - bboxes1[:, 0]\n",
    "        h1 = bboxes1[:, 3] - bboxes1[:, 1]\n",
    "        w2 = bboxes2[:, 2] - bboxes2[:, 0]\n",
    "        h2 = bboxes2[:, 3] - bboxes2[:, 1]\n",
    "\n",
    "        area1 = w1 * h1\n",
    "        area2 = w2 * h2\n",
    "\n",
    "        center_x1 = (bboxes1[:, 2] + bboxes1[:, 0]) / 2\n",
    "        center_y1 = (bboxes1[:, 3] + bboxes1[:, 1]) / 2\n",
    "        center_x2 = (bboxes2[:, 2] + bboxes2[:, 0]) / 2\n",
    "        center_y2 = (bboxes2[:, 3] + bboxes2[:, 1]) / 2\n",
    "\n",
    "        inter_max_xy = torch.min(bboxes1[:, 2:4],bboxes2[:, 2:4])\n",
    "        inter_min_xy = torch.max(bboxes1[:, :2],bboxes2[:, :2])\n",
    "        out_max_xy = torch.max(bboxes1[:, 2:4],bboxes2[:, 2:4])\n",
    "        out_min_xy = torch.min(bboxes1[:, :2],bboxes2[:, :2])\n",
    "        inter = torch.clamp((inter_max_xy - inter_min_xy), min=0)\n",
    "        inter_area = inter[:, 0] * inter[:, 1]\n",
    "        inter_diag = (center_x2 - center_x1)**2 + (center_y2 - center_y1)**2\n",
    "        outer = torch.clamp((out_max_xy - out_min_xy), min=0)\n",
    "        outer_diag = (outer[:, 0] ** 2) + (outer[:, 1] ** 2)\n",
    "        union = area1+area2-inter_area\n",
    "        u = (inter_diag) / outer_diag\n",
    "        iou = inter_area / (union + 1e-12)\n",
    "        v = (4 / (math.pi ** 2)) * torch.pow((torch.atan(w2 / (h2+1e-12)) - torch.atan(w1 / (h1+1e-12))), 2)\n",
    "        with torch.no_grad():\n",
    "            S = torch.clamp(1 - iou, min=1e-6)\n",
    "            alpha = v / (S + v)\n",
    "        cious = iou - (u + alpha * v)\n",
    "        cious = torch.clamp(cious,min=-1.0,max = 1.0)\n",
    "        if exchange:\n",
    "            cious = cious.T\n",
    "        return cious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_overlaps_ciou(bboxes1, bboxes2):\n",
    "    rows = bboxes1.shape[0]\n",
    "    cols = bboxes2.shape[0]\n",
    "    cious = torch.zeros((rows, cols))\n",
    "    if rows * cols == 0:\n",
    "        return cious\n",
    "    exchange = False\n",
    "    if bboxes1.shape[0] > bboxes2.shape[0]:\n",
    "        bboxes1, bboxes2 = bboxes2, bboxes1\n",
    "        cious = torch.zeros((cols, rows))\n",
    "        exchange = True\n",
    "\n",
    "    w1 = bboxes1[:, 2] - bboxes1[:, 0]\n",
    "    h1 = bboxes1[:, 3] - bboxes1[:, 1]\n",
    "    w2 = bboxes2[:, 2] - bboxes2[:, 0]\n",
    "    h2 = bboxes2[:, 3] - bboxes2[:, 1]\n",
    "\n",
    "    area1 = w1 * h1\n",
    "    area2 = w2 * h2\n",
    "\n",
    "    center_x1 = (bboxes1[:, 2] + bboxes1[:, 0]) / 2\n",
    "    center_y1 = (bboxes1[:, 3] + bboxes1[:, 1]) / 2\n",
    "    center_x2 = (bboxes2[:, 2] + bboxes2[:, 0]) / 2\n",
    "    center_y2 = (bboxes2[:, 3] + bboxes2[:, 1]) / 2\n",
    "\n",
    "    inter_max_xy = torch.min(bboxes1[:, 2:],bboxes2[:, 2:])\n",
    "    inter_min_xy = torch.max(bboxes1[:, :2],bboxes2[:, :2])\n",
    "    out_max_xy = torch.max(bboxes1[:, 2:],bboxes2[:, 2:])\n",
    "    out_min_xy = torch.min(bboxes1[:, :2],bboxes2[:, :2])\n",
    "    inter = torch.clamp((inter_max_xy - inter_min_xy), min=0)\n",
    "    inter_area = inter[:, 0] * inter[:, 1]\n",
    "    inter_diag = (center_x2 - center_x1)**2 + (center_y2 - center_y1)**2\n",
    "    outer = torch.clamp((out_max_xy - out_min_xy), min=0)\n",
    "    outer_diag = (outer[:, 0] ** 2) + (outer[:, 1] ** 2)\n",
    "    union = area1+area2-inter_area\n",
    "    u = (inter_diag) / outer_diag\n",
    "    iou = inter_area / union\n",
    "    v = (4 / (math.pi ** 2)) * torch.pow((torch.atan(w2 / h2) - torch.atan(w1 / h1)), 2)\n",
    "    with torch.no_grad():\n",
    "        S = torch.clamp(1 - iou, min=1e-6)\n",
    "        alpha = v / (S + v)\n",
    "    cious = iou - (u + alpha * v)\n",
    "    cious = torch.clamp(cious,min=-1.0,max = 1.0)\n",
    "    if exchange:\n",
    "        cious = cious.T\n",
    "    return cious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_float(x):\n",
    "    return float(\"{:.2f}\".format(x))\n",
    "\n",
    "def convert_eval_format(all_bboxes, valid_ids):\n",
    "    # import pdb; pdb.set_trace()\n",
    "    detections = []\n",
    "    for image_id in tqdm(all_bboxes, desc=\"COCO EVAL\"):\n",
    "        for cls_ind in all_bboxes[image_id]:\n",
    "            for bbox in all_bboxes[image_id][cls_ind]:\n",
    "                bbox[2] -= bbox[0]\n",
    "                bbox[3] -= bbox[1]\n",
    "                score = bbox[4]\n",
    "                bbox_out  = list(map(_to_float, bbox[0:4]))\n",
    "                category_id = valid_ids[cls_ind - 1]\n",
    "                detection = {\n",
    "                    \"image_id\": int(image_id),\n",
    "                    \"category_id\": int(category_id),\n",
    "                    \"bbox\": bbox_out,\n",
    "                    \"score\": float(\"{:.2f}\".format(score))\n",
    "                }\n",
    "                detections.append(detection)\n",
    "    return detections\n",
    "\n",
    "def coco_eval(coco, results, save_dir):\n",
    "    json.dump(convert_eval_format(results, coco.getCatIds()), open('{}/results_oracle.json'.format(save_dir), 'w'))\n",
    "    coco_dets = coco.loadRes('{}/results_oracle.json'.format(save_dir))\n",
    "    coco_eval = COCOeval(coco, coco_dets, \"bbox\")\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "coco_eval(loader[branch].dataset.coco[0], results, \"/home/agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_dets = loader[branch].dataset.coco[0].loadRes('/home/agent/results_gt.json')\n",
    "oracle_dets = loader[branch].dataset.coco[0].loadRes('/home/agent/results_oracle.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids = gt_dets.getImgIds()\n",
    "for img_id in img_ids[17:]:\n",
    "    gt_ann_ids = gt_dets.getAnnIds([img_id])\n",
    "    gt_anns = gt_dets.loadAnns(gt_ann_ids)\n",
    "    oracle_ann_ids = oracle_dets.getAnnIds([img_id])\n",
    "    oracle_anns = oracle_dets.loadAnns(oracle_ann_ids)\n",
    "    \n",
    "    fname = loader[branch].dataset.coco[0].loadImgs(img_id)[0]['file_name']\n",
    "    fname = osp.join(cfg.DB.PATH, cfg.DB.DATA, \"val2017\", fname)\n",
    "    np_img = cv2.imread(fname)\n",
    "    # np_img2 = np_img.copy()\n",
    "    for ann in gt_anns:\n",
    "        x1, y1, w, h = ann['bbox']\n",
    "        cv2.rectangle(np_img, (int(x1), int(y1)), (int(x1+w), int(y1+h)), (255,255,0), 2)\n",
    "    for ann in oracle_anns:\n",
    "        x1, y1, w, h = ann['bbox']\n",
    "        score = ann['score']\n",
    "        if score > 0.5:\n",
    "            cv2.rectangle(np_img, (int(x1), int(y1)), (int(x1+w), int(y1+h)), (255,0,255), 2)\n",
    "\n",
    "    break\n",
    "Image.fromarray(np_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes = dets_out[1]\n",
    "# bboxes[:, [0,2]] *= 4\n",
    "# bboxes[:, [1,3]] *= 4\n",
    "fname = loader[branch].dataset.coco[0].loadImgs(batch['img_id'][0].item())[0]['file_name']\n",
    "fname = osp.join(cfg.DB.PATH, \"cityperson\", \"val2017\", fname)\n",
    "np_img = cv2.imread(fname)\n",
    "# np_img = (batch['inp']*255).squeeze().permute(1,2,0).numpy().astype(np.uint8)\n",
    "# np_img = cv2.resize(np_img, (512,512))\n",
    "for b in bboxes:\n",
    "    x1, y1, x2, y2, score = b\n",
    "    if score > 0.5:\n",
    "        print(b)\n",
    "        cv2.rectangle(np_img, (int(x1), int(y1)), (int(x2), int(y2)), (255,255,0), 2)\n",
    "Image.fromarray(np_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dets_out[0].update(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls_id in a:\n",
    "    b[cls_id].extend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = loader[branch].dataset.coco[0]\n",
    "# orig_detections = convert_eval_format(results, handle.getCatIds())\n",
    "# json.dump(orig_detections, open('./external/result.json', 'w'))\n",
    "coco_dets = handle.loadRes('./external/result.json')\n",
    "coco_eval = COCOeval(handle, coco_dets, \"bbox\")\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_detections[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "for orig_b, b in zip(orig_detections, detections):\n",
    "    diff = np.array(orig_b['bbox']) - np.array(b['bbox'])\n",
    "    print(diff)\n",
    "    if diff.sum() > 0:\n",
    "        print(orig_b)\n",
    "        print(b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = batch['img_id'][0].item()\n",
    "handle = loader[branch].dataset.coco[0]\n",
    "fname = handle.loadImgs(ids=[img_id])[0]['file_name']\n",
    "fname = os.path.join(cfg.DB.PATH, \"crowdhuman\", \"val2017\", fname)\n",
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np_img = (batch['inp']*255).squeeze().permute(1,2,0).numpy().astype(np.uint8)\n",
    "np_img = cv2.imread(fname)\n",
    "num = 0\n",
    "for c in dets_out[0]:\n",
    "    for b in dets_out[0][c]:\n",
    "        x1, y1, x2, y2, score = b\n",
    "        if score > 0.5:\n",
    "            print(x1, y1, x2, y2)\n",
    "            num += 1\n",
    "            cv2.rectangle(np_img, (int(x1), int(y1)), (int(x2), int(y2)), (255,255,0), 2)\n",
    "pil_img = Image.fromarray(np_img)\n",
    "w, h = pil_img.size\n",
    "# print(num)\n",
    "pil_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _coco_box_to_bbox(box):\n",
    "    bbox = np.array([box[0], box[1], box[0] + box[2], box[1] + box[3]], dtype=np.float32)\n",
    "    return bbox\n",
    "ann_ids = handle.getAnnIds(imgIds=[img_id])\n",
    "anns = handle.loadAnns(ids=ann_ids)\n",
    "num_objs = len(anns)\n",
    "src_bboxes = []\n",
    "for k in range(num_objs):\n",
    "    ann = anns[k]\n",
    "    src_bboxes.append(_coco_box_to_bbox(ann['bbox']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np_img = cv2.imread(fname)\n",
    "for b in src_bboxes:\n",
    "    x1, y1, x2, y2 = b\n",
    "    cv2.rectangle(np_img, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 2)\n",
    "Image.fromarray(np_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = f\"/media/allen/mass/deep-learning-works/evaluation/caltech cityperson cityperson/Hourglass-coco_cityperson_caltech-person-focal_l1-SGDW_cosine_lr_0.01_warmup-scratch/000-2020-04-16_10-03/results.json\"\n",
    "f = open(src, 'r')\n",
    "results = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []\n",
    "for result in results:\n",
    "    if result['score'] > 0.5:\n",
    "        final.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 10\n",
    "img_id = final[idx]['image_id']\n",
    "handle = loader[branch].dataset.coco[0]\n",
    "fname = handle.loadImgs(ids=[img_id])[0]['file_name']\n",
    "fname = os.path.join(cfg.DB.PATH, \"cityperson\", \"val2017\", fname)\n",
    "np_img = cv2.imread(fname)\n",
    "x1, y1, w, h = final[idx]['bbox']\n",
    "cv2.rectangle(np_img, (int(x1), int(y1)), (int(x1+w), int(y1+h)), (255,255,0), 2)\n",
    "x1, y1, w, h = detections[idx+3]['bbox']\n",
    "cv2.rectangle(np_img, (int(x1), int(y1)), (int(x1+w), int(y1+h)), (0,0,255), 2)\n",
    "Image.fromarray(np_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = loader[branch].dataset.coco[0]\n",
    "image_ids = handle.getImgIds()\n",
    "detections = []\n",
    "for img_id in image_ids:\n",
    "    ann_ids = handle.getAnnIds(imgIds=[img_id])\n",
    "    anns = handle.loadAnns(ids=ann_ids)\n",
    "    for ann in anns:\n",
    "        detection = {\n",
    "            \"image_id\": int(img_id),\n",
    "            \"category_id\": int(ann['category_id']),\n",
    "            \"bbox\": ann['bbox'],\n",
    "            \"score\": 1.0,\n",
    "            'id': int(ann['id'])\n",
    "        }\n",
    "        detections.append(detection)\n",
    "    # breakhandle = loader[branch].dataset.coco[0]\n",
    "# json.dump(detections, open('./external/results.json', 'w'))\n",
    "# coco_dets = handle.loadRes('./external/results.json')\n",
    "# coco_eval = COCOeval(handle, coco_dets, \"bbox\")\n",
    "# coco_eval.evaluate()\n",
    "# coco_eval.accumulate()\n",
    "# coco_eval.summarize()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(orig_detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = loader[branch].dataset.coco[0]\n",
    "json.dump(detections, open('./external/results.json', 'w'))\n",
    "coco_dets = handle.loadRes('./external/results.json')\n",
    "coco_eval = COCOeval(handle, coco_dets, \"bbox\")\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36864bitpy368venv96aa759879e8443787e614586faca138",
   "display_name": "Python 3.6.8 64-bit ('py368': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}