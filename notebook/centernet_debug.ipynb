{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from src.factory.config_factory import cfg, show_configs, build_output\n",
    "from src.factory.data_factory import DataFactory\n",
    "from src.factory.data_format_factory import DataFormatFactory\n",
    "from src.factory.transform_factory import TransformFactory\n",
    "from src.factory.loader_factory import LoaderFactory\n",
    "from src.base_data import BaseData\n",
    "from tools.logger import setup_logger\n",
    "from tqdm import tqdm\n",
    "logger = setup_logger(\"./external/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.merge_from_file(\"./configs/shufflenetv2_scopehead_object_detection.yml\")\n",
    "# build_output(cfg, \"./configs/person.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.NUM_WORKERS = 1\n",
    "# cfg.DB.PATH = \"/media/allen/mass/DB\"\n",
    "cfg.DB.DATA = \"crowdhuman\"\n",
    "cfg.DB.DATA_FORMAT = \"coco\"\n",
    "cfg.DB.TARGET_FORMAT = \"scopehead\"\n",
    "cfg.DB.LOADER = \"coco\"\n",
    "cfg.DB.USE_TRAIN = False\n",
    "cfg.DB.USE_TEST = True\n",
    "cfg.INPUT.SIZE = (512, 512)\n",
    "cfg.INPUT.TEST_BS = 4\n",
    "cfg.MODEL.STRIDES = [4]\n",
    "cfg.DB.TRAIN_TRANSFORM = \"RandScale Tensorize\"\n",
    "cfg.DB.TEST_TRANSFORM = \"ResizeKeepAspectRatio Tensorize\"\n",
    "cfg.COCO.TARGET = \"person\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = LoaderFactory.produce(cfg)\n",
    "branch = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycocotools.coco as coco\n",
    "import json\n",
    "import os\n",
    "import os.path as osp\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import shutil\n",
    "import cv2\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from tools.centernet_utils import centernet_det_decode, centernet_det_post_process\n",
    "from tools.scopehead_utils import scopehead_det_decode\n",
    "from tools.oracle_utils import gen_oracle_map\n",
    "from tools.image import get_affine_transform\n",
    "from copy import deepcopy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "for i, batch in enumerate(loader[branch]):\n",
    "    batch['bboxes']\n",
    "    bboxes = np.vstack(batch['bboxes'])\n",
    "    bboxes[:, [0,2]] *= 128\n",
    "    bboxes[:, [1,3]] *= 128\n",
    "    break\n",
    "    fname = loader[branch].dataset.coco[0].loadImgs(batch['img_id'][0].item())[0]['file_name']\n",
    "    fname = osp.join(cfg.DB.PATH, cfg.DB.DATA, \"val2017\", fname)\n",
    "    np_img = cv2.imread(fname)\n",
    "    # np_img = (batch['inp']*255).squeeze().permute(1,2,0).numpy().astype(np.uint8)\n",
    "    # np_img = cv2.resize(np_img, (512,512))\n",
    "    \n",
    "    Image.fromarray(np_img)\n",
    "    candidates = []\n",
    "    for b in bboxes:\n",
    "        x1, y1, x2, y2 = b\n",
    "        candidates.append([x1, y1, x2, y2, 1.0, 0])\n",
    "    dets = np.array([candidates])\n",
    "    dets_out = centernet_det_post_process(\n",
    "        dets.copy(), \n",
    "        batch['c'].cpu().numpy(), \n",
    "        batch['s'].cpu().numpy(), \n",
    "        batch[(128,128)]['hm'].shape[2], \n",
    "        batch[(128,128)]['hm'].shape[3], \n",
    "        batch[(128,128)]['hm'].shape[1]\n",
    "    )[0]\n",
    "    results[batch['img_id'][0]] = dets_out\n",
    "#     for b in dets_out[1]:\n",
    "#         x1, y1, x2, y2, score = b\n",
    "#         if score > 0.5:\n",
    "#             cv2.rectangle(np_img, (int(x1), int(y1)), (int(x2), int(y2)), (255,255,0), 2)\n",
    "#     if i == 3:\n",
    "#         break\n",
    "# Image.fromarray(np_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for i, batch in enumerate(loader[branch]):\n",
    "    feat = {}\n",
    "    out_size = (128,128)\n",
    "    feat['hm']  = batch[out_size]['hm']\n",
    "    feat['wh']  = torch.from_numpy(\n",
    "        gen_oracle_map(\n",
    "            batch[out_size]['wh'].detach().cpu().numpy(), \n",
    "            batch[out_size]['ind'].detach().cpu().numpy(), \n",
    "            batch['inp'].shape[3] // cfg.MODEL.STRIDES[0], \n",
    "            batch['inp'].shape[2] // cfg.MODEL.STRIDES[0]\n",
    "        )\n",
    "    )\n",
    "    feat['reg'] = torch.from_numpy(\n",
    "        gen_oracle_map(\n",
    "            batch[out_size]['reg'].detach().cpu().numpy(), \n",
    "            batch[out_size]['ind'].detach().cpu().numpy(), \n",
    "            batch['inp'].shape[3] // cfg.MODEL.STRIDES[0], \n",
    "            batch['inp'].shape[2] // cfg.MODEL.STRIDES[0]\n",
    "        )\n",
    "    )\n",
    "    break\n",
    "    dets, inds = scopehead_det_decode(feat['hm'], feat['wh'], reg=feat['reg'], K=100, return_inds=True)\n",
    "    dets = dets.detach().cpu().numpy().reshape(2, 100, -1)\n",
    "    break\n",
    "    dets_out = centernet_det_post_process(\n",
    "        dets.copy(), \n",
    "        batch['c'].cpu().numpy(), \n",
    "        batch['s'].cpu().numpy(), \n",
    "        feat['hm'].shape[2], \n",
    "        feat['hm'].shape[3], \n",
    "        feat['hm'].shape[1]\n",
    "    )[0]\n",
    "    fname = loader[branch].dataset.coco[0].loadImgs(batch['img_id'][0].item())[0]['file_name']\n",
    "    fname = osp.join(cfg.DB.PATH, cfg.DB.DATA, \"val2017\", fname)\n",
    "    np_img = cv2.imread(fname)\n",
    "    results[batch['img_id'][0]] = dets_out\n",
    "#     for b in dets_out[1]:\n",
    "#         x1, y1, x2, y2, score = b\n",
    "#         if score > 0.5:\n",
    "#             cv2.rectangle(np_img, (int(x1), int(y1)), (int(x2), int(y2)), (255,255,0), 2)\n",
    "#     if i == 3:\n",
    "#         break\n",
    "# Image.fromarray(np_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[0.0900, 0.3775, 0.2937, 0.9980],\n        [0.2488, 0.3500, 0.4288, 0.9737],\n        [0.3875, 0.3750, 0.5900, 0.9962],\n        [0.5213, 0.3525, 0.6950, 0.9980],\n        [0.5362, 0.3388, 0.8163, 0.9775],\n        [0.6787, 0.3475, 0.9980, 0.9980]])"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "batch['bboxes'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dets[dets[...,4] > 0.5][...,:4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_order = inds[gt_inds>0].sort()[1]\n",
    "t_order = gt_inds[gt_inds>0].sort()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds[gt_inds>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_dets = []\n",
    "match_bboxes = []\n",
    "for p_ind, t_ind in zip(p_order, t_order):\n",
    "    match_dets.append(dets[dets[...,4] > 0.5][...,:4][p_ind])\n",
    "    match_bboxes.append(bboxes[t_ind])\n",
    "match_dets = torch.Tensor(match_dets)\n",
    "match_bboxes = torch.Tensor(match_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_dets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.from_numpy(dets[dets[...,4] > 0.5][...,:4]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bbox_overlaps_ciou(match_dets, match_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciou_loss = CIOULoss()\n",
    "p, t = ciou_loss(feat['wh'], feat['reg'], batch[out_size]['ind'], feat['hm'], batch['bboxes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[0.0900, 0.3775, 0.2937, 0.9980],\n        [0.2488, 0.3500, 0.4288, 0.9737],\n        [0.3875, 0.3750, 0.5900, 0.9962],\n        [0.5213, 0.3525, 0.6950, 0.9980],\n        [0.5362, 0.3388, 0.8163, 0.9775],\n        [0.6787, 0.3475, 0.9980, 0.9980],\n        [0.0240, 0.3646, 0.2615, 0.9865],\n        [0.1688, 0.3844, 0.3313, 0.9656],\n        [0.2823, 0.3375, 0.4563, 0.9219],\n        [0.4000, 0.3240, 0.6156, 0.9312]])"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "t[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([0.4667, 0.3198, 0.6792, 0.9187])"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "t_dets[[0, 2]] *= w\n",
    "t_dets[[1, 3]] *= h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class CIOULoss(nn.Module):\n",
    "    '''\n",
    "    Reference\n",
    "         Complete-IOU loss ( https://arxiv.org/abs/1911.08287 )\n",
    "    Code\n",
    "        https://github.com/Zzh-tju/DIoU-SSD-pytorch/blob/master/utils/box/box_utils.py#L47\n",
    "    Args\n",
    "        p_wh : prediced wh in centernet\n",
    "        p_reg : prediced reg in centernet\n",
    "        t_inds : ind generated by scopehead or centernet\n",
    "        t_hm : hm generated by scopehead or centernet\n",
    "        t_dets : grountruth of bboxes\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CIOULoss, self).__init__()\n",
    "\n",
    "    def forward(self, p_wh, p_reg, t_inds, t_hm, t_dets):\n",
    "        n, _, h, w = t_hm.size()\n",
    "        p_dets, p_inds = scopehead_det_decode(t_hm, p_wh, reg=p_reg, K=100, return_inds=True)\n",
    "        p_dets = p_dets.view(n, 100, -1)\n",
    "        t_dets = p_wh.new_tensor(torch.cat(t_dets, dim=0))\n",
    "        t_dets[:,[0, 2]] *= w\n",
    "        t_dets[:,[1, 3]] *= h\n",
    "        p_order = p_inds[t_inds>0].sort()[1]\n",
    "        t_order = t_inds[t_inds>0].sort()[1]\n",
    "        match_dets = []\n",
    "        match_bboxes = []\n",
    "        # return p_dets, t_dets\n",
    "        for p_ind, t_ind in zip(p_order, t_order):\n",
    "            match_dets.append(p_dets[p_dets[...,4] > 0.5][...,:4][p_ind])\n",
    "            match_bboxes.append(t_dets[t_ind])\n",
    "        match_dets = p_wh.new_tensor(torch.stack(match_dets))\n",
    "        match_bboxes = p_wh.new_tensor(torch.stack(match_bboxes))\n",
    "        ciou = self.bbox_overlaps_ciou(match_dets, match_bboxes)\n",
    "        return (1 - ciou).mean()\n",
    "\n",
    "    @staticmethod\n",
    "    def bbox_overlaps_ciou(bboxes1, bboxes2):\n",
    "        rows = bboxes1.shape[0]\n",
    "        cols = bboxes2.shape[0]\n",
    "        cious = torch.zeros((rows, cols))\n",
    "        if rows * cols == 0:\n",
    "            return cious\n",
    "        exchange = False\n",
    "        if bboxes1.shape[0] > bboxes2.shape[0]:\n",
    "            bboxes1, bboxes2 = bboxes2, bboxes1\n",
    "            cious = torch.zeros((cols, rows))\n",
    "            exchange = True\n",
    "\n",
    "        w1 = bboxes1[:, 2] - bboxes1[:, 0]\n",
    "        h1 = bboxes1[:, 3] - bboxes1[:, 1]\n",
    "        w2 = bboxes2[:, 2] - bboxes2[:, 0]\n",
    "        h2 = bboxes2[:, 3] - bboxes2[:, 1]\n",
    "\n",
    "        area1 = w1 * h1\n",
    "        area2 = w2 * h2\n",
    "\n",
    "        center_x1 = (bboxes1[:, 2] + bboxes1[:, 0]) / 2\n",
    "        center_y1 = (bboxes1[:, 3] + bboxes1[:, 1]) / 2\n",
    "        center_x2 = (bboxes2[:, 2] + bboxes2[:, 0]) / 2\n",
    "        center_y2 = (bboxes2[:, 3] + bboxes2[:, 1]) / 2\n",
    "\n",
    "        inter_max_xy = torch.min(bboxes1[:, 2:],bboxes2[:, 2:])\n",
    "        inter_min_xy = torch.max(bboxes1[:, :2],bboxes2[:, :2])\n",
    "        out_max_xy = torch.max(bboxes1[:, 2:],bboxes2[:, 2:])\n",
    "        out_min_xy = torch.min(bboxes1[:, :2],bboxes2[:, :2])\n",
    "        inter = torch.clamp((inter_max_xy - inter_min_xy), min=0)\n",
    "        inter_area = inter[:, 0] * inter[:, 1]\n",
    "        inter_diag = (center_x2 - center_x1)**2 + (center_y2 - center_y1)**2\n",
    "        outer = torch.clamp((out_max_xy - out_min_xy), min=0)\n",
    "        outer_diag = (outer[:, 0] ** 2) + (outer[:, 1] ** 2)\n",
    "        union = area1+area2-inter_area\n",
    "        u = (inter_diag) / outer_diag\n",
    "        iou = inter_area / union\n",
    "        v = (4 / (math.pi ** 2)) * torch.pow((torch.atan(w2 / h2) - torch.atan(w1 / h1)), 2)\n",
    "        with torch.no_grad():\n",
    "            S = torch.clamp(1 - iou, min=1e-6)\n",
    "            alpha = v / (S + v)\n",
    "        cious = iou - (u + alpha * v)\n",
    "        cious = torch.clamp(cious,min=-1.0,max = 1.0)\n",
    "        if exchange:\n",
    "            cious = cious.T\n",
    "        return cious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_overlaps_ciou(bboxes1, bboxes2):\n",
    "    rows = bboxes1.shape[0]\n",
    "    cols = bboxes2.shape[0]\n",
    "    cious = torch.zeros((rows, cols))\n",
    "    if rows * cols == 0:\n",
    "        return cious\n",
    "    exchange = False\n",
    "    if bboxes1.shape[0] > bboxes2.shape[0]:\n",
    "        bboxes1, bboxes2 = bboxes2, bboxes1\n",
    "        cious = torch.zeros((cols, rows))\n",
    "        exchange = True\n",
    "\n",
    "    w1 = bboxes1[:, 2] - bboxes1[:, 0]\n",
    "    h1 = bboxes1[:, 3] - bboxes1[:, 1]\n",
    "    w2 = bboxes2[:, 2] - bboxes2[:, 0]\n",
    "    h2 = bboxes2[:, 3] - bboxes2[:, 1]\n",
    "\n",
    "    area1 = w1 * h1\n",
    "    area2 = w2 * h2\n",
    "\n",
    "    center_x1 = (bboxes1[:, 2] + bboxes1[:, 0]) / 2\n",
    "    center_y1 = (bboxes1[:, 3] + bboxes1[:, 1]) / 2\n",
    "    center_x2 = (bboxes2[:, 2] + bboxes2[:, 0]) / 2\n",
    "    center_y2 = (bboxes2[:, 3] + bboxes2[:, 1]) / 2\n",
    "\n",
    "    inter_max_xy = torch.min(bboxes1[:, 2:],bboxes2[:, 2:])\n",
    "    inter_min_xy = torch.max(bboxes1[:, :2],bboxes2[:, :2])\n",
    "    out_max_xy = torch.max(bboxes1[:, 2:],bboxes2[:, 2:])\n",
    "    out_min_xy = torch.min(bboxes1[:, :2],bboxes2[:, :2])\n",
    "    inter = torch.clamp((inter_max_xy - inter_min_xy), min=0)\n",
    "    inter_area = inter[:, 0] * inter[:, 1]\n",
    "    inter_diag = (center_x2 - center_x1)**2 + (center_y2 - center_y1)**2\n",
    "    outer = torch.clamp((out_max_xy - out_min_xy), min=0)\n",
    "    outer_diag = (outer[:, 0] ** 2) + (outer[:, 1] ** 2)\n",
    "    union = area1+area2-inter_area\n",
    "    u = (inter_diag) / outer_diag\n",
    "    iou = inter_area / union\n",
    "    v = (4 / (math.pi ** 2)) * torch.pow((torch.atan(w2 / h2) - torch.atan(w1 / h1)), 2)\n",
    "    with torch.no_grad():\n",
    "        S = torch.clamp(1 - iou, min=1e-6)\n",
    "        alpha = v / (S + v)\n",
    "    cious = iou - (u + alpha * v)\n",
    "    cious = torch.clamp(cious,min=-1.0,max = 1.0)\n",
    "    if exchange:\n",
    "        cious = cious.T\n",
    "    return cious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_float(x):\n",
    "    return float(\"{:.2f}\".format(x))\n",
    "\n",
    "def convert_eval_format(all_bboxes, valid_ids):\n",
    "    # import pdb; pdb.set_trace()\n",
    "    detections = []\n",
    "    for image_id in tqdm(all_bboxes, desc=\"COCO EVAL\"):\n",
    "        for cls_ind in all_bboxes[image_id]:\n",
    "            for bbox in all_bboxes[image_id][cls_ind]:\n",
    "                bbox[2] -= bbox[0]\n",
    "                bbox[3] -= bbox[1]\n",
    "                score = bbox[4]\n",
    "                bbox_out  = list(map(_to_float, bbox[0:4]))\n",
    "                category_id = valid_ids[cls_ind - 1]\n",
    "                detection = {\n",
    "                    \"image_id\": int(image_id),\n",
    "                    \"category_id\": int(category_id),\n",
    "                    \"bbox\": bbox_out,\n",
    "                    \"score\": float(\"{:.2f}\".format(score))\n",
    "                }\n",
    "                detections.append(detection)\n",
    "    return detections\n",
    "\n",
    "def coco_eval(coco, results, save_dir):\n",
    "    json.dump(convert_eval_format(results, coco.getCatIds()), open('{}/results_oracle.json'.format(save_dir), 'w'))\n",
    "    coco_dets = coco.loadRes('{}/results_oracle.json'.format(save_dir))\n",
    "    coco_eval = COCOeval(coco, coco_dets, \"bbox\")\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "coco_eval(loader[branch].dataset.coco[0], results, \"/home/agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_dets = loader[branch].dataset.coco[0].loadRes('/home/agent/results_gt.json')\n",
    "oracle_dets = loader[branch].dataset.coco[0].loadRes('/home/agent/results_oracle.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids = gt_dets.getImgIds()\n",
    "for img_id in img_ids[17:]:\n",
    "    gt_ann_ids = gt_dets.getAnnIds([img_id])\n",
    "    gt_anns = gt_dets.loadAnns(gt_ann_ids)\n",
    "    oracle_ann_ids = oracle_dets.getAnnIds([img_id])\n",
    "    oracle_anns = oracle_dets.loadAnns(oracle_ann_ids)\n",
    "    \n",
    "    fname = loader[branch].dataset.coco[0].loadImgs(img_id)[0]['file_name']\n",
    "    fname = osp.join(cfg.DB.PATH, cfg.DB.DATA, \"val2017\", fname)\n",
    "    np_img = cv2.imread(fname)\n",
    "    # np_img2 = np_img.copy()\n",
    "    for ann in gt_anns:\n",
    "        x1, y1, w, h = ann['bbox']\n",
    "        cv2.rectangle(np_img, (int(x1), int(y1)), (int(x1+w), int(y1+h)), (255,255,0), 2)\n",
    "    for ann in oracle_anns:\n",
    "        x1, y1, w, h = ann['bbox']\n",
    "        score = ann['score']\n",
    "        if score > 0.5:\n",
    "            cv2.rectangle(np_img, (int(x1), int(y1)), (int(x1+w), int(y1+h)), (255,0,255), 2)\n",
    "\n",
    "    break\n",
    "Image.fromarray(np_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes = dets_out[1]\n",
    "# bboxes[:, [0,2]] *= 4\n",
    "# bboxes[:, [1,3]] *= 4\n",
    "fname = loader[branch].dataset.coco[0].loadImgs(batch['img_id'][0].item())[0]['file_name']\n",
    "fname = osp.join(cfg.DB.PATH, \"cityperson\", \"val2017\", fname)\n",
    "np_img = cv2.imread(fname)\n",
    "# np_img = (batch['inp']*255).squeeze().permute(1,2,0).numpy().astype(np.uint8)\n",
    "# np_img = cv2.resize(np_img, (512,512))\n",
    "for b in bboxes:\n",
    "    x1, y1, x2, y2, score = b\n",
    "    if score > 0.5:\n",
    "        print(b)\n",
    "        cv2.rectangle(np_img, (int(x1), int(y1)), (int(x2), int(y2)), (255,255,0), 2)\n",
    "Image.fromarray(np_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dets_out[0].update(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls_id in a:\n",
    "    b[cls_id].extend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = loader[branch].dataset.coco[0]\n",
    "# orig_detections = convert_eval_format(results, handle.getCatIds())\n",
    "# json.dump(orig_detections, open('./external/result.json', 'w'))\n",
    "coco_dets = handle.loadRes('./external/result.json')\n",
    "coco_eval = COCOeval(handle, coco_dets, \"bbox\")\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_detections[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "for orig_b, b in zip(orig_detections, detections):\n",
    "    diff = np.array(orig_b['bbox']) - np.array(b['bbox'])\n",
    "    print(diff)\n",
    "    if diff.sum() > 0:\n",
    "        print(orig_b)\n",
    "        print(b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = batch['img_id'][0].item()\n",
    "handle = loader[branch].dataset.coco[0]\n",
    "fname = handle.loadImgs(ids=[img_id])[0]['file_name']\n",
    "fname = os.path.join(cfg.DB.PATH, \"crowdhuman\", \"val2017\", fname)\n",
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np_img = (batch['inp']*255).squeeze().permute(1,2,0).numpy().astype(np.uint8)\n",
    "np_img = cv2.imread(fname)\n",
    "num = 0\n",
    "for c in dets_out[0]:\n",
    "    for b in dets_out[0][c]:\n",
    "        x1, y1, x2, y2, score = b\n",
    "        if score > 0.5:\n",
    "            print(x1, y1, x2, y2)\n",
    "            num += 1\n",
    "            cv2.rectangle(np_img, (int(x1), int(y1)), (int(x2), int(y2)), (255,255,0), 2)\n",
    "pil_img = Image.fromarray(np_img)\n",
    "w, h = pil_img.size\n",
    "# print(num)\n",
    "pil_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _coco_box_to_bbox(box):\n",
    "    bbox = np.array([box[0], box[1], box[0] + box[2], box[1] + box[3]], dtype=np.float32)\n",
    "    return bbox\n",
    "ann_ids = handle.getAnnIds(imgIds=[img_id])\n",
    "anns = handle.loadAnns(ids=ann_ids)\n",
    "num_objs = len(anns)\n",
    "src_bboxes = []\n",
    "for k in range(num_objs):\n",
    "    ann = anns[k]\n",
    "    src_bboxes.append(_coco_box_to_bbox(ann['bbox']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np_img = cv2.imread(fname)\n",
    "for b in src_bboxes:\n",
    "    x1, y1, x2, y2 = b\n",
    "    cv2.rectangle(np_img, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 2)\n",
    "Image.fromarray(np_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = f\"/media/allen/mass/deep-learning-works/evaluation/caltech cityperson cityperson/Hourglass-coco_cityperson_caltech-person-focal_l1-SGDW_cosine_lr_0.01_warmup-scratch/000-2020-04-16_10-03/results.json\"\n",
    "f = open(src, 'r')\n",
    "results = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []\n",
    "for result in results:\n",
    "    if result['score'] > 0.5:\n",
    "        final.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 10\n",
    "img_id = final[idx]['image_id']\n",
    "handle = loader[branch].dataset.coco[0]\n",
    "fname = handle.loadImgs(ids=[img_id])[0]['file_name']\n",
    "fname = os.path.join(cfg.DB.PATH, \"cityperson\", \"val2017\", fname)\n",
    "np_img = cv2.imread(fname)\n",
    "x1, y1, w, h = final[idx]['bbox']\n",
    "cv2.rectangle(np_img, (int(x1), int(y1)), (int(x1+w), int(y1+h)), (255,255,0), 2)\n",
    "x1, y1, w, h = detections[idx+3]['bbox']\n",
    "cv2.rectangle(np_img, (int(x1), int(y1)), (int(x1+w), int(y1+h)), (0,0,255), 2)\n",
    "Image.fromarray(np_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = loader[branch].dataset.coco[0]\n",
    "image_ids = handle.getImgIds()\n",
    "detections = []\n",
    "for img_id in image_ids:\n",
    "    ann_ids = handle.getAnnIds(imgIds=[img_id])\n",
    "    anns = handle.loadAnns(ids=ann_ids)\n",
    "    for ann in anns:\n",
    "        detection = {\n",
    "            \"image_id\": int(img_id),\n",
    "            \"category_id\": int(ann['category_id']),\n",
    "            \"bbox\": ann['bbox'],\n",
    "            \"score\": 1.0,\n",
    "            'id': int(ann['id'])\n",
    "        }\n",
    "        detections.append(detection)\n",
    "    # breakhandle = loader[branch].dataset.coco[0]\n",
    "# json.dump(detections, open('./external/results.json', 'w'))\n",
    "# coco_dets = handle.loadRes('./external/results.json')\n",
    "# coco_eval = COCOeval(handle, coco_dets, \"bbox\")\n",
    "# coco_eval.evaluate()\n",
    "# coco_eval.accumulate()\n",
    "# coco_eval.summarize()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(orig_detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = loader[branch].dataset.coco[0]\n",
    "json.dump(detections, open('./external/results.json', 'w'))\n",
    "coco_dets = handle.loadRes('./external/results.json')\n",
    "coco_eval = COCOeval(handle, coco_dets, \"bbox\")\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python361064bitedd738739abd4206b026637a39f9f4cc",
   "display_name": "Python 3.6.10 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}