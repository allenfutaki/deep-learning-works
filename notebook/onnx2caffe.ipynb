{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36864bitpy368venv9eae5ffd70f44f51af3a8f637c7407e2",
   "display_name": "Python 3.6.8 64-bit ('py368': venv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir(\"../\")\n",
    "from src.model.backbone.osnet import osnet\n",
    "from src.model.backbone.osnet_deep_reid_iap import osnet_iap_x1_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ing=(1, 1), groups=96, bias=False)\n        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n    (1): DropChannel()\n    (2): InversedDepthwiseSeparable(\n      (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n  )\n  (conv2c): Sequential(\n    (0): InversedDepthwiseSeparable(\n      (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n    (1): DropChannel()\n    (2): InversedDepthwiseSeparable(\n      (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n    (3): DropChannel()\n    (4): InversedDepthwiseSeparable(\n      (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n  )\n  (conv2d): Sequential(\n    (0): InversedDepthwiseSeparable(\n      (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n    (1): DropChannel()\n    (2): InversedDepthwiseSeparable(\n      (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n    (3): DropChannel()\n    (4): InversedDepthwiseSeparable(\n      (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n    (5): DropChannel()\n    (6): InversedDepthwiseSeparable(\n      (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n  )\n  (gate): SEModule(\n    (se): Sequential(\n      (0): AdaptiveAvgPool2d(output_size=1)\n      (1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (3): ReLU(inplace=True)\n      (4): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n  )\n  (conv3): ConvModule(\n    (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (relu): ReLU(inplace=True)\n), Sequential(\n  (0): ConvModule(\n    (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (activation): ReLU(inplace=True)\n  )\n  (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n)]\n1\n1\n1\n[OSBlock(\n  (conv1): ConvModule(\n    (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (activation): ReLU(inplace=True)\n  )\n  (conv2a): InversedDepthwiseSeparable(\n    (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (conv2): ConvModule(\n      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (activation): ReLU(inplace=True)\n    )\n  )\n  (conv2b): Sequential(\n    (0): InversedDepthwiseSeparable(\n      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n    (1): DropChannel()\n    (2): InversedDepthwiseSeparable(\n      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n  )\n  (conv2c): Sequential(\n    (0): InversedDepthwiseSeparable(\n      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n    (1): DropChannel()\n    (2): InversedDepthwiseSeparable(\n      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n    (3): DropChannel()\n    (4): InversedDepthwiseSeparable(\n      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n  )\n  (conv2d): Sequential(\n    (0): InversedDepthwiseSeparable(\n      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n    (1): DropChannel()\n    (2): InversedDepthwiseSeparable(\n      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n    (3): DropChannel()\n    (4): InversedDepthwiseSeparable(\n      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n    (5): DropChannel()\n    (6): InversedDepthwiseSeparable(\n      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n  )\n  (gate): SEModule(\n    (se): Sequential(\n      (0): AdaptiveAvgPool2d(output_size=1)\n      (1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (3): ReLU(inplace=True)\n      (4): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n  )\n  (conv3): ConvModule(\n    (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (downsample): ConvModule(\n    (conv): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (relu): ReLU(inplace=True)\n), OSBlock(\n  (conv1): ConvModule(\n    (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (activation): ReLU(inplace=True)\n  )\n  (conv2a): InversedDepthwiseSeparable(\n    (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (conv2): ConvModule(\n      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (activation): ReLU(inplace=True)\n    )\n  )\n  (conv2b): Sequential(\n    (0): InversedDepthwiseSeparable(\n      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n    (1): DropChannel()\n    (2): InversedDepthwiseSeparable(\n      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n  )\n  (conv2c): Sequential(\n    (0): InversedDepthwiseSeparable(\n      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n    (1): DropChannel()\n    (2): InversedDepthwiseSeparable(\n      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n    (3): DropChannel()\n    (4): InversedDepthwiseSeparable(\n      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n  )\n  (conv2d): Sequential(\n    (0): InversedDepthwiseSeparable(\n      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n    (1): DropChannel()\n    (2): InversedDepthwiseSeparable(\n      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n    (3): DropChannel()\n    (4): InversedDepthwiseSeparable(\n      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n    (5): DropChannel()\n    (6): InversedDepthwiseSeparable(\n      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n  )\n  (gate): SEModule(\n    (se): Sequential(\n      (0): AdaptiveAvgPool2d(output_size=1)\n      (1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (3): ReLU(inplace=True)\n      (4): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n  )\n  (conv3): ConvModule(\n    (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (relu): ReLU(inplace=True)\n), OSBlock(\n  (conv1): ConvModule(\n    (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (activation): ReLU(inplace=True)\n  )\n  (conv2a): InversedDepthwiseSeparable(\n    (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (conv2): ConvModule(\n      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (activation): ReLU(inplace=True)\n    )\n  )\n  (conv2b): Sequential(\n    (0): InversedDepthwiseSeparable(\n      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n    (1): DropChannel()\n    (2): InversedDepthwiseSeparable(\n      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n  )\n  (conv2c): Sequential(\n    (0): InversedDepthwiseSeparable(\n      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n    (1): DropChannel()\n    (2): InversedDepthwiseSeparable(\n      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n    (3): DropChannel()\n    (4): InversedDepthwiseSeparable(\n      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n  )\n  (conv2d): Sequential(\n    (0): InversedDepthwiseSeparable(\n      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n    (1): DropChannel()\n    (2): InversedDepthwiseSeparable(\n      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n    (3): DropChannel()\n    (4): InversedDepthwiseSeparable(\n      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n    (5): DropChannel()\n    (6): InversedDepthwiseSeparable(\n      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (conv2): ConvModule(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activation): ReLU(inplace=True)\n      )\n    )\n  )\n  (gate): SEModule(\n    (se): Sequential(\n      (0): AdaptiveAvgPool2d(output_size=1)\n      (1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (3): ReLU(inplace=True)\n      (4): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n  )\n  (conv3): ConvModule(\n    (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (relu): ReLU(inplace=True)\n), ConvModule(\n  (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (activation): ReLU(inplace=True)\n)]\n"
    }
   ],
   "source": [
    "src_model = osnet_iap_x1_0()\n",
    "trt_model = osnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_n = []\n",
    "for n, p in trt_model.named_parameters():\n",
    "    trt_n.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_n = []\n",
    "for n, p in src_model.named_parameters():\n",
    "    src_n.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['in_first.weight',\n 'in_first.bias',\n 'conv1.conv.weight',\n 'conv1.bn.weight',\n 'conv1.bn.bias',\n 'conv2.0.conv1.conv.weight',\n 'conv2.0.conv1.bn.weight',\n 'conv2.0.conv1.bn.bias',\n 'conv2.0.conv2a.conv1.weight',\n 'conv2.0.conv2a.conv2.weight',\n 'conv2.0.conv2a.bn.weight',\n 'conv2.0.conv2a.bn.bias',\n 'conv2.0.conv2b.0.conv1.weight',\n 'conv2.0.conv2b.0.conv2.weight',\n 'conv2.0.conv2b.0.bn.weight',\n 'conv2.0.conv2b.0.bn.bias',\n 'conv2.0.conv2b.1.conv1.weight',\n 'conv2.0.conv2b.1.conv2.weight',\n 'conv2.0.conv2b.1.bn.weight',\n 'conv2.0.conv2b.1.bn.bias',\n 'conv2.0.conv2c.0.conv1.weight',\n 'conv2.0.conv2c.0.conv2.weight',\n 'conv2.0.conv2c.0.bn.weight',\n 'conv2.0.conv2c.0.bn.bias',\n 'conv2.0.conv2c.1.conv1.weight',\n 'conv2.0.conv2c.1.conv2.weight',\n 'conv2.0.conv2c.1.bn.weight',\n 'conv2.0.conv2c.1.bn.bias',\n 'conv2.0.conv2c.2.conv1.weight',\n 'conv2.0.conv2c.2.conv2.weight',\n 'conv2.0.conv2c.2.bn.weight',\n 'conv2.0.conv2c.2.bn.bias',\n 'conv2.0.conv2d.0.conv1.weight',\n 'conv2.0.conv2d.0.conv2.weight',\n 'conv2.0.conv2d.0.bn.weight',\n 'conv2.0.conv2d.0.bn.bias',\n 'conv2.0.conv2d.1.conv1.weight',\n 'conv2.0.conv2d.1.conv2.weight',\n 'conv2.0.conv2d.1.bn.weight',\n 'conv2.0.conv2d.1.bn.bias',\n 'conv2.0.conv2d.2.conv1.weight',\n 'conv2.0.conv2d.2.conv2.weight',\n 'conv2.0.conv2d.2.bn.weight',\n 'conv2.0.conv2d.2.bn.bias',\n 'conv2.0.conv2d.3.conv1.weight',\n 'conv2.0.conv2d.3.conv2.weight',\n 'conv2.0.conv2d.3.bn.weight',\n 'conv2.0.conv2d.3.bn.bias',\n 'conv2.0.gate.fc1.weight',\n 'conv2.0.gate.fc1.bias',\n 'conv2.0.gate.fc2.weight',\n 'conv2.0.gate.fc2.bias',\n 'conv2.0.conv3.conv.weight',\n 'conv2.0.conv3.bn.weight',\n 'conv2.0.conv3.bn.bias',\n 'conv2.0.downsample.conv.weight',\n 'conv2.0.downsample.bn.weight',\n 'conv2.0.downsample.bn.bias',\n 'conv2.1.conv1.conv.weight',\n 'conv2.1.conv1.bn.weight',\n 'conv2.1.conv1.bn.bias',\n 'conv2.1.conv2a.conv1.weight',\n 'conv2.1.conv2a.conv2.weight',\n 'conv2.1.conv2a.bn.weight',\n 'conv2.1.conv2a.bn.bias',\n 'conv2.1.conv2b.0.conv1.weight',\n 'conv2.1.conv2b.0.conv2.weight',\n 'conv2.1.conv2b.0.bn.weight',\n 'conv2.1.conv2b.0.bn.bias',\n 'conv2.1.conv2b.1.conv1.weight',\n 'conv2.1.conv2b.1.conv2.weight',\n 'conv2.1.conv2b.1.bn.weight',\n 'conv2.1.conv2b.1.bn.bias',\n 'conv2.1.conv2c.0.conv1.weight',\n 'conv2.1.conv2c.0.conv2.weight',\n 'conv2.1.conv2c.0.bn.weight',\n 'conv2.1.conv2c.0.bn.bias',\n 'conv2.1.conv2c.1.conv1.weight',\n 'conv2.1.conv2c.1.conv2.weight',\n 'conv2.1.conv2c.1.bn.weight',\n 'conv2.1.conv2c.1.bn.bias',\n 'conv2.1.conv2c.2.conv1.weight',\n 'conv2.1.conv2c.2.conv2.weight',\n 'conv2.1.conv2c.2.bn.weight',\n 'conv2.1.conv2c.2.bn.bias',\n 'conv2.1.conv2d.0.conv1.weight',\n 'conv2.1.conv2d.0.conv2.weight',\n 'conv2.1.conv2d.0.bn.weight',\n 'conv2.1.conv2d.0.bn.bias',\n 'conv2.1.conv2d.1.conv1.weight',\n 'conv2.1.conv2d.1.conv2.weight',\n 'conv2.1.conv2d.1.bn.weight',\n 'conv2.1.conv2d.1.bn.bias',\n 'conv2.1.conv2d.2.conv1.weight',\n 'conv2.1.conv2d.2.conv2.weight',\n 'conv2.1.conv2d.2.bn.weight',\n 'conv2.1.conv2d.2.bn.bias',\n 'conv2.1.conv2d.3.conv1.weight',\n 'conv2.1.conv2d.3.conv2.weight',\n 'conv2.1.conv2d.3.bn.weight',\n 'conv2.1.conv2d.3.bn.bias',\n 'conv2.1.gate.fc1.weight',\n 'conv2.1.gate.fc1.bias',\n 'conv2.1.gate.fc2.weight',\n 'conv2.1.gate.fc2.bias',\n 'conv2.1.conv3.conv.weight',\n 'conv2.1.conv3.bn.weight',\n 'conv2.1.conv3.bn.bias',\n 'conv2.2.0.conv.weight',\n 'conv2.2.0.bn.weight',\n 'conv2.2.0.bn.bias',\n 'conv3.0.conv1.conv.weight',\n 'conv3.0.conv1.bn.weight',\n 'conv3.0.conv1.bn.bias',\n 'conv3.0.conv2a.conv1.weight',\n 'conv3.0.conv2a.conv2.weight',\n 'conv3.0.conv2a.bn.weight',\n 'conv3.0.conv2a.bn.bias',\n 'conv3.0.conv2b.0.conv1.weight',\n 'conv3.0.conv2b.0.conv2.weight',\n 'conv3.0.conv2b.0.bn.weight',\n 'conv3.0.conv2b.0.bn.bias',\n 'conv3.0.conv2b.1.conv1.weight',\n 'conv3.0.conv2b.1.conv2.weight',\n 'conv3.0.conv2b.1.bn.weight',\n 'conv3.0.conv2b.1.bn.bias',\n 'conv3.0.conv2c.0.conv1.weight',\n 'conv3.0.conv2c.0.conv2.weight',\n 'conv3.0.conv2c.0.bn.weight',\n 'conv3.0.conv2c.0.bn.bias',\n 'conv3.0.conv2c.1.conv1.weight',\n 'conv3.0.conv2c.1.conv2.weight',\n 'conv3.0.conv2c.1.bn.weight',\n 'conv3.0.conv2c.1.bn.bias',\n 'conv3.0.conv2c.2.conv1.weight',\n 'conv3.0.conv2c.2.conv2.weight',\n 'conv3.0.conv2c.2.bn.weight',\n 'conv3.0.conv2c.2.bn.bias',\n 'conv3.0.conv2d.0.conv1.weight',\n 'conv3.0.conv2d.0.conv2.weight',\n 'conv3.0.conv2d.0.bn.weight',\n 'conv3.0.conv2d.0.bn.bias',\n 'conv3.0.conv2d.1.conv1.weight',\n 'conv3.0.conv2d.1.conv2.weight',\n 'conv3.0.conv2d.1.bn.weight',\n 'conv3.0.conv2d.1.bn.bias',\n 'conv3.0.conv2d.2.conv1.weight',\n 'conv3.0.conv2d.2.conv2.weight',\n 'conv3.0.conv2d.2.bn.weight',\n 'conv3.0.conv2d.2.bn.bias',\n 'conv3.0.conv2d.3.conv1.weight',\n 'conv3.0.conv2d.3.conv2.weight',\n 'conv3.0.conv2d.3.bn.weight',\n 'conv3.0.conv2d.3.bn.bias',\n 'conv3.0.gate.fc1.weight',\n 'conv3.0.gate.fc1.bias',\n 'conv3.0.gate.fc2.weight',\n 'conv3.0.gate.fc2.bias',\n 'conv3.0.conv3.conv.weight',\n 'conv3.0.conv3.bn.weight',\n 'conv3.0.conv3.bn.bias',\n 'conv3.0.downsample.conv.weight',\n 'conv3.0.downsample.bn.weight',\n 'conv3.0.downsample.bn.bias',\n 'conv3.1.conv1.conv.weight',\n 'conv3.1.conv1.bn.weight',\n 'conv3.1.conv1.bn.bias',\n 'conv3.1.conv2a.conv1.weight',\n 'conv3.1.conv2a.conv2.weight',\n 'conv3.1.conv2a.bn.weight',\n 'conv3.1.conv2a.bn.bias',\n 'conv3.1.conv2b.0.conv1.weight',\n 'conv3.1.conv2b.0.conv2.weight',\n 'conv3.1.conv2b.0.bn.weight',\n 'conv3.1.conv2b.0.bn.bias',\n 'conv3.1.conv2b.1.conv1.weight',\n 'conv3.1.conv2b.1.conv2.weight',\n 'conv3.1.conv2b.1.bn.weight',\n 'conv3.1.conv2b.1.bn.bias',\n 'conv3.1.conv2c.0.conv1.weight',\n 'conv3.1.conv2c.0.conv2.weight',\n 'conv3.1.conv2c.0.bn.weight',\n 'conv3.1.conv2c.0.bn.bias',\n 'conv3.1.conv2c.1.conv1.weight',\n 'conv3.1.conv2c.1.conv2.weight',\n 'conv3.1.conv2c.1.bn.weight',\n 'conv3.1.conv2c.1.bn.bias',\n 'conv3.1.conv2c.2.conv1.weight',\n 'conv3.1.conv2c.2.conv2.weight',\n 'conv3.1.conv2c.2.bn.weight',\n 'conv3.1.conv2c.2.bn.bias',\n 'conv3.1.conv2d.0.conv1.weight',\n 'conv3.1.conv2d.0.conv2.weight',\n 'conv3.1.conv2d.0.bn.weight',\n 'conv3.1.conv2d.0.bn.bias',\n 'conv3.1.conv2d.1.conv1.weight',\n 'conv3.1.conv2d.1.conv2.weight',\n 'conv3.1.conv2d.1.bn.weight',\n 'conv3.1.conv2d.1.bn.bias',\n 'conv3.1.conv2d.2.conv1.weight',\n 'conv3.1.conv2d.2.conv2.weight',\n 'conv3.1.conv2d.2.bn.weight',\n 'conv3.1.conv2d.2.bn.bias',\n 'conv3.1.conv2d.3.conv1.weight',\n 'conv3.1.conv2d.3.conv2.weight',\n 'conv3.1.conv2d.3.bn.weight',\n 'conv3.1.conv2d.3.bn.bias',\n 'conv3.1.gate.fc1.weight',\n 'conv3.1.gate.fc1.bias',\n 'conv3.1.gate.fc2.weight',\n 'conv3.1.gate.fc2.bias',\n 'conv3.1.conv3.conv.weight',\n 'conv3.1.conv3.bn.weight',\n 'conv3.1.conv3.bn.bias',\n 'conv3.2.0.conv.weight',\n 'conv3.2.0.bn.weight',\n 'conv3.2.0.bn.bias',\n 'conv4.0.conv1.conv.weight',\n 'conv4.0.conv1.bn.weight',\n 'conv4.0.conv1.bn.bias',\n 'conv4.0.conv2a.conv1.weight',\n 'conv4.0.conv2a.conv2.weight',\n 'conv4.0.conv2a.bn.weight',\n 'conv4.0.conv2a.bn.bias',\n 'conv4.0.conv2b.0.conv1.weight',\n 'conv4.0.conv2b.0.conv2.weight',\n 'conv4.0.conv2b.0.bn.weight',\n 'conv4.0.conv2b.0.bn.bias',\n 'conv4.0.conv2b.1.conv1.weight',\n 'conv4.0.conv2b.1.conv2.weight',\n 'conv4.0.conv2b.1.bn.weight',\n 'conv4.0.conv2b.1.bn.bias',\n 'conv4.0.conv2c.0.conv1.weight',\n 'conv4.0.conv2c.0.conv2.weight',\n 'conv4.0.conv2c.0.bn.weight',\n 'conv4.0.conv2c.0.bn.bias',\n 'conv4.0.conv2c.1.conv1.weight',\n 'conv4.0.conv2c.1.conv2.weight',\n 'conv4.0.conv2c.1.bn.weight',\n 'conv4.0.conv2c.1.bn.bias',\n 'conv4.0.conv2c.2.conv1.weight',\n 'conv4.0.conv2c.2.conv2.weight',\n 'conv4.0.conv2c.2.bn.weight',\n 'conv4.0.conv2c.2.bn.bias',\n 'conv4.0.conv2d.0.conv1.weight',\n 'conv4.0.conv2d.0.conv2.weight',\n 'conv4.0.conv2d.0.bn.weight',\n 'conv4.0.conv2d.0.bn.bias',\n 'conv4.0.conv2d.1.conv1.weight',\n 'conv4.0.conv2d.1.conv2.weight',\n 'conv4.0.conv2d.1.bn.weight',\n 'conv4.0.conv2d.1.bn.bias',\n 'conv4.0.conv2d.2.conv1.weight',\n 'conv4.0.conv2d.2.conv2.weight',\n 'conv4.0.conv2d.2.bn.weight',\n 'conv4.0.conv2d.2.bn.bias',\n 'conv4.0.conv2d.3.conv1.weight',\n 'conv4.0.conv2d.3.conv2.weight',\n 'conv4.0.conv2d.3.bn.weight',\n 'conv4.0.conv2d.3.bn.bias',\n 'conv4.0.gate.fc1.weight',\n 'conv4.0.gate.fc1.bias',\n 'conv4.0.gate.fc2.weight',\n 'conv4.0.gate.fc2.bias',\n 'conv4.0.conv3.conv.weight',\n 'conv4.0.conv3.bn.weight',\n 'conv4.0.conv3.bn.bias',\n 'conv4.0.downsample.conv.weight',\n 'conv4.0.downsample.bn.weight',\n 'conv4.0.downsample.bn.bias',\n 'conv4.1.conv1.conv.weight',\n 'conv4.1.conv1.bn.weight',\n 'conv4.1.conv1.bn.bias',\n 'conv4.1.conv2a.conv1.weight',\n 'conv4.1.conv2a.conv2.weight',\n 'conv4.1.conv2a.bn.weight',\n 'conv4.1.conv2a.bn.bias',\n 'conv4.1.conv2b.0.conv1.weight',\n 'conv4.1.conv2b.0.conv2.weight',\n 'conv4.1.conv2b.0.bn.weight',\n 'conv4.1.conv2b.0.bn.bias',\n 'conv4.1.conv2b.1.conv1.weight',\n 'conv4.1.conv2b.1.conv2.weight',\n 'conv4.1.conv2b.1.bn.weight',\n 'conv4.1.conv2b.1.bn.bias',\n 'conv4.1.conv2c.0.conv1.weight',\n 'conv4.1.conv2c.0.conv2.weight',\n 'conv4.1.conv2c.0.bn.weight',\n 'conv4.1.conv2c.0.bn.bias',\n 'conv4.1.conv2c.1.conv1.weight',\n 'conv4.1.conv2c.1.conv2.weight',\n 'conv4.1.conv2c.1.bn.weight',\n 'conv4.1.conv2c.1.bn.bias',\n 'conv4.1.conv2c.2.conv1.weight',\n 'conv4.1.conv2c.2.conv2.weight',\n 'conv4.1.conv2c.2.bn.weight',\n 'conv4.1.conv2c.2.bn.bias',\n 'conv4.1.conv2d.0.conv1.weight',\n 'conv4.1.conv2d.0.conv2.weight',\n 'conv4.1.conv2d.0.bn.weight',\n 'conv4.1.conv2d.0.bn.bias',\n 'conv4.1.conv2d.1.conv1.weight',\n 'conv4.1.conv2d.1.conv2.weight',\n 'conv4.1.conv2d.1.bn.weight',\n 'conv4.1.conv2d.1.bn.bias',\n 'conv4.1.conv2d.2.conv1.weight',\n 'conv4.1.conv2d.2.conv2.weight',\n 'conv4.1.conv2d.2.bn.weight',\n 'conv4.1.conv2d.2.bn.bias',\n 'conv4.1.conv2d.3.conv1.weight',\n 'conv4.1.conv2d.3.conv2.weight',\n 'conv4.1.conv2d.3.bn.weight',\n 'conv4.1.conv2d.3.bn.bias',\n 'conv4.1.gate.fc1.weight',\n 'conv4.1.gate.fc1.bias',\n 'conv4.1.gate.fc2.weight',\n 'conv4.1.gate.fc2.bias',\n 'conv4.1.conv3.conv.weight',\n 'conv4.1.conv3.bn.weight',\n 'conv4.1.conv3.bn.bias',\n 'conv5.conv.weight',\n 'conv5.bn.weight',\n 'conv5.bn.bias']"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "src_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['stem.stem.0.weight',\n 'stem.stem.0.bias',\n 'stem.stem.1.weight',\n 'stem.stem.1.bias',\n 'stem.stem.2.weight',\n 'stem.stem.2.bias',\n 'stages.0.0.conv1.conv.weight',\n 'stages.0.0.conv1.bn.weight',\n 'stages.0.0.conv1.bn.bias',\n 'stages.0.0.conv2a.conv1.weight',\n 'stages.0.0.conv2a.conv2.conv.weight',\n 'stages.0.0.conv2a.conv2.bn.weight',\n 'stages.0.0.conv2a.conv2.bn.bias',\n 'stages.0.0.conv2b.0.conv1.weight',\n 'stages.0.0.conv2b.0.conv2.conv.weight',\n 'stages.0.0.conv2b.0.conv2.bn.weight',\n 'stages.0.0.conv2b.0.conv2.bn.bias',\n 'stages.0.0.conv2b.2.conv1.weight',\n 'stages.0.0.conv2b.2.conv2.conv.weight',\n 'stages.0.0.conv2b.2.conv2.bn.weight',\n 'stages.0.0.conv2b.2.conv2.bn.bias',\n 'stages.0.0.conv2c.0.conv1.weight',\n 'stages.0.0.conv2c.0.conv2.conv.weight',\n 'stages.0.0.conv2c.0.conv2.bn.weight',\n 'stages.0.0.conv2c.0.conv2.bn.bias',\n 'stages.0.0.conv2c.2.conv1.weight',\n 'stages.0.0.conv2c.2.conv2.conv.weight',\n 'stages.0.0.conv2c.2.conv2.bn.weight',\n 'stages.0.0.conv2c.2.conv2.bn.bias',\n 'stages.0.0.conv2c.4.conv1.weight',\n 'stages.0.0.conv2c.4.conv2.conv.weight',\n 'stages.0.0.conv2c.4.conv2.bn.weight',\n 'stages.0.0.conv2c.4.conv2.bn.bias',\n 'stages.0.0.conv2d.0.conv1.weight',\n 'stages.0.0.conv2d.0.conv2.conv.weight',\n 'stages.0.0.conv2d.0.conv2.bn.weight',\n 'stages.0.0.conv2d.0.conv2.bn.bias',\n 'stages.0.0.conv2d.2.conv1.weight',\n 'stages.0.0.conv2d.2.conv2.conv.weight',\n 'stages.0.0.conv2d.2.conv2.bn.weight',\n 'stages.0.0.conv2d.2.conv2.bn.bias',\n 'stages.0.0.conv2d.4.conv1.weight',\n 'stages.0.0.conv2d.4.conv2.conv.weight',\n 'stages.0.0.conv2d.4.conv2.bn.weight',\n 'stages.0.0.conv2d.4.conv2.bn.bias',\n 'stages.0.0.conv2d.6.conv1.weight',\n 'stages.0.0.conv2d.6.conv2.conv.weight',\n 'stages.0.0.conv2d.6.conv2.bn.weight',\n 'stages.0.0.conv2d.6.conv2.bn.bias',\n 'stages.0.0.gate.se.1.weight',\n 'stages.0.0.gate.se.2.weight',\n 'stages.0.0.gate.se.2.bias',\n 'stages.0.0.gate.se.4.weight',\n 'stages.0.0.conv3.conv.weight',\n 'stages.0.0.conv3.bn.weight',\n 'stages.0.0.conv3.bn.bias',\n 'stages.0.0.downsample.conv.weight',\n 'stages.0.0.downsample.bn.weight',\n 'stages.0.0.downsample.bn.bias',\n 'stages.0.1.conv1.conv.weight',\n 'stages.0.1.conv1.bn.weight',\n 'stages.0.1.conv1.bn.bias',\n 'stages.0.1.conv2a.conv1.weight',\n 'stages.0.1.conv2a.conv2.conv.weight',\n 'stages.0.1.conv2a.conv2.bn.weight',\n 'stages.0.1.conv2a.conv2.bn.bias',\n 'stages.0.1.conv2b.0.conv1.weight',\n 'stages.0.1.conv2b.0.conv2.conv.weight',\n 'stages.0.1.conv2b.0.conv2.bn.weight',\n 'stages.0.1.conv2b.0.conv2.bn.bias',\n 'stages.0.1.conv2b.2.conv1.weight',\n 'stages.0.1.conv2b.2.conv2.conv.weight',\n 'stages.0.1.conv2b.2.conv2.bn.weight',\n 'stages.0.1.conv2b.2.conv2.bn.bias',\n 'stages.0.1.conv2c.0.conv1.weight',\n 'stages.0.1.conv2c.0.conv2.conv.weight',\n 'stages.0.1.conv2c.0.conv2.bn.weight',\n 'stages.0.1.conv2c.0.conv2.bn.bias',\n 'stages.0.1.conv2c.2.conv1.weight',\n 'stages.0.1.conv2c.2.conv2.conv.weight',\n 'stages.0.1.conv2c.2.conv2.bn.weight',\n 'stages.0.1.conv2c.2.conv2.bn.bias',\n 'stages.0.1.conv2c.4.conv1.weight',\n 'stages.0.1.conv2c.4.conv2.conv.weight',\n 'stages.0.1.conv2c.4.conv2.bn.weight',\n 'stages.0.1.conv2c.4.conv2.bn.bias',\n 'stages.0.1.conv2d.0.conv1.weight',\n 'stages.0.1.conv2d.0.conv2.conv.weight',\n 'stages.0.1.conv2d.0.conv2.bn.weight',\n 'stages.0.1.conv2d.0.conv2.bn.bias',\n 'stages.0.1.conv2d.2.conv1.weight',\n 'stages.0.1.conv2d.2.conv2.conv.weight',\n 'stages.0.1.conv2d.2.conv2.bn.weight',\n 'stages.0.1.conv2d.2.conv2.bn.bias',\n 'stages.0.1.conv2d.4.conv1.weight',\n 'stages.0.1.conv2d.4.conv2.conv.weight',\n 'stages.0.1.conv2d.4.conv2.bn.weight',\n 'stages.0.1.conv2d.4.conv2.bn.bias',\n 'stages.0.1.conv2d.6.conv1.weight',\n 'stages.0.1.conv2d.6.conv2.conv.weight',\n 'stages.0.1.conv2d.6.conv2.bn.weight',\n 'stages.0.1.conv2d.6.conv2.bn.bias',\n 'stages.0.1.gate.se.1.weight',\n 'stages.0.1.gate.se.2.weight',\n 'stages.0.1.gate.se.2.bias',\n 'stages.0.1.gate.se.4.weight',\n 'stages.0.1.conv3.conv.weight',\n 'stages.0.1.conv3.bn.weight',\n 'stages.0.1.conv3.bn.bias',\n 'stages.0.2.0.conv.weight',\n 'stages.0.2.0.bn.weight',\n 'stages.0.2.0.bn.bias',\n 'stages.1.0.conv1.conv.weight',\n 'stages.1.0.conv1.bn.weight',\n 'stages.1.0.conv1.bn.bias',\n 'stages.1.0.conv2a.conv1.weight',\n 'stages.1.0.conv2a.conv2.conv.weight',\n 'stages.1.0.conv2a.conv2.bn.weight',\n 'stages.1.0.conv2a.conv2.bn.bias',\n 'stages.1.0.conv2b.0.conv1.weight',\n 'stages.1.0.conv2b.0.conv2.conv.weight',\n 'stages.1.0.conv2b.0.conv2.bn.weight',\n 'stages.1.0.conv2b.0.conv2.bn.bias',\n 'stages.1.0.conv2b.2.conv1.weight',\n 'stages.1.0.conv2b.2.conv2.conv.weight',\n 'stages.1.0.conv2b.2.conv2.bn.weight',\n 'stages.1.0.conv2b.2.conv2.bn.bias',\n 'stages.1.0.conv2c.0.conv1.weight',\n 'stages.1.0.conv2c.0.conv2.conv.weight',\n 'stages.1.0.conv2c.0.conv2.bn.weight',\n 'stages.1.0.conv2c.0.conv2.bn.bias',\n 'stages.1.0.conv2c.2.conv1.weight',\n 'stages.1.0.conv2c.2.conv2.conv.weight',\n 'stages.1.0.conv2c.2.conv2.bn.weight',\n 'stages.1.0.conv2c.2.conv2.bn.bias',\n 'stages.1.0.conv2c.4.conv1.weight',\n 'stages.1.0.conv2c.4.conv2.conv.weight',\n 'stages.1.0.conv2c.4.conv2.bn.weight',\n 'stages.1.0.conv2c.4.conv2.bn.bias',\n 'stages.1.0.conv2d.0.conv1.weight',\n 'stages.1.0.conv2d.0.conv2.conv.weight',\n 'stages.1.0.conv2d.0.conv2.bn.weight',\n 'stages.1.0.conv2d.0.conv2.bn.bias',\n 'stages.1.0.conv2d.2.conv1.weight',\n 'stages.1.0.conv2d.2.conv2.conv.weight',\n 'stages.1.0.conv2d.2.conv2.bn.weight',\n 'stages.1.0.conv2d.2.conv2.bn.bias',\n 'stages.1.0.conv2d.4.conv1.weight',\n 'stages.1.0.conv2d.4.conv2.conv.weight',\n 'stages.1.0.conv2d.4.conv2.bn.weight',\n 'stages.1.0.conv2d.4.conv2.bn.bias',\n 'stages.1.0.conv2d.6.conv1.weight',\n 'stages.1.0.conv2d.6.conv2.conv.weight',\n 'stages.1.0.conv2d.6.conv2.bn.weight',\n 'stages.1.0.conv2d.6.conv2.bn.bias',\n 'stages.1.0.gate.se.1.weight',\n 'stages.1.0.gate.se.2.weight',\n 'stages.1.0.gate.se.2.bias',\n 'stages.1.0.gate.se.4.weight',\n 'stages.1.0.conv3.conv.weight',\n 'stages.1.0.conv3.bn.weight',\n 'stages.1.0.conv3.bn.bias',\n 'stages.1.0.downsample.conv.weight',\n 'stages.1.0.downsample.bn.weight',\n 'stages.1.0.downsample.bn.bias',\n 'stages.1.1.conv1.conv.weight',\n 'stages.1.1.conv1.bn.weight',\n 'stages.1.1.conv1.bn.bias',\n 'stages.1.1.conv2a.conv1.weight',\n 'stages.1.1.conv2a.conv2.conv.weight',\n 'stages.1.1.conv2a.conv2.bn.weight',\n 'stages.1.1.conv2a.conv2.bn.bias',\n 'stages.1.1.conv2b.0.conv1.weight',\n 'stages.1.1.conv2b.0.conv2.conv.weight',\n 'stages.1.1.conv2b.0.conv2.bn.weight',\n 'stages.1.1.conv2b.0.conv2.bn.bias',\n 'stages.1.1.conv2b.2.conv1.weight',\n 'stages.1.1.conv2b.2.conv2.conv.weight',\n 'stages.1.1.conv2b.2.conv2.bn.weight',\n 'stages.1.1.conv2b.2.conv2.bn.bias',\n 'stages.1.1.conv2c.0.conv1.weight',\n 'stages.1.1.conv2c.0.conv2.conv.weight',\n 'stages.1.1.conv2c.0.conv2.bn.weight',\n 'stages.1.1.conv2c.0.conv2.bn.bias',\n 'stages.1.1.conv2c.2.conv1.weight',\n 'stages.1.1.conv2c.2.conv2.conv.weight',\n 'stages.1.1.conv2c.2.conv2.bn.weight',\n 'stages.1.1.conv2c.2.conv2.bn.bias',\n 'stages.1.1.conv2c.4.conv1.weight',\n 'stages.1.1.conv2c.4.conv2.conv.weight',\n 'stages.1.1.conv2c.4.conv2.bn.weight',\n 'stages.1.1.conv2c.4.conv2.bn.bias',\n 'stages.1.1.conv2d.0.conv1.weight',\n 'stages.1.1.conv2d.0.conv2.conv.weight',\n 'stages.1.1.conv2d.0.conv2.bn.weight',\n 'stages.1.1.conv2d.0.conv2.bn.bias',\n 'stages.1.1.conv2d.2.conv1.weight',\n 'stages.1.1.conv2d.2.conv2.conv.weight',\n 'stages.1.1.conv2d.2.conv2.bn.weight',\n 'stages.1.1.conv2d.2.conv2.bn.bias',\n 'stages.1.1.conv2d.4.conv1.weight',\n 'stages.1.1.conv2d.4.conv2.conv.weight',\n 'stages.1.1.conv2d.4.conv2.bn.weight',\n 'stages.1.1.conv2d.4.conv2.bn.bias',\n 'stages.1.1.conv2d.6.conv1.weight',\n 'stages.1.1.conv2d.6.conv2.conv.weight',\n 'stages.1.1.conv2d.6.conv2.bn.weight',\n 'stages.1.1.conv2d.6.conv2.bn.bias',\n 'stages.1.1.gate.se.1.weight',\n 'stages.1.1.gate.se.2.weight',\n 'stages.1.1.gate.se.2.bias',\n 'stages.1.1.gate.se.4.weight',\n 'stages.1.1.conv3.conv.weight',\n 'stages.1.1.conv3.bn.weight',\n 'stages.1.1.conv3.bn.bias',\n 'stages.1.2.0.conv.weight',\n 'stages.1.2.0.bn.weight',\n 'stages.1.2.0.bn.bias',\n 'stages.2.0.conv1.conv.weight',\n 'stages.2.0.conv1.bn.weight',\n 'stages.2.0.conv1.bn.bias',\n 'stages.2.0.conv2a.conv1.weight',\n 'stages.2.0.conv2a.conv2.conv.weight',\n 'stages.2.0.conv2a.conv2.bn.weight',\n 'stages.2.0.conv2a.conv2.bn.bias',\n 'stages.2.0.conv2b.0.conv1.weight',\n 'stages.2.0.conv2b.0.conv2.conv.weight',\n 'stages.2.0.conv2b.0.conv2.bn.weight',\n 'stages.2.0.conv2b.0.conv2.bn.bias',\n 'stages.2.0.conv2b.2.conv1.weight',\n 'stages.2.0.conv2b.2.conv2.conv.weight',\n 'stages.2.0.conv2b.2.conv2.bn.weight',\n 'stages.2.0.conv2b.2.conv2.bn.bias',\n 'stages.2.0.conv2c.0.conv1.weight',\n 'stages.2.0.conv2c.0.conv2.conv.weight',\n 'stages.2.0.conv2c.0.conv2.bn.weight',\n 'stages.2.0.conv2c.0.conv2.bn.bias',\n 'stages.2.0.conv2c.2.conv1.weight',\n 'stages.2.0.conv2c.2.conv2.conv.weight',\n 'stages.2.0.conv2c.2.conv2.bn.weight',\n 'stages.2.0.conv2c.2.conv2.bn.bias',\n 'stages.2.0.conv2c.4.conv1.weight',\n 'stages.2.0.conv2c.4.conv2.conv.weight',\n 'stages.2.0.conv2c.4.conv2.bn.weight',\n 'stages.2.0.conv2c.4.conv2.bn.bias',\n 'stages.2.0.conv2d.0.conv1.weight',\n 'stages.2.0.conv2d.0.conv2.conv.weight',\n 'stages.2.0.conv2d.0.conv2.bn.weight',\n 'stages.2.0.conv2d.0.conv2.bn.bias',\n 'stages.2.0.conv2d.2.conv1.weight',\n 'stages.2.0.conv2d.2.conv2.conv.weight',\n 'stages.2.0.conv2d.2.conv2.bn.weight',\n 'stages.2.0.conv2d.2.conv2.bn.bias',\n 'stages.2.0.conv2d.4.conv1.weight',\n 'stages.2.0.conv2d.4.conv2.conv.weight',\n 'stages.2.0.conv2d.4.conv2.bn.weight',\n 'stages.2.0.conv2d.4.conv2.bn.bias',\n 'stages.2.0.conv2d.6.conv1.weight',\n 'stages.2.0.conv2d.6.conv2.conv.weight',\n 'stages.2.0.conv2d.6.conv2.bn.weight',\n 'stages.2.0.conv2d.6.conv2.bn.bias',\n 'stages.2.0.gate.se.1.weight',\n 'stages.2.0.gate.se.2.weight',\n 'stages.2.0.gate.se.2.bias',\n 'stages.2.0.gate.se.4.weight',\n 'stages.2.0.conv3.conv.weight',\n 'stages.2.0.conv3.bn.weight',\n 'stages.2.0.conv3.bn.bias',\n 'stages.2.0.downsample.conv.weight',\n 'stages.2.0.downsample.bn.weight',\n 'stages.2.0.downsample.bn.bias',\n 'stages.2.1.conv1.conv.weight',\n 'stages.2.1.conv1.bn.weight',\n 'stages.2.1.conv1.bn.bias',\n 'stages.2.1.conv2a.conv1.weight',\n 'stages.2.1.conv2a.conv2.conv.weight',\n 'stages.2.1.conv2a.conv2.bn.weight',\n 'stages.2.1.conv2a.conv2.bn.bias',\n 'stages.2.1.conv2b.0.conv1.weight',\n 'stages.2.1.conv2b.0.conv2.conv.weight',\n 'stages.2.1.conv2b.0.conv2.bn.weight',\n 'stages.2.1.conv2b.0.conv2.bn.bias',\n 'stages.2.1.conv2b.2.conv1.weight',\n 'stages.2.1.conv2b.2.conv2.conv.weight',\n 'stages.2.1.conv2b.2.conv2.bn.weight',\n 'stages.2.1.conv2b.2.conv2.bn.bias',\n 'stages.2.1.conv2c.0.conv1.weight',\n 'stages.2.1.conv2c.0.conv2.conv.weight',\n 'stages.2.1.conv2c.0.conv2.bn.weight',\n 'stages.2.1.conv2c.0.conv2.bn.bias',\n 'stages.2.1.conv2c.2.conv1.weight',\n 'stages.2.1.conv2c.2.conv2.conv.weight',\n 'stages.2.1.conv2c.2.conv2.bn.weight',\n 'stages.2.1.conv2c.2.conv2.bn.bias',\n 'stages.2.1.conv2c.4.conv1.weight',\n 'stages.2.1.conv2c.4.conv2.conv.weight',\n 'stages.2.1.conv2c.4.conv2.bn.weight',\n 'stages.2.1.conv2c.4.conv2.bn.bias',\n 'stages.2.1.conv2d.0.conv1.weight',\n 'stages.2.1.conv2d.0.conv2.conv.weight',\n 'stages.2.1.conv2d.0.conv2.bn.weight',\n 'stages.2.1.conv2d.0.conv2.bn.bias',\n 'stages.2.1.conv2d.2.conv1.weight',\n 'stages.2.1.conv2d.2.conv2.conv.weight',\n 'stages.2.1.conv2d.2.conv2.bn.weight',\n 'stages.2.1.conv2d.2.conv2.bn.bias',\n 'stages.2.1.conv2d.4.conv1.weight',\n 'stages.2.1.conv2d.4.conv2.conv.weight',\n 'stages.2.1.conv2d.4.conv2.bn.weight',\n 'stages.2.1.conv2d.4.conv2.bn.bias',\n 'stages.2.1.conv2d.6.conv1.weight',\n 'stages.2.1.conv2d.6.conv2.conv.weight',\n 'stages.2.1.conv2d.6.conv2.bn.weight',\n 'stages.2.1.conv2d.6.conv2.bn.bias',\n 'stages.2.1.gate.se.1.weight',\n 'stages.2.1.gate.se.2.weight',\n 'stages.2.1.gate.se.2.bias',\n 'stages.2.1.gate.se.4.weight',\n 'stages.2.1.conv3.conv.weight',\n 'stages.2.1.conv3.bn.weight',\n 'stages.2.1.conv3.bn.bias',\n 'stages.2.2.conv1.conv.weight',\n 'stages.2.2.conv1.bn.weight',\n 'stages.2.2.conv1.bn.bias',\n 'stages.2.2.conv2a.conv1.weight',\n 'stages.2.2.conv2a.conv2.conv.weight',\n 'stages.2.2.conv2a.conv2.bn.weight',\n 'stages.2.2.conv2a.conv2.bn.bias',\n 'stages.2.2.conv2b.0.conv1.weight',\n 'stages.2.2.conv2b.0.conv2.conv.weight',\n 'stages.2.2.conv2b.0.conv2.bn.weight',\n 'stages.2.2.conv2b.0.conv2.bn.bias',\n 'stages.2.2.conv2b.2.conv1.weight',\n 'stages.2.2.conv2b.2.conv2.conv.weight',\n 'stages.2.2.conv2b.2.conv2.bn.weight',\n 'stages.2.2.conv2b.2.conv2.bn.bias',\n 'stages.2.2.conv2c.0.conv1.weight',\n 'stages.2.2.conv2c.0.conv2.conv.weight',\n 'stages.2.2.conv2c.0.conv2.bn.weight',\n 'stages.2.2.conv2c.0.conv2.bn.bias',\n 'stages.2.2.conv2c.2.conv1.weight',\n 'stages.2.2.conv2c.2.conv2.conv.weight',\n 'stages.2.2.conv2c.2.conv2.bn.weight',\n 'stages.2.2.conv2c.2.conv2.bn.bias',\n 'stages.2.2.conv2c.4.conv1.weight',\n 'stages.2.2.conv2c.4.conv2.conv.weight',\n 'stages.2.2.conv2c.4.conv2.bn.weight',\n 'stages.2.2.conv2c.4.conv2.bn.bias',\n 'stages.2.2.conv2d.0.conv1.weight',\n 'stages.2.2.conv2d.0.conv2.conv.weight',\n 'stages.2.2.conv2d.0.conv2.bn.weight',\n 'stages.2.2.conv2d.0.conv2.bn.bias',\n 'stages.2.2.conv2d.2.conv1.weight',\n 'stages.2.2.conv2d.2.conv2.conv.weight',\n 'stages.2.2.conv2d.2.conv2.bn.weight',\n 'stages.2.2.conv2d.2.conv2.bn.bias',\n 'stages.2.2.conv2d.4.conv1.weight',\n 'stages.2.2.conv2d.4.conv2.conv.weight',\n 'stages.2.2.conv2d.4.conv2.bn.weight',\n 'stages.2.2.conv2d.4.conv2.bn.bias',\n 'stages.2.2.conv2d.6.conv1.weight',\n 'stages.2.2.conv2d.6.conv2.conv.weight',\n 'stages.2.2.conv2d.6.conv2.bn.weight',\n 'stages.2.2.conv2d.6.conv2.bn.bias',\n 'stages.2.2.gate.se.1.weight',\n 'stages.2.2.gate.se.2.weight',\n 'stages.2.2.gate.se.2.bias',\n 'stages.2.2.gate.se.4.weight',\n 'stages.2.2.conv3.conv.weight',\n 'stages.2.2.conv3.bn.weight',\n 'stages.2.2.conv3.bn.bias',\n 'stages.2.3.conv.weight',\n 'stages.2.3.bn.weight',\n 'stages.2.3.bn.bias']"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "trt_n"
   ]
  }
 ]
}