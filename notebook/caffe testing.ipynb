{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# caffe\n",
    "1. [dummy convolution](#dummy-conv-layer)\n",
    "1. [dummy depthwise](#dummy-depthwise-layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/allen/Documents/caffe/python\")\n",
    "import caffe\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caffe import layers as L\n",
    "from caffe import params as P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe_net = caffe.NetSpec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "caffe_net['data1'] = data1\n",
    "caffe_net['data2'] = data2\n",
    "caffe_net['data3'] = data3\n",
    "caffe_net['eltwise'] = elt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "layer {\n",
       "  name: \"data1\"\n",
       "  type: \"Input\"\n",
       "  top: \"data1\"\n",
       "  input_param {\n",
       "    shape {\n",
       "      dim: 1\n",
       "      dim: 3\n",
       "      dim: 112\n",
       "      dim: 112\n",
       "    }\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"data2\"\n",
       "  type: \"Input\"\n",
       "  top: \"data2\"\n",
       "  input_param {\n",
       "    shape {\n",
       "      dim: 1\n",
       "      dim: 3\n",
       "      dim: 112\n",
       "      dim: 112\n",
       "    }\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"data3\"\n",
       "  type: \"Input\"\n",
       "  top: \"data3\"\n",
       "  input_param {\n",
       "    shape {\n",
       "      dim: 1\n",
       "      dim: 3\n",
       "      dim: 112\n",
       "      dim: 112\n",
       "    }\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"eltwise\"\n",
       "  type: \"Eltwise\"\n",
       "  bottom: \"data1\"\n",
       "  bottom: \"data2\"\n",
       "  bottom: \"data3\"\n",
       "  top: \"eltwise\"\n",
       "  eltwise_param {\n",
       "    operation: SUM\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caffe_net.to_proto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = L.Input(shape=dict(dim=[1,3,112,112]))\n",
    "data2 = L.Input(shape=dict(dim=[1,3,112,112]))\n",
    "data3 = L.Input(shape=dict(dim=[1,3,112,112]))\n",
    "elt = L.Eltwise(data1, data2, data3, operation=P.Eltwise.SUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy=\"/home/allen/mobilenet_multitask_20190322.temp.cp.prototxt\"\n",
    "caffe_model='/home/allen/mobilenet_multitask_20190322.temp.caffemodel'\n",
    "net = caffe.Net(deploy,caffe_model,caffe.TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "_input = cv2.imread(path)\n",
    "_input = cv2.resize(_input,(112,112))\n",
    "_input = (_input/255.0 - 0.5)/0.5\n",
    "\n",
    "caffe_input = np.transpose(_input, (2,0,1))[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.45882353, -0.45882353, -0.46666667, ...,  0.00392157,\n",
       "           0.01176471,  0.02745098],\n",
       "         [-0.43529412, -0.44313725, -0.45098039, ...,  0.01176471,\n",
       "           0.00392157,  0.01960784],\n",
       "         [-0.42745098, -0.42745098, -0.43529412, ...,  0.00392157,\n",
       "           0.01176471,  0.02745098],\n",
       "         ...,\n",
       "         [-0.45098039, -0.44313725, -0.49019608, ...,  0.30980392,\n",
       "           0.30980392,  0.30980392],\n",
       "         [-0.45882353, -0.45098039, -0.52156863, ...,  0.30196078,\n",
       "           0.30196078,  0.30980392],\n",
       "         [-0.51372549, -0.52941176, -0.61568627, ...,  0.30196078,\n",
       "           0.30196078,  0.31764706]],\n",
       "\n",
       "        [[-0.46666667, -0.45882353, -0.45098039, ...,  0.04313725,\n",
       "           0.05098039,  0.06666667],\n",
       "         [-0.44313725, -0.44313725, -0.43529412, ...,  0.05098039,\n",
       "           0.04313725,  0.05882353],\n",
       "         [-0.43529412, -0.42745098, -0.42745098, ...,  0.04313725,\n",
       "           0.05098039,  0.06666667],\n",
       "         ...,\n",
       "         [-0.4745098 , -0.50588235, -0.55294118, ...,  0.30196078,\n",
       "           0.30196078,  0.29411765],\n",
       "         [-0.49019608, -0.51372549, -0.58431373, ...,  0.29411765,\n",
       "           0.29411765,  0.30196078],\n",
       "         [-0.54509804, -0.58431373, -0.67058824, ...,  0.29411765,\n",
       "           0.28627451,  0.29411765]],\n",
       "\n",
       "        [[-0.06666667, -0.05882353, -0.05882353, ..., -0.09019608,\n",
       "          -0.08235294, -0.06666667],\n",
       "         [-0.05098039, -0.05098039, -0.04313725, ..., -0.08235294,\n",
       "          -0.09019608, -0.0745098 ],\n",
       "         [-0.04313725, -0.04313725, -0.04313725, ..., -0.09019608,\n",
       "          -0.08235294, -0.06666667],\n",
       "         ...,\n",
       "         [-0.1372549 , -0.19215686, -0.27058824, ...,  0.10588235,\n",
       "           0.10588235,  0.09803922],\n",
       "         [-0.19215686, -0.2627451 , -0.36470588, ...,  0.09019608,\n",
       "           0.09019608,  0.09803922],\n",
       "         [-0.34117647, -0.45098039, -0.56078431, ...,  0.09803922,\n",
       "           0.08235294,  0.09803922]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(tf_input, (0,3,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.45882353, -0.45882353, -0.46666667, ...,  0.00392157,\n",
       "           0.01176471,  0.02745098],\n",
       "         [-0.43529412, -0.44313725, -0.45098039, ...,  0.01176471,\n",
       "           0.00392157,  0.01960784],\n",
       "         [-0.42745098, -0.42745098, -0.43529412, ...,  0.00392157,\n",
       "           0.01176471,  0.02745098],\n",
       "         ...,\n",
       "         [-0.45098039, -0.44313725, -0.49019608, ...,  0.30980392,\n",
       "           0.30980392,  0.30980392],\n",
       "         [-0.45882353, -0.45098039, -0.52156863, ...,  0.30196078,\n",
       "           0.30196078,  0.30980392],\n",
       "         [-0.51372549, -0.52941176, -0.61568627, ...,  0.30196078,\n",
       "           0.30196078,  0.31764706]],\n",
       "\n",
       "        [[-0.46666667, -0.45882353, -0.45098039, ...,  0.04313725,\n",
       "           0.05098039,  0.06666667],\n",
       "         [-0.44313725, -0.44313725, -0.43529412, ...,  0.05098039,\n",
       "           0.04313725,  0.05882353],\n",
       "         [-0.43529412, -0.42745098, -0.42745098, ...,  0.04313725,\n",
       "           0.05098039,  0.06666667],\n",
       "         ...,\n",
       "         [-0.4745098 , -0.50588235, -0.55294118, ...,  0.30196078,\n",
       "           0.30196078,  0.29411765],\n",
       "         [-0.49019608, -0.51372549, -0.58431373, ...,  0.29411765,\n",
       "           0.29411765,  0.30196078],\n",
       "         [-0.54509804, -0.58431373, -0.67058824, ...,  0.29411765,\n",
       "           0.28627451,  0.29411765]],\n",
       "\n",
       "        [[-0.06666667, -0.05882353, -0.05882353, ..., -0.09019608,\n",
       "          -0.08235294, -0.06666667],\n",
       "         [-0.05098039, -0.05098039, -0.04313725, ..., -0.08235294,\n",
       "          -0.09019608, -0.0745098 ],\n",
       "         [-0.04313725, -0.04313725, -0.04313725, ..., -0.09019608,\n",
       "          -0.08235294, -0.06666667],\n",
       "         ...,\n",
       "         [-0.1372549 , -0.19215686, -0.27058824, ...,  0.10588235,\n",
       "           0.10588235,  0.09803922],\n",
       "         [-0.19215686, -0.2627451 , -0.36470588, ...,  0.09019608,\n",
       "           0.09019608,  0.09803922],\n",
       "         [-0.34117647, -0.45098039, -0.56078431, ...,  0.09803922,\n",
       "           0.08235294,  0.09803922]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caffe_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net.blobs['blob1'].data[...] = caffe_input\n",
    "embedding = net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30726722]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding['sigmoid_prob1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.0569167 ,  2.2177708 , -2.0151384 ,  1.9262052 , -1.7954506 ,\n",
       "         1.7967215 , -1.5535408 ,  1.6716592 , -1.562477  ,  1.4859504 ,\n",
       "        -1.293287  ,  1.5827228 , -1.2759242 ,  1.4708483 , -1.59766   ,\n",
       "         1.1100159 , -1.2941504 ,  1.2946421 , -1.2329605 ,  1.3136355 ,\n",
       "        -1.2851585 ,  1.218411  , -1.1929178 ,  1.2144083 , -1.3668921 ,\n",
       "         0.8933704 , -0.88162947,  1.2286606 , -0.8739527 ,  0.9999685 ,\n",
       "        -0.66567105,  0.80061245, -0.40747237,  0.7218433 , -0.34840328,\n",
       "         0.44554165, -0.26410255,  0.26102898, -0.11449168,  0.13764828,\n",
       "        -0.0280425 , -0.08047274,  0.1399315 , -0.14167714,  0.43023863,\n",
       "        -0.02579966,  0.40510562, -0.30545947,  0.60345745, -0.46024734,\n",
       "         0.75440496, -0.4886549 ,  0.82801884, -0.6817773 ,  0.7985397 ,\n",
       "        -0.8874794 ,  0.92524827, -1.0285472 ,  1.1571255 , -1.0018244 ,\n",
       "         1.0471345 , -1.3038747 ,  1.4094805 , -1.0448556 ,  1.327141  ,\n",
       "        -1.2800848 ,  1.3011665 , -1.3201606 ,  1.30323   , -1.4191749 ,\n",
       "         1.2540274 , -1.6467342 ,  1.4962785 , -1.5649778 ,  1.4868946 ,\n",
       "        -1.7378058 ,  1.6288506 , -1.6823816 ,  1.6131401 , -1.8229735 ,\n",
       "         1.6917698 , -1.835057  ,  1.8163843 , -1.7482088 ,  1.7662911 ,\n",
       "        -1.9900308 ,  1.8222077 , -1.9890591 ,  1.876391  , -2.0148969 ,\n",
       "         1.8570168 , -2.055814  ,  1.9003212 , -2.1543927 ,  2.2076218 ,\n",
       "        -1.8675017 ,  1.9957285 , -1.9816486 ,  1.9248513 , -2.129606  ,\n",
       "         2.1747098 , -1.936261  ,  2.1996293 , -1.9770192 ,  1.8944501 ,\n",
       "        -2.3191144 ,  2.2763426 , -1.993063  ,  2.1435485 , -2.2678473 ,\n",
       "         2.107371  , -2.2423155 ,  2.275137  , -2.10815   ,  2.2970371 ,\n",
       "        -2.1279824 ,  2.1316125 , -2.3650193 ,  2.265845  , -2.2549388 ,\n",
       "         2.3210592 , -2.2682354 ,  2.2215893 , -2.4119341 ,  2.276884  ,\n",
       "        -2.2370558 ,  2.2095413 , -2.3844614 ,  2.213629  , -2.4963849 ,\n",
       "         2.3813403 , -2.271918  ,  2.3019085 , -2.3444633 ,  2.311157  ,\n",
       "        -2.3284836 ,  2.3808355 , -2.2174444 ,  2.515496  , -2.2585938 ,\n",
       "         2.503068  , -2.2449017 ,  2.174767  , -2.4429307 ,  2.3942237 ,\n",
       "        -2.370294  ,  2.3906288 , -2.3029726 ,  2.2960627 , -2.4540474 ,\n",
       "         2.298488  , -2.575812  ,  2.577418  , -2.234819  ,  2.5076287 ,\n",
       "        -2.3193336 ,  2.4887466 , -2.3268194 ,  2.2085052 , -2.5199661 ,\n",
       "         2.5202713 , -2.3444004 ,  2.553013  , -2.3764663 ,  2.5047948 ,\n",
       "        -2.3486526 ,  2.5760324 , -2.3150165 ,  2.3256292 , -2.514357  ,\n",
       "         2.1505654 , -2.483803  ,  2.490464  , -2.371918  ,  2.357741  ,\n",
       "        -2.4124706 ,  2.627774  , -2.3503845 ,  2.4993963 , -2.3435657 ,\n",
       "         2.202641  , -2.425965  ,  2.5632317 , -2.346458  ,  2.5112617 ,\n",
       "        -2.4547925 ,  2.4309764 , -2.4980433 ,  2.4541082 , -2.4083076 ,\n",
       "         2.5804667 , -2.2058773 ,  2.403318  , -2.392349  ,  2.2919378 ,\n",
       "        -2.5012515 ,  2.1823516 , -2.6557636 ,  2.2904165 , -2.5146449 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = net.blobs['fc_blob3'].data\n",
    "b = net.blobs['sigmoid_prob1'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30726722]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3072672078882084"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0 / (1 + math.exp(-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe_output = net.blobs['334'].data\n",
    "# normalized_out = out / np.linalg.norm(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trans_tf_output = np.transpose(tf_output, (0,3,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'caffe_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8c95ddf0cd56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcaffe_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'caffe_output' is not defined"
     ]
    }
   ],
   "source": [
    "caffe_output[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.2734248e-02, -1.3860692e-01, -1.3460992e-01, ...,\n",
       "         3.1584096e-01,  3.1197596e-01,  2.9990199e-01],\n",
       "       [-2.0925051e-02, -1.0163886e-01, -9.4726495e-02, ...,\n",
       "         2.8029236e-01,  2.4022545e-01,  1.9750033e-01],\n",
       "       [-1.6264418e-02, -8.5879825e-02, -9.2555188e-02, ...,\n",
       "         2.6499698e-01,  2.3532212e-01,  1.8790987e-01],\n",
       "       ...,\n",
       "       [-2.4213150e-04, -7.4104555e-03, -6.6696368e-03, ...,\n",
       "         1.5966980e-01,  1.3823235e-01,  1.2317617e-01],\n",
       "       [-8.5471844e-04, -2.8979240e-03,  7.8092641e-03, ...,\n",
       "         1.3362150e-01,  1.3228619e-01,  1.2900597e-01],\n",
       "       [ 1.1870424e-03,  2.6170681e-03,  2.8478617e-03, ...,\n",
       "         1.3213433e-01,  1.3156262e-01,  1.3363789e-01]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.flip(trans_tf_output)[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe_output = embedding / np.linalg.norm(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_tf_output = tf_output / np.linalg.norm(tf_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(caffe_output * normalized_tf_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0000004 , 0.7134838 , 0.68740374, 0.63135636, 0.31626278,\n",
       "       0.64604163, 0.3802653 , 0.4661587 , 0.35336965, 0.34694254,\n",
       "       0.5389409 , 0.38242942, 0.40371138, 0.32311618, 0.15025601,\n",
       "       0.3828416 , 0.26598275, 0.28421402, 0.52755284, 0.41375685],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = [os.path.join(root, f) for root, _, files in os.walk(\"/home/allen/Lennon_Lin/\") for f in files if 'jpg' in f or  'png' in f]\n",
    "embs = []\n",
    "for path in paths:   \n",
    "\n",
    "    _input = cv2.imread(path)\n",
    "    _input = cv2.resize(_input,(112,112))\n",
    "    _input = (_input/255.0 - 0.5)/0.5\n",
    "\n",
    "    caffe_input = np.transpose(_input, (2,0,1))[np.newaxis, :]\n",
    "    net.blobs['0'].data[...] = caffe_input\n",
    "    embedding = net.forward()['477'].copy()\n",
    "    embs.append(embedding)\n",
    "\n",
    "normalized_embs = []\n",
    "for i in embs:\n",
    "    normalized_embs.append(i / np.linalg.norm(i))\n",
    "\n",
    "normalized_embs_arr = np.array(normalized_embs).squeeze()\n",
    "\n",
    "np.matmul(normalized_embs_arr, normalized_embs_arr.transpose())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_output = np.load(\"/home/allen/00140_embedding.npy\")\n",
    "tflite_output = tflite_output[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03098539, -0.01920414, -0.06054536, -0.03239093, -0.03895952,\n",
       "         0.04260923, -0.00063052,  0.06049987,  0.02268264,  0.02008231,\n",
       "         0.03962162, -0.04164155, -0.02439435,  0.00142316, -0.0123225 ,\n",
       "         0.03314535, -0.0577183 , -0.05079812, -0.02055868,  0.01013203,\n",
       "        -0.00118758, -0.05671863, -0.0444616 , -0.01263302, -0.05209986,\n",
       "        -0.02911533,  0.02838958,  0.00202656, -0.01508614,  0.04455404,\n",
       "         0.03431712,  0.01210972, -0.00203951,  0.01067953,  0.03043412,\n",
       "        -0.01058405, -0.00432229, -0.06245269,  0.01691664,  0.02557359,\n",
       "        -0.01972048, -0.04603468,  0.03518996, -0.0583852 ,  0.02593375,\n",
       "        -0.00249705,  0.00986063, -0.00028198, -0.02440025,  0.051347  ,\n",
       "         0.01176422,  0.04838645,  0.01441191, -0.01849311,  0.02700114,\n",
       "         0.02861025,  0.03077151,  0.05156572, -0.06263892, -0.00825037,\n",
       "        -0.03154445,  0.03638807, -0.0037927 , -0.08963073, -0.02630693,\n",
       "         0.00249512,  0.07729867,  0.0175095 , -0.0604143 , -0.04987745,\n",
       "         0.02492247, -0.01532298, -0.11663409,  0.00329178, -0.02698101,\n",
       "        -0.01686494, -0.03693452,  0.02084984, -0.02125785, -0.02719909,\n",
       "        -0.08991934,  0.0288392 , -0.04785775,  0.02823348,  0.02926867,\n",
       "        -0.01726872,  0.03370061, -0.0144818 ,  0.02658802,  0.00211736,\n",
       "         0.04844458,  0.02056799,  0.07627754, -0.01004869, -0.06942157,\n",
       "        -0.00483809, -0.06445444,  0.05773909,  0.01325239,  0.02650869,\n",
       "         0.0139718 ,  0.0012375 , -0.02352813, -0.0055232 ,  0.00835209,\n",
       "        -0.05287865,  0.06144242, -0.07124362, -0.02470146, -0.00181502,\n",
       "        -0.02940272,  0.03110424, -0.02355209, -0.01262   , -0.10052264,\n",
       "        -0.04884896,  0.04324223,  0.01847942,  0.05710891,  0.01347885,\n",
       "         0.00437705, -0.08404985,  0.02087911,  0.05341523,  0.05469255,\n",
       "        -0.06554915, -0.00502863,  0.00545411, -0.03762081,  0.04475365,\n",
       "        -0.04585106,  0.00268263,  0.02410935, -0.01191822,  0.0314817 ,\n",
       "        -0.0402278 , -0.03393919, -0.00535291, -0.00134882, -0.03373117,\n",
       "        -0.0516148 ,  0.01241139,  0.01416895,  0.04210211,  0.06859708,\n",
       "        -0.01097925,  0.04263185,  0.00065794, -0.06347698,  0.05558591,\n",
       "         0.02848919,  0.01131456, -0.01277209,  0.01932624,  0.03457299,\n",
       "         0.07999847,  0.0173696 ,  0.02129853,  0.0555339 ,  0.01431334,\n",
       "         0.02791919,  0.10202125,  0.09028756, -0.03769683, -0.01710041,\n",
       "         0.06506493, -0.03168797, -0.06779031,  0.06786073,  0.01761883,\n",
       "        -0.0235638 , -0.04829278,  0.02920085, -0.07086229, -0.00673344,\n",
       "        -0.06029443,  0.05886117, -0.01329595, -0.06644855,  0.00782016,\n",
       "         0.02815153,  0.08015181, -0.07193734, -0.04658523,  0.02752531,\n",
       "        -0.02766514, -0.00531913, -0.00375322, -0.03799643, -0.03127219,\n",
       "         0.01300587, -0.0302396 , -0.03382104, -0.12191376, -0.01291207,\n",
       "        -0.06762628, -0.00378665,  0.01221592,  0.03646597,  0.03126171,\n",
       "         0.0549231 ,  0.02604216, -0.06657336,  0.01892763,  0.01990052,\n",
       "         0.0254866 ,  0.04472943, -0.03015464, -0.05829584,  0.03809468,\n",
       "        -0.03847592,  0.01203114, -0.01973571, -0.02382084,  0.01010568,\n",
       "        -0.06613055, -0.0355606 , -0.05266132,  0.01858362,  0.00820486,\n",
       "         0.01011459, -0.00953808, -0.020633  , -0.0829744 ,  0.06916893,\n",
       "        -0.08165056,  0.02060996,  0.02639791,  0.05199655,  0.01688248,\n",
       "        -0.05423857, -0.10870117, -0.08891917, -0.03891045,  0.03420576,\n",
       "         0.00714359, -0.0156863 , -0.03823899, -0.02463259,  0.05738744,\n",
       "        -0.0484609 ,  0.03472797, -0.02258603, -0.07231028,  0.06325474,\n",
       "        -0.03381258,  0.00627801, -0.05547873,  0.03971683,  0.0017431 ,\n",
       "         0.10395756,  0.04329943, -0.05676103,  0.02222642, -0.005157  ,\n",
       "         0.03515388,  0.07180883,  0.00303014,  0.12783706,  0.00566033,\n",
       "        -0.0341491 ,  0.0201539 , -0.03394061,  0.0085855 ,  0.01791802,\n",
       "         0.02639734,  0.08890786,  0.05066536, -0.0022379 ,  0.03545767,\n",
       "         0.00574902,  0.03397652,  0.09264446, -0.0081044 ,  0.05432583,\n",
       "         0.00299069, -0.01189764,  0.01030544, -0.0111589 , -0.01746465,\n",
       "         0.02787076,  0.07358126,  0.00707009,  0.01646081,  0.03265912,\n",
       "         0.02420458,  0.06885287, -0.01860503,  0.03403674,  0.01467916,\n",
       "        -0.02974324, -0.00648475,  0.02569914,  0.01724031,  0.08913171,\n",
       "         0.01321038,  0.00947264, -0.09208885, -0.00170277, -0.03202235,\n",
       "        -0.03582937, -0.02063398, -0.06728885,  0.03179403, -0.04346852,\n",
       "         0.01865543,  0.02585102,  0.05781393, -0.00331963, -0.02484792,\n",
       "        -0.03271791, -0.01681003,  0.03580819,  0.0276223 ,  0.0199588 ,\n",
       "         0.05892487, -0.05666631,  0.05654171, -0.02927009, -0.06888479,\n",
       "        -0.0779871 ,  0.06876405,  0.09043027, -0.02716553, -0.00158467,\n",
       "         0.02809897,  0.03271006,  0.01371709, -0.00436015, -0.04756678,\n",
       "        -0.04014241, -0.01123058, -0.13992895,  0.07264075, -0.0725759 ,\n",
       "        -0.05498563, -0.04791579, -0.00962679,  0.04435574,  0.01313202,\n",
       "         0.05776069,  0.0986682 , -0.09683155,  0.01770595, -0.04527685,\n",
       "        -0.07044629, -0.02223589, -0.02209995,  0.00141679,  0.08735042,\n",
       "        -0.10145072, -0.03648445,  0.03923674, -0.03602593,  0.10284173,\n",
       "        -0.07518327,  0.00807766,  0.01381657, -0.02374613, -0.01452363,\n",
       "         0.08335919,  0.0267769 , -0.0891774 ,  0.00806351, -0.05554841,\n",
       "        -0.07506362,  0.03923091,  0.01273772,  0.02200708,  0.01322591,\n",
       "        -0.02202361,  0.03621799, -0.05477829,  0.03113255,  0.02428211,\n",
       "        -0.02541419, -0.00620068,  0.00355048,  0.03059256, -0.00148503,\n",
       "        -0.03866078,  0.00494516, -0.07202139, -0.05335145, -0.03340375,\n",
       "         0.0342846 , -0.04058383,  0.04397864,  0.03792896, -0.0093828 ,\n",
       "         0.06134208, -0.00668664,  0.0463835 ,  0.01887076,  0.0471711 ,\n",
       "         0.03753902, -0.02628772,  0.07242689,  0.10531023,  0.05755928,\n",
       "        -0.04437043,  0.07471838, -0.04606022,  0.02102482,  0.04488577,\n",
       "        -0.02952923, -0.0142406 , -0.01058938, -0.04172521, -0.01516398,\n",
       "         0.06487178,  0.01506308,  0.00046589, -0.0724706 ,  0.10314049,\n",
       "         0.03748971, -0.00190707,  0.01104193, -0.00515289,  0.03143112,\n",
       "        -0.03775588,  0.05835546, -0.00526095, -0.08967511,  0.00023754,\n",
       "         0.08117   , -0.02066658,  0.04521366, -0.02486883,  0.00267146,\n",
       "         0.04015699, -0.04401391, -0.0572299 ,  0.03499588, -0.00413168,\n",
       "        -0.05033769,  0.02895247,  0.0248228 , -0.00353499, -0.02643185,\n",
       "         0.04997457,  0.04783029,  0.03098952, -0.01521169, -0.00131074,\n",
       "        -0.06255572,  0.02029865, -0.01772929,  0.01447645,  0.00425158,\n",
       "        -0.06963594, -0.02184954,  0.06948593,  0.04048913,  0.01370089,\n",
       "        -0.02878013, -0.04814836,  0.09139167,  0.05107205, -0.06003631,\n",
       "        -0.01217404, -0.04213816,  0.00284596,  0.00069707, -0.06647273,\n",
       "        -0.04230579,  0.04274705,  0.03085726,  0.00710699,  0.0480199 ,\n",
       "        -0.08236764, -0.05375202, -0.0087427 , -0.00691872, -0.04487963,\n",
       "         0.06100072, -0.03352207,  0.01485397,  0.00880835, -0.03697652,\n",
       "         0.0029412 ,  0.018143  , -0.00247909,  0.07610343, -0.00154956,\n",
       "         0.00809266, -0.05662902, -0.03609133, -0.04328235,  0.00608696,\n",
       "        -0.00223006, -0.08386871, -0.02875739, -0.01510374,  0.02835887,\n",
       "        -0.00545606,  0.00054331, -0.01129362,  0.04925416, -0.05291058,\n",
       "        -0.07908411, -0.03649475, -0.03431306, -0.02929677,  0.0771078 ,\n",
       "         0.09896065,  0.04068576, -0.05608902, -0.02472633,  0.0214692 ,\n",
       "         0.02545513,  0.0361822 ]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_tf_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16432562"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(tflite_output * normalized_tf_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.63282040e-02, -3.57723162e-02,  3.53021994e-02,\n",
       "         8.10580328e-04, -3.38179618e-03,  1.73042193e-02,\n",
       "         8.08609556e-03, -3.32332291e-02,  2.09442489e-02,\n",
       "        -7.87368789e-02,  2.48556361e-02, -9.53205004e-02,\n",
       "        -4.71324511e-02, -1.71131566e-02, -1.31104589e-02,\n",
       "         5.53108705e-03,  1.43610490e-02,  7.43892603e-03,\n",
       "        -2.95287035e-02,  6.29728660e-02,  5.90888076e-02,\n",
       "         7.76419789e-03,  3.62838581e-02,  7.13380203e-02,\n",
       "         4.20546941e-02,  2.34157983e-02,  9.25904438e-02,\n",
       "         9.51686036e-03, -3.83009203e-02, -2.72125732e-02,\n",
       "         1.83203910e-02, -9.57886106e-04, -5.98643795e-02,\n",
       "        -3.83775681e-02,  6.37396192e-03, -6.34784698e-02,\n",
       "         8.70735664e-03,  1.47271650e-02,  2.48763189e-02,\n",
       "        -2.28058491e-02,  2.57522408e-02,  1.91656984e-02,\n",
       "        -2.53685098e-02,  6.21827245e-02,  4.60363366e-02,\n",
       "        -1.56486649e-02,  2.02384014e-02,  4.01177742e-02,\n",
       "         7.94488713e-02,  7.32454583e-02, -5.61649501e-02,\n",
       "        -5.45450374e-02,  1.89870931e-02, -1.75116456e-03,\n",
       "        -3.52032669e-02,  1.21542802e-02,  1.66628510e-03,\n",
       "         3.07456069e-02,  4.45165019e-03,  5.60904033e-02,\n",
       "         9.07108467e-03, -2.71457694e-02,  3.86142284e-02,\n",
       "         1.03280939e-01,  1.98166426e-02, -1.63076054e-02,\n",
       "        -2.74065323e-02,  4.02910672e-02,  4.64991927e-02,\n",
       "         4.69460413e-02, -8.75706878e-03,  7.45918080e-02,\n",
       "        -3.15041766e-02, -1.02712512e-02, -6.64930642e-02,\n",
       "         1.64365787e-02, -2.00629141e-02,  4.49296869e-02,\n",
       "         1.05327554e-02,  2.92125368e-03,  7.93188065e-03,\n",
       "         7.26256520e-03, -4.01459076e-03,  3.58790234e-02,\n",
       "         9.90000088e-03, -1.08408138e-01,  6.68392777e-02,\n",
       "         3.97188701e-02, -2.09917855e-02, -4.86208964e-03,\n",
       "         7.72222923e-03,  1.09259523e-01, -2.04528533e-02,\n",
       "        -1.02577573e-02, -7.58688748e-02,  9.53944493e-03,\n",
       "        -1.09693632e-02, -3.44121605e-02, -1.18525298e-02,\n",
       "        -1.66696310e-02,  3.38101350e-02, -3.04566827e-02,\n",
       "         2.90569048e-02, -1.82429850e-02, -1.91032644e-02,\n",
       "         2.05318797e-02,  1.39743499e-02, -9.63659137e-02,\n",
       "        -3.75229940e-02, -1.94544792e-02,  1.27642006e-02,\n",
       "        -3.53227891e-02, -7.51257455e-03, -7.28291050e-02,\n",
       "        -1.77181773e-02,  5.83685795e-03,  9.07528400e-03,\n",
       "        -5.02220877e-02,  2.45172288e-02,  8.01000968e-02,\n",
       "        -9.65751614e-03, -1.59995370e-02,  6.15790673e-03,\n",
       "        -2.95610074e-02, -5.42939873e-03,  1.08494475e-01,\n",
       "         3.85985039e-02,  4.57740650e-02, -1.37234004e-02,\n",
       "         1.58669073e-02, -5.77385165e-02, -1.87513344e-02,\n",
       "         5.45599163e-02,  2.45679729e-02,  1.39706908e-02,\n",
       "        -3.70128304e-02, -1.36587890e-02,  2.84964554e-02,\n",
       "         6.27827421e-02,  4.00680006e-02,  5.25425971e-02,\n",
       "        -1.97701901e-02,  4.73909602e-02,  2.07828023e-02,\n",
       "         1.39883645e-02,  4.21008701e-03, -1.79429480e-03,\n",
       "        -7.40244333e-03, -8.51033106e-02, -4.55901735e-02,\n",
       "        -9.70254242e-02, -1.09994035e-04,  3.76045774e-03,\n",
       "         1.13558494e-01, -6.13225177e-02,  1.20172538e-01,\n",
       "         1.91288479e-02,  5.35433460e-03, -3.50720175e-02,\n",
       "         3.02844457e-02,  5.50742820e-03, -3.96139510e-02,\n",
       "         5.13993949e-03,  2.29467731e-02, -1.13081327e-02,\n",
       "        -1.46489718e-03,  8.65944028e-02,  2.30354108e-02,\n",
       "        -3.37465070e-02, -5.91885708e-02,  4.23142686e-02,\n",
       "         2.14564689e-02, -3.26373763e-02,  1.74190160e-02,\n",
       "         5.35951182e-02,  1.38916653e-02, -2.73426250e-03,\n",
       "         8.80520698e-03,  1.42088952e-02, -7.71709830e-02,\n",
       "        -7.77639961e-03, -6.08430058e-02, -1.90687843e-03,\n",
       "        -6.61979010e-03,  3.92797217e-03, -9.02462676e-02,\n",
       "        -5.20530045e-02, -2.41482928e-02,  4.79519293e-02,\n",
       "         2.37774737e-02, -1.19045628e-02, -7.31535554e-02,\n",
       "         2.37119328e-02,  2.41235457e-02,  2.49525886e-02,\n",
       "         3.81368473e-02,  5.69977947e-02,  2.33827461e-03,\n",
       "        -3.69096883e-02, -6.45955354e-02, -6.47557601e-02,\n",
       "         1.50143774e-02,  4.79536168e-02, -4.84172860e-03,\n",
       "         2.30214037e-02, -2.70779561e-02,  1.60765846e-03,\n",
       "         5.91493621e-02,  6.53166398e-02,  2.03908887e-02,\n",
       "        -2.68013421e-02,  2.92924307e-02,  8.63851085e-02,\n",
       "        -4.11656536e-02,  3.20610516e-02, -8.51122215e-02,\n",
       "         5.55811040e-02, -1.69383697e-02,  1.55234868e-02,\n",
       "        -3.37984636e-02, -4.97071957e-03,  2.35146172e-02,\n",
       "        -4.04676087e-02,  9.01356041e-02, -4.13892679e-02,\n",
       "        -4.21356969e-02,  3.45297083e-02,  3.60878818e-02,\n",
       "         6.33295700e-02, -3.94005477e-02,  4.56052609e-02,\n",
       "        -1.40260635e-02,  2.77297292e-02, -3.09009571e-02,\n",
       "         2.27915365e-02, -1.25936627e-01, -8.91556814e-02,\n",
       "         1.17867915e-02,  7.54307141e-04, -6.00364711e-03,\n",
       "         7.47010857e-02,  5.24650794e-03,  7.03824172e-03,\n",
       "        -3.20942816e-03, -2.63076909e-02, -5.79276271e-02,\n",
       "        -2.83783674e-02,  4.69577536e-02, -2.68229600e-02,\n",
       "        -3.07697169e-02, -3.51270400e-02, -2.00700499e-02,\n",
       "        -4.42035645e-02,  1.44775519e-02, -1.44405840e-02,\n",
       "        -2.08871644e-02, -1.10566579e-01,  8.78702570e-03,\n",
       "         7.06702024e-02,  1.73932370e-02,  8.61852244e-03,\n",
       "        -3.17467265e-02, -3.23195755e-02,  8.08038265e-02,\n",
       "         2.28331308e-03,  2.19318252e-02,  4.05408330e-02,\n",
       "        -2.76074950e-02,  4.85729873e-02, -1.21186459e-02,\n",
       "         2.86745522e-02,  3.77652124e-02,  4.93861325e-02,\n",
       "         1.67317763e-02, -5.51091805e-02, -9.94630530e-02,\n",
       "         6.69504330e-02, -4.34603356e-02, -3.18860076e-02,\n",
       "         1.18324354e-01, -1.69890858e-02, -9.32554714e-03,\n",
       "        -7.51305893e-02,  6.29920512e-02,  3.55591998e-02,\n",
       "         3.80987860e-03,  7.25717004e-03,  3.55389230e-02,\n",
       "        -1.72194466e-02,  2.67972369e-02,  2.49928720e-02,\n",
       "         3.29618640e-02,  1.07122317e-01,  2.40020780e-03,\n",
       "        -6.45584762e-02,  1.16699621e-01,  3.01320087e-02,\n",
       "         2.89521459e-02, -4.94865142e-02, -4.97865453e-02,\n",
       "        -1.27952348e-03, -1.21929057e-01, -9.04032681e-03,\n",
       "         4.30671088e-02, -4.64109704e-02,  2.42496990e-02,\n",
       "        -4.47248444e-02, -2.49744719e-03, -4.72302735e-02,\n",
       "        -7.64243230e-02, -2.34010126e-02, -3.61778289e-02,\n",
       "         2.78622899e-02,  8.98034722e-02,  1.67051833e-02,\n",
       "        -1.47468606e-02, -1.45896245e-02, -5.87568991e-03,\n",
       "         1.82270613e-02, -1.09051177e-02,  5.75985163e-02,\n",
       "        -3.84065807e-02,  2.27896981e-02,  3.13207810e-03,\n",
       "         4.43131998e-02, -3.47708501e-02,  5.85427694e-02,\n",
       "        -6.20610937e-02,  3.61035392e-02,  4.35048155e-02,\n",
       "         2.73688491e-02,  4.70299311e-02,  6.92943037e-02,\n",
       "        -3.06712631e-02,  2.74302997e-02,  3.46020982e-03,\n",
       "        -9.10141543e-02, -6.05935976e-03,  1.23975771e-02,\n",
       "        -7.18295872e-02, -1.69867296e-02,  3.29172648e-02,\n",
       "         5.88168250e-03, -1.83559991e-02, -6.11811168e-02,\n",
       "        -5.28379604e-02, -1.92363989e-02, -4.71739061e-02,\n",
       "        -5.08549297e-03,  1.45512652e-02,  3.45711857e-02,\n",
       "         5.77533729e-02,  5.97562231e-02, -6.75564557e-02,\n",
       "         4.65546101e-02,  2.27484237e-02,  3.35445851e-02,\n",
       "        -1.41882394e-02,  2.43886467e-02,  5.94081357e-02,\n",
       "         7.57244276e-03,  5.24312556e-02, -4.87973839e-02,\n",
       "        -1.96428578e-02, -8.16500280e-04,  1.06546879e-02,\n",
       "        -7.92036485e-03, -2.78765466e-02, -2.34197043e-02,\n",
       "        -3.50539498e-02,  6.88097402e-02,  4.86695999e-03,\n",
       "        -8.52001272e-03,  9.33291391e-03, -3.50742899e-02,\n",
       "        -4.49020006e-02, -9.28730180e-04,  5.21982871e-02,\n",
       "         1.33464374e-02, -7.48150945e-02,  4.12587374e-02,\n",
       "        -2.83351000e-02,  6.67727068e-02,  2.50729118e-02,\n",
       "         5.42581305e-02,  2.67370604e-02,  9.32009239e-03,\n",
       "        -2.29068398e-02,  3.43105607e-02,  1.71534289e-02,\n",
       "         4.38519707e-03, -7.45259151e-02, -6.85326606e-02,\n",
       "        -6.72939047e-02, -4.95911352e-02, -9.02670156e-03,\n",
       "        -9.87295527e-03, -4.76039276e-02, -3.95733165e-03,\n",
       "        -6.62576500e-03,  4.45836969e-02,  7.21435398e-02,\n",
       "        -8.30209162e-03, -3.75543796e-02, -8.81209224e-03,\n",
       "        -1.33863501e-02, -2.25574840e-02,  2.39476729e-02,\n",
       "         2.79439297e-02, -1.06579140e-02,  2.15280559e-02,\n",
       "        -5.10742236e-03,  6.39121830e-02, -5.91653809e-02,\n",
       "        -1.06723681e-01, -8.64698812e-02, -5.11427075e-02,\n",
       "        -4.08547744e-02, -1.44601446e-02, -4.14139107e-02,\n",
       "         5.88052161e-03, -1.83555745e-02,  2.16751685e-03,\n",
       "        -5.83798215e-02, -2.07166821e-02, -6.47117198e-02,\n",
       "        -1.93972066e-02, -2.51830257e-02, -6.47737784e-03,\n",
       "        -3.10596116e-02, -6.03894591e-02, -2.55873613e-02,\n",
       "         1.02834841e-02,  6.23277538e-02, -9.52778682e-02,\n",
       "         2.52131801e-02,  1.46867782e-02,  2.01399289e-02,\n",
       "         1.33302100e-02, -1.06515409e-02, -8.04562420e-02,\n",
       "        -8.32638610e-03, -6.52802065e-02, -6.49697110e-02,\n",
       "        -3.19303498e-02, -2.25190111e-02,  1.75276678e-02,\n",
       "         7.11846277e-02,  2.62383284e-04,  3.36840819e-03,\n",
       "         1.98563114e-02,  8.71941969e-02, -4.84007932e-02,\n",
       "         7.67487735e-02,  4.08148542e-02, -1.49581665e-02,\n",
       "        -1.93532072e-02,  5.38572185e-02,  5.44517450e-02,\n",
       "         5.83827756e-02, -1.85445640e-02,  4.12825542e-03,\n",
       "        -2.24541761e-02, -1.07545508e-02, -2.83491220e-02,\n",
       "        -9.65502709e-02,  4.67204563e-02,  3.14547643e-02,\n",
       "         9.26097669e-03, -6.22215588e-03, -5.36749475e-02,\n",
       "        -2.33180448e-02,  3.85619178e-02, -1.09311109e-02,\n",
       "         1.39653504e-01, -1.82006191e-02, -6.60458282e-02,\n",
       "        -2.67475974e-02, -8.00595358e-02,  4.11450267e-02,\n",
       "         2.85022575e-02,  1.85299944e-02,  8.69633034e-02,\n",
       "         6.84445649e-02,  4.97297309e-02, -5.51431701e-02,\n",
       "         8.53130594e-03, -1.11231878e-02, -2.47701537e-02,\n",
       "        -7.89185427e-03,  5.72635159e-02,  2.47894321e-04,\n",
       "        -6.08330928e-02, -4.64053601e-02, -3.66192982e-02,\n",
       "        -9.00613796e-03,  3.48727554e-02, -3.08887754e-02,\n",
       "        -5.35078198e-02, -8.57464299e-02, -7.97062814e-02,\n",
       "         4.94899675e-02,  2.77976897e-02, -1.19169513e-02,\n",
       "         9.16872639e-03, -4.54227775e-02, -4.45021316e-02,\n",
       "         8.53392202e-03, -2.28195563e-02, -3.93872522e-02,\n",
       "        -5.34992069e-02,  9.47645400e-03]], dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00058991835"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(normalized_output * normalized_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dummy conv layer\n",
    "[top](#caffe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy=\"/home/allen.jc.lin/tf_testing/single_conv.prototxt\"\n",
    "net = caffe.Net(deploy,caffe.TRAIN)\n",
    "net.params['334'][0].data[...] = np.ones((1,3,3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NHWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_input[0,:,:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe_input = np.transpose(tf_input,(0,3,1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCHW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 3)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_input[0,0,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe_input = tf_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net.blobs['0'].data[...] = caffe_input\n",
    "caffe_output = net.forward()['334']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n",
      "[[ 7.075458   9.458788   9.173692   6.019715 ]\n",
      " [ 9.410875  12.871306  12.739386  10.120045 ]\n",
      " [ 7.644647  11.824449  13.184648   7.5542674]\n",
      " [ 6.893902   9.88094    9.679523   5.1581664]]\n"
     ]
    }
   ],
   "source": [
    "print(caffe_output[0,0,:,:].shape)\n",
    "print(caffe_output[0,0,:,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n",
      "[[ 7.075458   9.458788   9.173692   6.019715 ]\n",
      " [ 9.410875  12.871306  12.739386  10.120045 ]\n",
      " [ 7.644647  11.824449  13.184648   7.5542674]\n",
      " [ 6.893902   9.88094    9.679523   5.1581664]]\n",
      "[[ 7.075458   9.458788   9.173692   6.019715 ]\n",
      " [ 9.410875  12.871306  12.739386  10.120045 ]\n",
      " [ 7.644647  11.824449  13.184648   7.5542674]\n",
      " [ 6.893902   9.88094    9.679523   5.1581664]]\n"
     ]
    }
   ],
   "source": [
    "print(tf_output[0,:,:,0].shape)\n",
    "print(tf_output[0,:,:,0])\n",
    "print(np.transpose(tf_output, (0,3,1,2))[0,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.,  0.,  0., -1.,  0.,  0., -1., -1.,  0.,  0.],\n",
       "       [-1.,  0.,  0., -2.,  0.,  0., -1., -1.,  0.,  0.],\n",
       "       [-1.,  0.,  0., -2.,  0.,  0., -1., -1.,  0.,  0.],\n",
       "       [ 0.,  2.,  2.,  0.,  2.,  2.,  1.,  1.,  2.,  2.],\n",
       "       [-1.,  0.,  0., -2.,  0.,  0., -1., -1.,  0.,  0.],\n",
       "       [-1.,  0.,  0., -2.,  0.,  0., -1., -1.,  0.,  0.],\n",
       "       [ 0.,  1.,  1., -1.,  1.,  1.,  0.,  0.,  1.,  1.],\n",
       "       [ 0.,  1.,  1., -1.,  1.,  1.,  0.,  0.,  1.,  1.],\n",
       "       [-1.,  0.,  0., -2.,  0.,  0., -1., -1.,  0.,  0.],\n",
       "       [ 0.,  2.,  2.,  0.,  2.,  2.,  1.,  1.,  2.,  2.]], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.flip(np.swapaxes(tf_output,3,2))[0,0,:,:] - caffe_output[0,0,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dummy depthwise layer  \n",
    "[top](#caffe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/allen/Documents/caffe/python\")\n",
    "import caffe\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = np.array([[[[1],[2],[3],[4]],[[2],[1],[3],[4]],[[3],[1],[2],[4]],[[4],[1],[2],[3]]]])\n",
    "img2 = np.array([[[[1],[1],[1],[1]],[[1],[1],[1],[1]],[[1],[1],[1],[1]],[[1],[1],[1],[1]]]])\n",
    "img = np.concatenate([img1,img2,img1],axis=3)\n",
    "np.random.seed(5)\n",
    "filter1 = np.random.rand(3,3,1,1)\n",
    "filter2 = np.random.rand(3,3,1,1)\n",
    "filter3 = np.random.rand(3,3,1,1)\n",
    "kernel = np.concatenate((filter1,filter2,filter3),axis=2)\n",
    "kernel = kernel.transpose(2,3,0,1)\n",
    "img = img.transpose(0,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.22199317]],\n",
       "\n",
       "        [[0.87073231]],\n",
       "\n",
       "        [[0.20671916]]],\n",
       "\n",
       "\n",
       "       [[[0.91861091]],\n",
       "\n",
       "        [[0.48841119]],\n",
       "\n",
       "        [[0.61174386]]],\n",
       "\n",
       "\n",
       "       [[[0.76590786]],\n",
       "\n",
       "        [[0.51841799]],\n",
       "\n",
       "        [[0.2968005 ]]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(5)\n",
    "np.random.rand(3,3,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.22199317, 0.87073231, 0.20671916],\n",
       "         [0.91861091, 0.48841119, 0.61174386],\n",
       "         [0.76590786, 0.51841799, 0.2968005 ]]],\n",
       "\n",
       "\n",
       "       [[[0.18772123, 0.08074127, 0.7384403 ],\n",
       "         [0.44130922, 0.15830987, 0.87993703],\n",
       "         [0.27408646, 0.41423502, 0.29607993]]],\n",
       "\n",
       "\n",
       "       [[[0.62878791, 0.57983781, 0.5999292 ],\n",
       "         [0.26581912, 0.28468588, 0.25358821],\n",
       "         [0.32756395, 0.1441643 , 0.16561286]]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.22199317],\n",
       "         [0.18772123],\n",
       "         [0.62878791]],\n",
       "\n",
       "        [[0.87073231],\n",
       "         [0.08074127],\n",
       "         [0.57983781]],\n",
       "\n",
       "        [[0.20671916],\n",
       "         [0.7384403 ],\n",
       "         [0.5999292 ]]],\n",
       "\n",
       "\n",
       "       [[[0.91861091],\n",
       "         [0.44130922],\n",
       "         [0.26581912]],\n",
       "\n",
       "        [[0.48841119],\n",
       "         [0.15830987],\n",
       "         [0.28468588]],\n",
       "\n",
       "        [[0.61174386],\n",
       "         [0.87993703],\n",
       "         [0.25358821]]],\n",
       "\n",
       "\n",
       "       [[[0.76590786],\n",
       "         [0.27408646],\n",
       "         [0.32756395]],\n",
       "\n",
       "        [[0.51841799],\n",
       "         [0.41423502],\n",
       "         [0.1441643 ]],\n",
       "\n",
       "        [[0.2968005 ],\n",
       "         [0.29607993],\n",
       "         [0.16561286]]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel.transpose((2,3,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy=\"/home/allen/20190220_fmobilenet_fc_align.prototxt\"\n",
    "net = caffe.Net(deploy,caffe.TRAIN)\n",
    "# net.params['334'][0].data[...] = kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(net.params['334'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer-0:0                   , type:Input\n",
      " -------------\n",
      "     from: \n",
      "     to  : 0                    \n",
      "------------- \n",
      "\n",
      "layer-1:334                 , type:Convolution\n",
      " -------------     weight:(64, 3, 3, 3)\n",
      "     from: 0                    \n",
      "     to  : 334                  \n",
      "------------- \n",
      "\n",
      "layer-2:335_bn              , type:BatchNorm\n",
      " -------------     weight:(64,)     weight:(64,)     weight:(1,)\n",
      "     from: 334                  \n",
      "     to  : 335                  \n",
      "------------- \n",
      "\n",
      "layer-3:335                 , type:Scale\n",
      " -------------     weight:(64,)     weight:(64,)\n",
      "     from: 335                  \n",
      "     to  : 335                  \n",
      "------------- \n",
      "\n",
      "layer-4:336_prelu           , type:PReLU\n",
      " -------------     weight:(64,)\n",
      "     from: 335                  \n",
      "     to  : 336                  \n",
      "------------- \n",
      "\n",
      "layer-5:337                 , type:Convolution\n",
      " -------------     weight:(64, 1, 3, 3)\n",
      "     from: 336                  \n",
      "     to  : 337                  \n",
      "------------- \n",
      "\n",
      "layer-6:338_bn              , type:BatchNorm\n",
      " -------------     weight:(64,)     weight:(64,)     weight:(1,)\n",
      "     from: 337                  \n",
      "     to  : 338                  \n",
      "------------- \n",
      "\n",
      "layer-7:338                 , type:Scale\n",
      " -------------     weight:(64,)     weight:(64,)\n",
      "     from: 338                  \n",
      "     to  : 338                  \n",
      "------------- \n",
      "\n",
      "layer-8:339_prelu           , type:PReLU\n",
      " -------------     weight:(64,)\n",
      "     from: 338                  \n",
      "     to  : 339                  \n",
      "------------- \n",
      "\n",
      "layer-9:340                 , type:Convolution\n",
      " -------------     weight:(128, 64, 1, 1)\n",
      "     from: 339                  \n",
      "     to  : 340                  \n",
      "------------- \n",
      "\n",
      "layer-10:341_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 340                  \n",
      "     to  : 341                  \n",
      "------------- \n",
      "\n",
      "layer-11:341                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 341                  \n",
      "     to  : 341                  \n",
      "------------- \n",
      "\n",
      "layer-12:342_prelu           , type:PReLU\n",
      " -------------     weight:(128,)\n",
      "     from: 341                  \n",
      "     to  : 342                  \n",
      "------------- \n",
      "\n",
      "layer-13:343                 , type:Convolution\n",
      " -------------     weight:(128, 1, 3, 3)\n",
      "     from: 342                  \n",
      "     to  : 343                  \n",
      "------------- \n",
      "\n",
      "layer-14:344_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 343                  \n",
      "     to  : 344                  \n",
      "------------- \n",
      "\n",
      "layer-15:344                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 344                  \n",
      "     to  : 344                  \n",
      "------------- \n",
      "\n",
      "layer-16:345_prelu           , type:PReLU\n",
      " -------------     weight:(128,)\n",
      "     from: 344                  \n",
      "     to  : 345                  \n",
      "------------- \n",
      "\n",
      "layer-17:346                 , type:Convolution\n",
      " -------------     weight:(64, 128, 1, 1)\n",
      "     from: 345                  \n",
      "     to  : 346                  \n",
      "------------- \n",
      "\n",
      "layer-18:347_bn              , type:BatchNorm\n",
      " -------------     weight:(64,)     weight:(64,)     weight:(1,)\n",
      "     from: 346                  \n",
      "     to  : 347                  \n",
      "------------- \n",
      "\n",
      "layer-19:347                 , type:Scale\n",
      " -------------     weight:(64,)     weight:(64,)\n",
      "     from: 347                  \n",
      "     to  : 347                  \n",
      "------------- \n",
      "\n",
      "layer-20:347_347_0_split     , type:Split\n",
      " -------------\n",
      "     from: 347                  \n",
      "     to  : 347_347_0_split_0    347_347_0_split_1    \n",
      "------------- \n",
      "\n",
      "layer-21:348                 , type:Convolution\n",
      " -------------     weight:(128, 64, 1, 1)\n",
      "     from: 347_347_0_split_0    \n",
      "     to  : 348                  \n",
      "------------- \n",
      "\n",
      "layer-22:349_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 348                  \n",
      "     to  : 349                  \n",
      "------------- \n",
      "\n",
      "layer-23:349                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 349                  \n",
      "     to  : 349                  \n",
      "------------- \n",
      "\n",
      "layer-24:350_prelu           , type:PReLU\n",
      " -------------     weight:(128,)\n",
      "     from: 349                  \n",
      "     to  : 350                  \n",
      "------------- \n",
      "\n",
      "layer-25:351                 , type:Convolution\n",
      " -------------     weight:(128, 1, 3, 3)\n",
      "     from: 350                  \n",
      "     to  : 351                  \n",
      "------------- \n",
      "\n",
      "layer-26:352_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 351                  \n",
      "     to  : 352                  \n",
      "------------- \n",
      "\n",
      "layer-27:352                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 352                  \n",
      "     to  : 352                  \n",
      "------------- \n",
      "\n",
      "layer-28:353_prelu           , type:PReLU\n",
      " -------------     weight:(128,)\n",
      "     from: 352                  \n",
      "     to  : 353                  \n",
      "------------- \n",
      "\n",
      "layer-29:354                 , type:Convolution\n",
      " -------------     weight:(64, 128, 1, 1)\n",
      "     from: 353                  \n",
      "     to  : 354                  \n",
      "------------- \n",
      "\n",
      "layer-30:355_bn              , type:BatchNorm\n",
      " -------------     weight:(64,)     weight:(64,)     weight:(1,)\n",
      "     from: 354                  \n",
      "     to  : 355                  \n",
      "------------- \n",
      "\n",
      "layer-31:355                 , type:Scale\n",
      " -------------     weight:(64,)     weight:(64,)\n",
      "     from: 355                  \n",
      "     to  : 355                  \n",
      "------------- \n",
      "\n",
      "layer-32:356                 , type:Eltwise\n",
      " -------------\n",
      "     from: 347_347_0_split_1    355                  \n",
      "     to  : 356                  \n",
      "------------- \n",
      "\n",
      "layer-33:356_356_0_split     , type:Split\n",
      " -------------\n",
      "     from: 356                  \n",
      "     to  : 356_356_0_split_0    356_356_0_split_1    \n",
      "------------- \n",
      "\n",
      "layer-34:357                 , type:Convolution\n",
      " -------------     weight:(128, 64, 1, 1)\n",
      "     from: 356_356_0_split_0    \n",
      "     to  : 357                  \n",
      "------------- \n",
      "\n",
      "layer-35:358_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 357                  \n",
      "     to  : 358                  \n",
      "------------- \n",
      "\n",
      "layer-36:358                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 358                  \n",
      "     to  : 358                  \n",
      "------------- \n",
      "\n",
      "layer-37:359_prelu           , type:PReLU\n",
      " -------------     weight:(128,)\n",
      "     from: 358                  \n",
      "     to  : 359                  \n",
      "------------- \n",
      "\n",
      "layer-38:360                 , type:Convolution\n",
      " -------------     weight:(128, 1, 3, 3)\n",
      "     from: 359                  \n",
      "     to  : 360                  \n",
      "------------- \n",
      "\n",
      "layer-39:361_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 360                  \n",
      "     to  : 361                  \n",
      "------------- \n",
      "\n",
      "layer-40:361                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 361                  \n",
      "     to  : 361                  \n",
      "------------- \n",
      "\n",
      "layer-41:362_prelu           , type:PReLU\n",
      " -------------     weight:(128,)\n",
      "     from: 361                  \n",
      "     to  : 362                  \n",
      "------------- \n",
      "\n",
      "layer-42:363                 , type:Convolution\n",
      " -------------     weight:(64, 128, 1, 1)\n",
      "     from: 362                  \n",
      "     to  : 363                  \n",
      "------------- \n",
      "\n",
      "layer-43:364_bn              , type:BatchNorm\n",
      " -------------     weight:(64,)     weight:(64,)     weight:(1,)\n",
      "     from: 363                  \n",
      "     to  : 364                  \n",
      "------------- \n",
      "\n",
      "layer-44:364                 , type:Scale\n",
      " -------------     weight:(64,)     weight:(64,)\n",
      "     from: 364                  \n",
      "     to  : 364                  \n",
      "------------- \n",
      "\n",
      "layer-45:365                 , type:Eltwise\n",
      " -------------\n",
      "     from: 356_356_0_split_1    364                  \n",
      "     to  : 365                  \n",
      "------------- \n",
      "\n",
      "layer-46:365_365_0_split     , type:Split\n",
      " -------------\n",
      "     from: 365                  \n",
      "     to  : 365_365_0_split_0    365_365_0_split_1    \n",
      "------------- \n",
      "\n",
      "layer-47:366                 , type:Convolution\n",
      " -------------     weight:(128, 64, 1, 1)\n",
      "     from: 365_365_0_split_0    \n",
      "     to  : 366                  \n",
      "------------- \n",
      "\n",
      "layer-48:367_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 366                  \n",
      "     to  : 367                  \n",
      "------------- \n",
      "\n",
      "layer-49:367                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 367                  \n",
      "     to  : 367                  \n",
      "------------- \n",
      "\n",
      "layer-50:368_prelu           , type:PReLU\n",
      " -------------     weight:(128,)\n",
      "     from: 367                  \n",
      "     to  : 368                  \n",
      "------------- \n",
      "\n",
      "layer-51:369                 , type:Convolution\n",
      " -------------     weight:(128, 1, 3, 3)\n",
      "     from: 368                  \n",
      "     to  : 369                  \n",
      "------------- \n",
      "\n",
      "layer-52:370_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 369                  \n",
      "     to  : 370                  \n",
      "------------- \n",
      "\n",
      "layer-53:370                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 370                  \n",
      "     to  : 370                  \n",
      "------------- \n",
      "\n",
      "layer-54:371_prelu           , type:PReLU\n",
      " -------------     weight:(128,)\n",
      "     from: 370                  \n",
      "     to  : 371                  \n",
      "------------- \n",
      "\n",
      "layer-55:372                 , type:Convolution\n",
      " -------------     weight:(64, 128, 1, 1)\n",
      "     from: 371                  \n",
      "     to  : 372                  \n",
      "------------- \n",
      "\n",
      "layer-56:373_bn              , type:BatchNorm\n",
      " -------------     weight:(64,)     weight:(64,)     weight:(1,)\n",
      "     from: 372                  \n",
      "     to  : 373                  \n",
      "------------- \n",
      "\n",
      "layer-57:373                 , type:Scale\n",
      " -------------     weight:(64,)     weight:(64,)\n",
      "     from: 373                  \n",
      "     to  : 373                  \n",
      "------------- \n",
      "\n",
      "layer-58:374                 , type:Eltwise\n",
      " -------------\n",
      "     from: 365_365_0_split_1    373                  \n",
      "     to  : 374                  \n",
      "------------- \n",
      "\n",
      "layer-59:374_374_0_split     , type:Split\n",
      " -------------\n",
      "     from: 374                  \n",
      "     to  : 374_374_0_split_0    374_374_0_split_1    \n",
      "------------- \n",
      "\n",
      "layer-60:375                 , type:Convolution\n",
      " -------------     weight:(128, 64, 1, 1)\n",
      "     from: 374_374_0_split_0    \n",
      "     to  : 375                  \n",
      "------------- \n",
      "\n",
      "layer-61:376_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 375                  \n",
      "     to  : 376                  \n",
      "------------- \n",
      "\n",
      "layer-62:376                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 376                  \n",
      "     to  : 376                  \n",
      "------------- \n",
      "\n",
      "layer-63:377_prelu           , type:PReLU\n",
      " -------------     weight:(128,)\n",
      "     from: 376                  \n",
      "     to  : 377                  \n",
      "------------- \n",
      "\n",
      "layer-64:378                 , type:Convolution\n",
      " -------------     weight:(128, 1, 3, 3)\n",
      "     from: 377                  \n",
      "     to  : 378                  \n",
      "------------- \n",
      "\n",
      "layer-65:379_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 378                  \n",
      "     to  : 379                  \n",
      "------------- \n",
      "\n",
      "layer-66:379                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 379                  \n",
      "     to  : 379                  \n",
      "------------- \n",
      "\n",
      "layer-67:380_prelu           , type:PReLU\n",
      " -------------     weight:(128,)\n",
      "     from: 379                  \n",
      "     to  : 380                  \n",
      "------------- \n",
      "\n",
      "layer-68:381                 , type:Convolution\n",
      " -------------     weight:(64, 128, 1, 1)\n",
      "     from: 380                  \n",
      "     to  : 381                  \n",
      "------------- \n",
      "\n",
      "layer-69:382_bn              , type:BatchNorm\n",
      " -------------     weight:(64,)     weight:(64,)     weight:(1,)\n",
      "     from: 381                  \n",
      "     to  : 382                  \n",
      "------------- \n",
      "\n",
      "layer-70:382                 , type:Scale\n",
      " -------------     weight:(64,)     weight:(64,)\n",
      "     from: 382                  \n",
      "     to  : 382                  \n",
      "------------- \n",
      "\n",
      "layer-71:383                 , type:Eltwise\n",
      " -------------\n",
      "     from: 374_374_0_split_1    382                  \n",
      "     to  : 383                  \n",
      "------------- \n",
      "\n",
      "layer-72:384                 , type:Convolution\n",
      " -------------     weight:(256, 64, 1, 1)\n",
      "     from: 383                  \n",
      "     to  : 384                  \n",
      "------------- \n",
      "\n",
      "layer-73:385_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 384                  \n",
      "     to  : 385                  \n",
      "------------- \n",
      "\n",
      "layer-74:385                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 385                  \n",
      "     to  : 385                  \n",
      "------------- \n",
      "\n",
      "layer-75:386_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 385                  \n",
      "     to  : 386                  \n",
      "------------- \n",
      "\n",
      "layer-76:387                 , type:Convolution\n",
      " -------------     weight:(256, 1, 3, 3)\n",
      "     from: 386                  \n",
      "     to  : 387                  \n",
      "------------- \n",
      "\n",
      "layer-77:388_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 387                  \n",
      "     to  : 388                  \n",
      "------------- \n",
      "\n",
      "layer-78:388                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 388                  \n",
      "     to  : 388                  \n",
      "------------- \n",
      "\n",
      "layer-79:389_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 388                  \n",
      "     to  : 389                  \n",
      "------------- \n",
      "\n",
      "layer-80:390                 , type:Convolution\n",
      " -------------     weight:(128, 256, 1, 1)\n",
      "     from: 389                  \n",
      "     to  : 390                  \n",
      "------------- \n",
      "\n",
      "layer-81:391_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 390                  \n",
      "     to  : 391                  \n",
      "------------- \n",
      "\n",
      "layer-82:391                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 391                  \n",
      "     to  : 391                  \n",
      "------------- \n",
      "\n",
      "layer-83:391_391_0_split     , type:Split\n",
      " -------------\n",
      "     from: 391                  \n",
      "     to  : 391_391_0_split_0    391_391_0_split_1    \n",
      "------------- \n",
      "\n",
      "layer-84:392                 , type:Convolution\n",
      " -------------     weight:(256, 128, 1, 1)\n",
      "     from: 391_391_0_split_0    \n",
      "     to  : 392                  \n",
      "------------- \n",
      "\n",
      "layer-85:393_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 392                  \n",
      "     to  : 393                  \n",
      "------------- \n",
      "\n",
      "layer-86:393                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 393                  \n",
      "     to  : 393                  \n",
      "------------- \n",
      "\n",
      "layer-87:394_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 393                  \n",
      "     to  : 394                  \n",
      "------------- \n",
      "\n",
      "layer-88:395                 , type:Convolution\n",
      " -------------     weight:(256, 1, 3, 3)\n",
      "     from: 394                  \n",
      "     to  : 395                  \n",
      "------------- \n",
      "\n",
      "layer-89:396_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 395                  \n",
      "     to  : 396                  \n",
      "------------- \n",
      "\n",
      "layer-90:396                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 396                  \n",
      "     to  : 396                  \n",
      "------------- \n",
      "\n",
      "layer-91:397_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 396                  \n",
      "     to  : 397                  \n",
      "------------- \n",
      "\n",
      "layer-92:398                 , type:Convolution\n",
      " -------------     weight:(128, 256, 1, 1)\n",
      "     from: 397                  \n",
      "     to  : 398                  \n",
      "------------- \n",
      "\n",
      "layer-93:399_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 398                  \n",
      "     to  : 399                  \n",
      "------------- \n",
      "\n",
      "layer-94:399                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 399                  \n",
      "     to  : 399                  \n",
      "------------- \n",
      "\n",
      "layer-95:400                 , type:Eltwise\n",
      " -------------\n",
      "     from: 391_391_0_split_1    399                  \n",
      "     to  : 400                  \n",
      "------------- \n",
      "\n",
      "layer-96:400_400_0_split     , type:Split\n",
      " -------------\n",
      "     from: 400                  \n",
      "     to  : 400_400_0_split_0    400_400_0_split_1    \n",
      "------------- \n",
      "\n",
      "layer-97:401                 , type:Convolution\n",
      " -------------     weight:(256, 128, 1, 1)\n",
      "     from: 400_400_0_split_0    \n",
      "     to  : 401                  \n",
      "------------- \n",
      "\n",
      "layer-98:402_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 401                  \n",
      "     to  : 402                  \n",
      "------------- \n",
      "\n",
      "layer-99:402                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 402                  \n",
      "     to  : 402                  \n",
      "------------- \n",
      "\n",
      "layer-100:403_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 402                  \n",
      "     to  : 403                  \n",
      "------------- \n",
      "\n",
      "layer-101:404                 , type:Convolution\n",
      " -------------     weight:(256, 1, 3, 3)\n",
      "     from: 403                  \n",
      "     to  : 404                  \n",
      "------------- \n",
      "\n",
      "layer-102:405_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 404                  \n",
      "     to  : 405                  \n",
      "------------- \n",
      "\n",
      "layer-103:405                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 405                  \n",
      "     to  : 405                  \n",
      "------------- \n",
      "\n",
      "layer-104:406_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 405                  \n",
      "     to  : 406                  \n",
      "------------- \n",
      "\n",
      "layer-105:407                 , type:Convolution\n",
      " -------------     weight:(128, 256, 1, 1)\n",
      "     from: 406                  \n",
      "     to  : 407                  \n",
      "------------- \n",
      "\n",
      "layer-106:408_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 407                  \n",
      "     to  : 408                  \n",
      "------------- \n",
      "\n",
      "layer-107:408                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 408                  \n",
      "     to  : 408                  \n",
      "------------- \n",
      "\n",
      "layer-108:409                 , type:Eltwise\n",
      " -------------\n",
      "     from: 400_400_0_split_1    408                  \n",
      "     to  : 409                  \n",
      "------------- \n",
      "\n",
      "layer-109:409_409_0_split     , type:Split\n",
      " -------------\n",
      "     from: 409                  \n",
      "     to  : 409_409_0_split_0    409_409_0_split_1    \n",
      "------------- \n",
      "\n",
      "layer-110:410                 , type:Convolution\n",
      " -------------     weight:(256, 128, 1, 1)\n",
      "     from: 409_409_0_split_0    \n",
      "     to  : 410                  \n",
      "------------- \n",
      "\n",
      "layer-111:411_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 410                  \n",
      "     to  : 411                  \n",
      "------------- \n",
      "\n",
      "layer-112:411                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 411                  \n",
      "     to  : 411                  \n",
      "------------- \n",
      "\n",
      "layer-113:412_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 411                  \n",
      "     to  : 412                  \n",
      "------------- \n",
      "\n",
      "layer-114:413                 , type:Convolution\n",
      " -------------     weight:(256, 1, 3, 3)\n",
      "     from: 412                  \n",
      "     to  : 413                  \n",
      "------------- \n",
      "\n",
      "layer-115:414_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 413                  \n",
      "     to  : 414                  \n",
      "------------- \n",
      "\n",
      "layer-116:414                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 414                  \n",
      "     to  : 414                  \n",
      "------------- \n",
      "\n",
      "layer-117:415_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 414                  \n",
      "     to  : 415                  \n",
      "------------- \n",
      "\n",
      "layer-118:416                 , type:Convolution\n",
      " -------------     weight:(128, 256, 1, 1)\n",
      "     from: 415                  \n",
      "     to  : 416                  \n",
      "------------- \n",
      "\n",
      "layer-119:417_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 416                  \n",
      "     to  : 417                  \n",
      "------------- \n",
      "\n",
      "layer-120:417                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 417                  \n",
      "     to  : 417                  \n",
      "------------- \n",
      "\n",
      "layer-121:418                 , type:Eltwise\n",
      " -------------\n",
      "     from: 409_409_0_split_1    417                  \n",
      "     to  : 418                  \n",
      "------------- \n",
      "\n",
      "layer-122:418_418_0_split     , type:Split\n",
      " -------------\n",
      "     from: 418                  \n",
      "     to  : 418_418_0_split_0    418_418_0_split_1    \n",
      "------------- \n",
      "\n",
      "layer-123:419                 , type:Convolution\n",
      " -------------     weight:(256, 128, 1, 1)\n",
      "     from: 418_418_0_split_0    \n",
      "     to  : 419                  \n",
      "------------- \n",
      "\n",
      "layer-124:420_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 419                  \n",
      "     to  : 420                  \n",
      "------------- \n",
      "\n",
      "layer-125:420                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 420                  \n",
      "     to  : 420                  \n",
      "------------- \n",
      "\n",
      "layer-126:421_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 420                  \n",
      "     to  : 421                  \n",
      "------------- \n",
      "\n",
      "layer-127:422                 , type:Convolution\n",
      " -------------     weight:(256, 1, 3, 3)\n",
      "     from: 421                  \n",
      "     to  : 422                  \n",
      "------------- \n",
      "\n",
      "layer-128:423_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 422                  \n",
      "     to  : 423                  \n",
      "------------- \n",
      "\n",
      "layer-129:423                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 423                  \n",
      "     to  : 423                  \n",
      "------------- \n",
      "\n",
      "layer-130:424_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 423                  \n",
      "     to  : 424                  \n",
      "------------- \n",
      "\n",
      "layer-131:425                 , type:Convolution\n",
      " -------------     weight:(128, 256, 1, 1)\n",
      "     from: 424                  \n",
      "     to  : 425                  \n",
      "------------- \n",
      "\n",
      "layer-132:426_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 425                  \n",
      "     to  : 426                  \n",
      "------------- \n",
      "\n",
      "layer-133:426                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 426                  \n",
      "     to  : 426                  \n",
      "------------- \n",
      "\n",
      "layer-134:427                 , type:Eltwise\n",
      " -------------\n",
      "     from: 418_418_0_split_1    426                  \n",
      "     to  : 427                  \n",
      "------------- \n",
      "\n",
      "layer-135:427_427_0_split     , type:Split\n",
      " -------------\n",
      "     from: 427                  \n",
      "     to  : 427_427_0_split_0    427_427_0_split_1    \n",
      "------------- \n",
      "\n",
      "layer-136:428                 , type:Convolution\n",
      " -------------     weight:(256, 128, 1, 1)\n",
      "     from: 427_427_0_split_0    \n",
      "     to  : 428                  \n",
      "------------- \n",
      "\n",
      "layer-137:429_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 428                  \n",
      "     to  : 429                  \n",
      "------------- \n",
      "\n",
      "layer-138:429                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 429                  \n",
      "     to  : 429                  \n",
      "------------- \n",
      "\n",
      "layer-139:430_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 429                  \n",
      "     to  : 430                  \n",
      "------------- \n",
      "\n",
      "layer-140:431                 , type:Convolution\n",
      " -------------     weight:(256, 1, 3, 3)\n",
      "     from: 430                  \n",
      "     to  : 431                  \n",
      "------------- \n",
      "\n",
      "layer-141:432_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 431                  \n",
      "     to  : 432                  \n",
      "------------- \n",
      "\n",
      "layer-142:432                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 432                  \n",
      "     to  : 432                  \n",
      "------------- \n",
      "\n",
      "layer-143:433_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 432                  \n",
      "     to  : 433                  \n",
      "------------- \n",
      "\n",
      "layer-144:434                 , type:Convolution\n",
      " -------------     weight:(128, 256, 1, 1)\n",
      "     from: 433                  \n",
      "     to  : 434                  \n",
      "------------- \n",
      "\n",
      "layer-145:435_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 434                  \n",
      "     to  : 435                  \n",
      "------------- \n",
      "\n",
      "layer-146:435                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 435                  \n",
      "     to  : 435                  \n",
      "------------- \n",
      "\n",
      "layer-147:436                 , type:Eltwise\n",
      " -------------\n",
      "     from: 427_427_0_split_1    435                  \n",
      "     to  : 436                  \n",
      "------------- \n",
      "\n",
      "layer-148:436_436_0_split     , type:Split\n",
      " -------------\n",
      "     from: 436                  \n",
      "     to  : 436_436_0_split_0    436_436_0_split_1    \n",
      "------------- \n",
      "\n",
      "layer-149:437                 , type:Convolution\n",
      " -------------     weight:(256, 128, 1, 1)\n",
      "     from: 436_436_0_split_0    \n",
      "     to  : 437                  \n",
      "------------- \n",
      "\n",
      "layer-150:438_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 437                  \n",
      "     to  : 438                  \n",
      "------------- \n",
      "\n",
      "layer-151:438                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 438                  \n",
      "     to  : 438                  \n",
      "------------- \n",
      "\n",
      "layer-152:439_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 438                  \n",
      "     to  : 439                  \n",
      "------------- \n",
      "\n",
      "layer-153:440                 , type:Convolution\n",
      " -------------     weight:(256, 1, 3, 3)\n",
      "     from: 439                  \n",
      "     to  : 440                  \n",
      "------------- \n",
      "\n",
      "layer-154:441_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 440                  \n",
      "     to  : 441                  \n",
      "------------- \n",
      "\n",
      "layer-155:441                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 441                  \n",
      "     to  : 441                  \n",
      "------------- \n",
      "\n",
      "layer-156:442_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 441                  \n",
      "     to  : 442                  \n",
      "------------- \n",
      "\n",
      "layer-157:443                 , type:Convolution\n",
      " -------------     weight:(128, 256, 1, 1)\n",
      "     from: 442                  \n",
      "     to  : 443                  \n",
      "------------- \n",
      "\n",
      "layer-158:444_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 443                  \n",
      "     to  : 444                  \n",
      "------------- \n",
      "\n",
      "layer-159:444                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 444                  \n",
      "     to  : 444                  \n",
      "------------- \n",
      "\n",
      "layer-160:445                 , type:Eltwise\n",
      " -------------\n",
      "     from: 436_436_0_split_1    444                  \n",
      "     to  : 445                  \n",
      "------------- \n",
      "\n",
      "layer-161:446                 , type:Convolution\n",
      " -------------     weight:(512, 128, 1, 1)\n",
      "     from: 445                  \n",
      "     to  : 446                  \n",
      "------------- \n",
      "\n",
      "layer-162:447_bn              , type:BatchNorm\n",
      " -------------     weight:(512,)     weight:(512,)     weight:(1,)\n",
      "     from: 446                  \n",
      "     to  : 447                  \n",
      "------------- \n",
      "\n",
      "layer-163:447                 , type:Scale\n",
      " -------------     weight:(512,)     weight:(512,)\n",
      "     from: 447                  \n",
      "     to  : 447                  \n",
      "------------- \n",
      "\n",
      "layer-164:448_prelu           , type:PReLU\n",
      " -------------     weight:(512,)\n",
      "     from: 447                  \n",
      "     to  : 448                  \n",
      "------------- \n",
      "\n",
      "layer-165:449                 , type:Convolution\n",
      " -------------     weight:(512, 1, 3, 3)\n",
      "     from: 448                  \n",
      "     to  : 449                  \n",
      "------------- \n",
      "\n",
      "layer-166:450_bn              , type:BatchNorm\n",
      " -------------     weight:(512,)     weight:(512,)     weight:(1,)\n",
      "     from: 449                  \n",
      "     to  : 450                  \n",
      "------------- \n",
      "\n",
      "layer-167:450                 , type:Scale\n",
      " -------------     weight:(512,)     weight:(512,)\n",
      "     from: 450                  \n",
      "     to  : 450                  \n",
      "------------- \n",
      "\n",
      "layer-168:451_prelu           , type:PReLU\n",
      " -------------     weight:(512,)\n",
      "     from: 450                  \n",
      "     to  : 451                  \n",
      "------------- \n",
      "\n",
      "layer-169:452                 , type:Convolution\n",
      " -------------     weight:(128, 512, 1, 1)\n",
      "     from: 451                  \n",
      "     to  : 452                  \n",
      "------------- \n",
      "\n",
      "layer-170:453_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 452                  \n",
      "     to  : 453                  \n",
      "------------- \n",
      "\n",
      "layer-171:453                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 453                  \n",
      "     to  : 453                  \n",
      "------------- \n",
      "\n",
      "layer-172:453_453_0_split     , type:Split\n",
      " -------------\n",
      "     from: 453                  \n",
      "     to  : 453_453_0_split_0    453_453_0_split_1    \n",
      "------------- \n",
      "\n",
      "layer-173:454                 , type:Convolution\n",
      " -------------     weight:(256, 128, 1, 1)\n",
      "     from: 453_453_0_split_0    \n",
      "     to  : 454                  \n",
      "------------- \n",
      "\n",
      "layer-174:455_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 454                  \n",
      "     to  : 455                  \n",
      "------------- \n",
      "\n",
      "layer-175:455                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 455                  \n",
      "     to  : 455                  \n",
      "------------- \n",
      "\n",
      "layer-176:456_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 455                  \n",
      "     to  : 456                  \n",
      "------------- \n",
      "\n",
      "layer-177:457                 , type:Convolution\n",
      " -------------     weight:(256, 1, 3, 3)\n",
      "     from: 456                  \n",
      "     to  : 457                  \n",
      "------------- \n",
      "\n",
      "layer-178:458_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 457                  \n",
      "     to  : 458                  \n",
      "------------- \n",
      "\n",
      "layer-179:458                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 458                  \n",
      "     to  : 458                  \n",
      "------------- \n",
      "\n",
      "layer-180:459_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 458                  \n",
      "     to  : 459                  \n",
      "------------- \n",
      "\n",
      "layer-181:460                 , type:Convolution\n",
      " -------------     weight:(128, 256, 1, 1)\n",
      "     from: 459                  \n",
      "     to  : 460                  \n",
      "------------- \n",
      "\n",
      "layer-182:461_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 460                  \n",
      "     to  : 461                  \n",
      "------------- \n",
      "\n",
      "layer-183:461                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 461                  \n",
      "     to  : 461                  \n",
      "------------- \n",
      "\n",
      "layer-184:462                 , type:Eltwise\n",
      " -------------\n",
      "     from: 453_453_0_split_1    461                  \n",
      "     to  : 462                  \n",
      "------------- \n",
      "\n",
      "layer-185:462_462_0_split     , type:Split\n",
      " -------------\n",
      "     from: 462                  \n",
      "     to  : 462_462_0_split_0    462_462_0_split_1    \n",
      "------------- \n",
      "\n",
      "layer-186:463                 , type:Convolution\n",
      " -------------     weight:(256, 128, 1, 1)\n",
      "     from: 462_462_0_split_0    \n",
      "     to  : 463                  \n",
      "------------- \n",
      "\n",
      "layer-187:464_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 463                  \n",
      "     to  : 464                  \n",
      "------------- \n",
      "\n",
      "layer-188:464                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 464                  \n",
      "     to  : 464                  \n",
      "------------- \n",
      "\n",
      "layer-189:465_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 464                  \n",
      "     to  : 465                  \n",
      "------------- \n",
      "\n",
      "layer-190:466                 , type:Convolution\n",
      " -------------     weight:(256, 1, 3, 3)\n",
      "     from: 465                  \n",
      "     to  : 466                  \n",
      "------------- \n",
      "\n",
      "layer-191:467_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 466                  \n",
      "     to  : 467                  \n",
      "------------- \n",
      "\n",
      "layer-192:467                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 467                  \n",
      "     to  : 467                  \n",
      "------------- \n",
      "\n",
      "layer-193:468_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 467                  \n",
      "     to  : 468                  \n",
      "------------- \n",
      "\n",
      "layer-194:469                 , type:Convolution\n",
      " -------------     weight:(128, 256, 1, 1)\n",
      "     from: 468                  \n",
      "     to  : 469                  \n",
      "------------- \n",
      "\n",
      "layer-195:470_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 469                  \n",
      "     to  : 470                  \n",
      "------------- \n",
      "\n",
      "layer-196:470                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 470                  \n",
      "     to  : 470                  \n",
      "------------- \n",
      "\n",
      "layer-197:471                 , type:Eltwise\n",
      " -------------\n",
      "     from: 462_462_0_split_1    470                  \n",
      "     to  : 471                  \n",
      "------------- \n",
      "\n",
      "layer-198:472                 , type:Convolution\n",
      " -------------     weight:(512, 128, 1, 1)\n",
      "     from: 471                  \n",
      "     to  : 472                  \n",
      "------------- \n",
      "\n",
      "layer-199:473_bn              , type:BatchNorm\n",
      " -------------     weight:(512,)     weight:(512,)     weight:(1,)\n",
      "     from: 472                  \n",
      "     to  : 473                  \n",
      "------------- \n",
      "\n",
      "layer-200:473                 , type:Scale\n",
      " -------------     weight:(512,)     weight:(512,)\n",
      "     from: 473                  \n",
      "     to  : 473                  \n",
      "------------- \n",
      "\n",
      "layer-201:474_prelu           , type:PReLU\n",
      " -------------     weight:(512,)\n",
      "     from: 473                  \n",
      "     to  : 474                  \n",
      "------------- \n",
      "\n",
      "layer-202:bn1                 , type:BatchNorm\n",
      " -------------     weight:(512,)     weight:(512,)     weight:(1,)\n",
      "     from: 474                  \n",
      "     to  : 475                  \n",
      "------------- \n",
      "\n",
      "layer-203:bn1_scale           , type:Scale\n",
      " -------------     weight:(512,)     weight:(512,)\n",
      "     from: 475                  \n",
      "     to  : 475                  \n",
      "------------- \n",
      "\n",
      "layer-204:fc_emb              , type:InnerProduct\n",
      " -------------     weight:(512, 25088)     weight:(512,)\n",
      "     from: 475                  \n",
      "     to  : 476                  \n",
      "------------- \n",
      "\n",
      "layer-205:bn2                 , type:BatchNorm\n",
      " -------------     weight:(512,)     weight:(512,)     weight:(1,)\n",
      "     from: 476                  \n",
      "     to  : 477                  \n",
      "------------- \n",
      "\n",
      "layer-206:bn2_scale           , type:Scale\n",
      " -------------     weight:(512,)     weight:(512,)\n",
      "     from: 477                  \n",
      "     to  : 477                  \n",
      "------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "network = {}\n",
    "for i, layer in enumerate(net._layer_names):\n",
    "    bottoms = net.bottom_names[layer]\n",
    "    tops = net.top_names[layer]\n",
    "    network[layer] = {}\n",
    "    network[layer]['bottom'] = bottoms\n",
    "    network[layer]['top'] = tops\n",
    "    network[layer]['weights'] = []\n",
    "    msg = \"layer-{}:{:20}, type:{}\\n \".format(i, layer, net.layers[i].type)\n",
    "    msg += \"-------------\"\n",
    "    if layer in net.params:\n",
    "        for param in net.params[layer]:\n",
    "            msg += \"     weight:{}\".format(param.data[...].shape)\n",
    "            network[layer]['weights'].append(param.data[...])\n",
    "    msg += \"\\n     from: \"\n",
    "    for bottom in bottoms:\n",
    "        msg += \"{:20} \".format(bottom)\n",
    "    msg += \"\\n     to  : \"\n",
    "    for top in tops:\n",
    "        msg += \"{:20} \".format(top)\n",
    "    msg += \"\\n------------- \\n\"\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import caffe.proto.caffe_pb2 as caffepb\n",
    "net_params = caffepb.NetParameter()\n",
    "f = open(deploy, 'rb')\n",
    "net_str = f.read()\n",
    "# net_params.ParseFromString(f.read())\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "layer {\n",
       "  name: \"0\"\n",
       "  type: \"Input\"\n",
       "  top: \"0\"\n",
       "  input_param {\n",
       "    shape {\n",
       "      dim: 1\n",
       "      dim: 3\n",
       "      dim: 112\n",
       "      dim: 112\n",
       "    }\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"334\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"0\"\n",
       "  top: \"334\"\n",
       "  convolution_param {\n",
       "    num_output: 64\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 1\n",
       "    pad_w: 1\n",
       "    kernel_h: 3\n",
       "    kernel_w: 3\n",
       "    stride_h: 2\n",
       "    stride_w: 2\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"335_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"334\"\n",
       "  top: \"335\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"335\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"335\"\n",
       "  top: \"335\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"336_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"335\"\n",
       "  top: \"336\"\n",
       "}\n",
       "layer {\n",
       "  name: \"337\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"336\"\n",
       "  top: \"337\"\n",
       "  convolution_param {\n",
       "    num_output: 64\n",
       "    bias_term: false\n",
       "    group: 64\n",
       "    pad_h: 1\n",
       "    pad_w: 1\n",
       "    kernel_h: 3\n",
       "    kernel_w: 3\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"338_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"337\"\n",
       "  top: \"338\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"338\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"338\"\n",
       "  top: \"338\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"339_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"338\"\n",
       "  top: \"339\"\n",
       "}\n",
       "layer {\n",
       "  name: \"340\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"339\"\n",
       "  top: \"340\"\n",
       "  convolution_param {\n",
       "    num_output: 128\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"341_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"340\"\n",
       "  top: \"341\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"341\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"341\"\n",
       "  top: \"341\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"342_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"341\"\n",
       "  top: \"342\"\n",
       "}\n",
       "layer {\n",
       "  name: \"343\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"342\"\n",
       "  top: \"343\"\n",
       "  convolution_param {\n",
       "    num_output: 128\n",
       "    bias_term: false\n",
       "    group: 128\n",
       "    pad_h: 1\n",
       "    pad_w: 1\n",
       "    kernel_h: 3\n",
       "    kernel_w: 3\n",
       "    stride_h: 2\n",
       "    stride_w: 2\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"344_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"343\"\n",
       "  top: \"344\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"344\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"344\"\n",
       "  top: \"344\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"345_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"344\"\n",
       "  top: \"345\"\n",
       "}\n",
       "layer {\n",
       "  name: \"346\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"345\"\n",
       "  top: \"346\"\n",
       "  convolution_param {\n",
       "    num_output: 64\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"347_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"346\"\n",
       "  top: \"347\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"347\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"347\"\n",
       "  top: \"347\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"348\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"347\"\n",
       "  top: \"348\"\n",
       "  convolution_param {\n",
       "    num_output: 128\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"349_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"348\"\n",
       "  top: \"349\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"349\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"349\"\n",
       "  top: \"349\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"350_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"349\"\n",
       "  top: \"350\"\n",
       "}\n",
       "layer {\n",
       "  name: \"351\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"350\"\n",
       "  top: \"351\"\n",
       "  convolution_param {\n",
       "    num_output: 128\n",
       "    bias_term: false\n",
       "    group: 128\n",
       "    pad_h: 1\n",
       "    pad_w: 1\n",
       "    kernel_h: 3\n",
       "    kernel_w: 3\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"352_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"351\"\n",
       "  top: \"352\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"352\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"352\"\n",
       "  top: \"352\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"353_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"352\"\n",
       "  top: \"353\"\n",
       "}\n",
       "layer {\n",
       "  name: \"354\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"353\"\n",
       "  top: \"354\"\n",
       "  convolution_param {\n",
       "    num_output: 64\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"355_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"354\"\n",
       "  top: \"355\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"355\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"355\"\n",
       "  top: \"355\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"356\"\n",
       "  type: \"Eltwise\"\n",
       "  bottom: \"347\"\n",
       "  bottom: \"355\"\n",
       "  top: \"356\"\n",
       "  eltwise_param {\n",
       "    operation: SUM\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"357\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"356\"\n",
       "  top: \"357\"\n",
       "  convolution_param {\n",
       "    num_output: 128\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"358_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"357\"\n",
       "  top: \"358\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"358\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"358\"\n",
       "  top: \"358\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"359_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"358\"\n",
       "  top: \"359\"\n",
       "}\n",
       "layer {\n",
       "  name: \"360\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"359\"\n",
       "  top: \"360\"\n",
       "  convolution_param {\n",
       "    num_output: 128\n",
       "    bias_term: false\n",
       "    group: 128\n",
       "    pad_h: 1\n",
       "    pad_w: 1\n",
       "    kernel_h: 3\n",
       "    kernel_w: 3\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"361_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"360\"\n",
       "  top: \"361\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"361\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"361\"\n",
       "  top: \"361\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"362_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"361\"\n",
       "  top: \"362\"\n",
       "}\n",
       "layer {\n",
       "  name: \"363\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"362\"\n",
       "  top: \"363\"\n",
       "  convolution_param {\n",
       "    num_output: 64\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"364_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"363\"\n",
       "  top: \"364\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"364\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"364\"\n",
       "  top: \"364\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"365\"\n",
       "  type: \"Eltwise\"\n",
       "  bottom: \"356\"\n",
       "  bottom: \"364\"\n",
       "  top: \"365\"\n",
       "  eltwise_param {\n",
       "    operation: SUM\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"366\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"365\"\n",
       "  top: \"366\"\n",
       "  convolution_param {\n",
       "    num_output: 128\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"367_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"366\"\n",
       "  top: \"367\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"367\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"367\"\n",
       "  top: \"367\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"368_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"367\"\n",
       "  top: \"368\"\n",
       "}\n",
       "layer {\n",
       "  name: \"369\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"368\"\n",
       "  top: \"369\"\n",
       "  convolution_param {\n",
       "    num_output: 128\n",
       "    bias_term: false\n",
       "    group: 128\n",
       "    pad_h: 1\n",
       "    pad_w: 1\n",
       "    kernel_h: 3\n",
       "    kernel_w: 3\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"370_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"369\"\n",
       "  top: \"370\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"370\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"370\"\n",
       "  top: \"370\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"371_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"370\"\n",
       "  top: \"371\"\n",
       "}\n",
       "layer {\n",
       "  name: \"372\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"371\"\n",
       "  top: \"372\"\n",
       "  convolution_param {\n",
       "    num_output: 64\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"373_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"372\"\n",
       "  top: \"373\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"373\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"373\"\n",
       "  top: \"373\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"374\"\n",
       "  type: \"Eltwise\"\n",
       "  bottom: \"365\"\n",
       "  bottom: \"373\"\n",
       "  top: \"374\"\n",
       "  eltwise_param {\n",
       "    operation: SUM\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"375\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"374\"\n",
       "  top: \"375\"\n",
       "  convolution_param {\n",
       "    num_output: 128\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"376_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"375\"\n",
       "  top: \"376\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"376\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"376\"\n",
       "  top: \"376\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"377_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"376\"\n",
       "  top: \"377\"\n",
       "}\n",
       "layer {\n",
       "  name: \"378\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"377\"\n",
       "  top: \"378\"\n",
       "  convolution_param {\n",
       "    num_output: 128\n",
       "    bias_term: false\n",
       "    group: 128\n",
       "    pad_h: 1\n",
       "    pad_w: 1\n",
       "    kernel_h: 3\n",
       "    kernel_w: 3\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"379_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"378\"\n",
       "  top: \"379\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"379\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"379\"\n",
       "  top: \"379\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"380_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"379\"\n",
       "  top: \"380\"\n",
       "}\n",
       "layer {\n",
       "  name: \"381\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"380\"\n",
       "  top: \"381\"\n",
       "  convolution_param {\n",
       "    num_output: 64\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"382_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"381\"\n",
       "  top: \"382\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"382\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"382\"\n",
       "  top: \"382\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"383\"\n",
       "  type: \"Eltwise\"\n",
       "  bottom: \"374\"\n",
       "  bottom: \"382\"\n",
       "  top: \"383\"\n",
       "  eltwise_param {\n",
       "    operation: SUM\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"384\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"383\"\n",
       "  top: \"384\"\n",
       "  convolution_param {\n",
       "    num_output: 256\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"385_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"384\"\n",
       "  top: \"385\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"385\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"385\"\n",
       "  top: \"385\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"386_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"385\"\n",
       "  top: \"386\"\n",
       "}\n",
       "layer {\n",
       "  name: \"387\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"386\"\n",
       "  top: \"387\"\n",
       "  convolution_param {\n",
       "    num_output: 256\n",
       "    bias_term: false\n",
       "    group: 256\n",
       "    pad_h: 1\n",
       "    pad_w: 1\n",
       "    kernel_h: 3\n",
       "    kernel_w: 3\n",
       "    stride_h: 2\n",
       "    stride_w: 2\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"388_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"387\"\n",
       "  top: \"388\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"388\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"388\"\n",
       "  top: \"388\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"389_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"388\"\n",
       "  top: \"389\"\n",
       "}\n",
       "layer {\n",
       "  name: \"390\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"389\"\n",
       "  top: \"390\"\n",
       "  convolution_param {\n",
       "    num_output: 128\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"391_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"390\"\n",
       "  top: \"391\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"391\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"391\"\n",
       "  top: \"391\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"392\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"391\"\n",
       "  top: \"392\"\n",
       "  convolution_param {\n",
       "    num_output: 256\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"393_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"392\"\n",
       "  top: \"393\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"393\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"393\"\n",
       "  top: \"393\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"394_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"393\"\n",
       "  top: \"394\"\n",
       "}\n",
       "layer {\n",
       "  name: \"395\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"394\"\n",
       "  top: \"395\"\n",
       "  convolution_param {\n",
       "    num_output: 256\n",
       "    bias_term: false\n",
       "    group: 256\n",
       "    pad_h: 1\n",
       "    pad_w: 1\n",
       "    kernel_h: 3\n",
       "    kernel_w: 3\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"396_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"395\"\n",
       "  top: \"396\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"396\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"396\"\n",
       "  top: \"396\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"397_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"396\"\n",
       "  top: \"397\"\n",
       "}\n",
       "layer {\n",
       "  name: \"398\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"397\"\n",
       "  top: \"398\"\n",
       "  convolution_param {\n",
       "    num_output: 128\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"399_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"398\"\n",
       "  top: \"399\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"399\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"399\"\n",
       "  top: \"399\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"400\"\n",
       "  type: \"Eltwise\"\n",
       "  bottom: \"391\"\n",
       "  bottom: \"399\"\n",
       "  top: \"400\"\n",
       "  eltwise_param {\n",
       "    operation: SUM\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"401\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"400\"\n",
       "  top: \"401\"\n",
       "  convolution_param {\n",
       "    num_output: 256\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"402_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"401\"\n",
       "  top: \"402\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"402\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"402\"\n",
       "  top: \"402\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"403_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"402\"\n",
       "  top: \"403\"\n",
       "}\n",
       "layer {\n",
       "  name: \"404\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"403\"\n",
       "  top: \"404\"\n",
       "  convolution_param {\n",
       "    num_output: 256\n",
       "    bias_term: false\n",
       "    group: 256\n",
       "    pad_h: 1\n",
       "    pad_w: 1\n",
       "    kernel_h: 3\n",
       "    kernel_w: 3\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"405_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"404\"\n",
       "  top: \"405\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"405\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"405\"\n",
       "  top: \"405\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"406_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"405\"\n",
       "  top: \"406\"\n",
       "}\n",
       "layer {\n",
       "  name: \"407\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"406\"\n",
       "  top: \"407\"\n",
       "  convolution_param {\n",
       "    num_output: 128\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"408_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"407\"\n",
       "  top: \"408\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"408\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"408\"\n",
       "  top: \"408\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"409\"\n",
       "  type: \"Eltwise\"\n",
       "  bottom: \"400\"\n",
       "  bottom: \"408\"\n",
       "  top: \"409\"\n",
       "  eltwise_param {\n",
       "    operation: SUM\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"410\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"409\"\n",
       "  top: \"410\"\n",
       "  convolution_param {\n",
       "    num_output: 256\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"411_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"410\"\n",
       "  top: \"411\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"411\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"411\"\n",
       "  top: \"411\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"412_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"411\"\n",
       "  top: \"412\"\n",
       "}\n",
       "layer {\n",
       "  name: \"413\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"412\"\n",
       "  top: \"413\"\n",
       "  convolution_param {\n",
       "    num_output: 256\n",
       "    bias_term: false\n",
       "    group: 256\n",
       "    pad_h: 1\n",
       "    pad_w: 1\n",
       "    kernel_h: 3\n",
       "    kernel_w: 3\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"414_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"413\"\n",
       "  top: \"414\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"414\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"414\"\n",
       "  top: \"414\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"415_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"414\"\n",
       "  top: \"415\"\n",
       "}\n",
       "layer {\n",
       "  name: \"416\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"415\"\n",
       "  top: \"416\"\n",
       "  convolution_param {\n",
       "    num_output: 128\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"417_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"416\"\n",
       "  top: \"417\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"417\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"417\"\n",
       "  top: \"417\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"418\"\n",
       "  type: \"Eltwise\"\n",
       "  bottom: \"409\"\n",
       "  bottom: \"417\"\n",
       "  top: \"418\"\n",
       "  eltwise_param {\n",
       "    operation: SUM\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"419\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"418\"\n",
       "  top: \"419\"\n",
       "  convolution_param {\n",
       "    num_output: 256\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"420_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"419\"\n",
       "  top: \"420\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"420\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"420\"\n",
       "  top: \"420\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"421_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"420\"\n",
       "  top: \"421\"\n",
       "}\n",
       "layer {\n",
       "  name: \"422\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"421\"\n",
       "  top: \"422\"\n",
       "  convolution_param {\n",
       "    num_output: 256\n",
       "    bias_term: false\n",
       "    group: 256\n",
       "    pad_h: 1\n",
       "    pad_w: 1\n",
       "    kernel_h: 3\n",
       "    kernel_w: 3\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"423_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"422\"\n",
       "  top: \"423\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"423\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"423\"\n",
       "  top: \"423\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"424_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"423\"\n",
       "  top: \"424\"\n",
       "}\n",
       "layer {\n",
       "  name: \"425\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"424\"\n",
       "  top: \"425\"\n",
       "  convolution_param {\n",
       "    num_output: 128\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"426_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"425\"\n",
       "  top: \"426\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"426\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"426\"\n",
       "  top: \"426\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"427\"\n",
       "  type: \"Eltwise\"\n",
       "  bottom: \"418\"\n",
       "  bottom: \"426\"\n",
       "  top: \"427\"\n",
       "  eltwise_param {\n",
       "    operation: SUM\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"428\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"427\"\n",
       "  top: \"428\"\n",
       "  convolution_param {\n",
       "    num_output: 256\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"429_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"428\"\n",
       "  top: \"429\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"429\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"429\"\n",
       "  top: \"429\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"430_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"429\"\n",
       "  top: \"430\"\n",
       "}\n",
       "layer {\n",
       "  name: \"431\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"430\"\n",
       "  top: \"431\"\n",
       "  convolution_param {\n",
       "    num_output: 256\n",
       "    bias_term: false\n",
       "    group: 256\n",
       "    pad_h: 1\n",
       "    pad_w: 1\n",
       "    kernel_h: 3\n",
       "    kernel_w: 3\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"432_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"431\"\n",
       "  top: \"432\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"432\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"432\"\n",
       "  top: \"432\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"433_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"432\"\n",
       "  top: \"433\"\n",
       "}\n",
       "layer {\n",
       "  name: \"434\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"433\"\n",
       "  top: \"434\"\n",
       "  convolution_param {\n",
       "    num_output: 128\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"435_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"434\"\n",
       "  top: \"435\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"435\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"435\"\n",
       "  top: \"435\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"436\"\n",
       "  type: \"Eltwise\"\n",
       "  bottom: \"427\"\n",
       "  bottom: \"435\"\n",
       "  top: \"436\"\n",
       "  eltwise_param {\n",
       "    operation: SUM\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"437\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"436\"\n",
       "  top: \"437\"\n",
       "  convolution_param {\n",
       "    num_output: 256\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"438_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"437\"\n",
       "  top: \"438\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"438\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"438\"\n",
       "  top: \"438\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"439_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"438\"\n",
       "  top: \"439\"\n",
       "}\n",
       "layer {\n",
       "  name: \"440\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"439\"\n",
       "  top: \"440\"\n",
       "  convolution_param {\n",
       "    num_output: 256\n",
       "    bias_term: false\n",
       "    group: 256\n",
       "    pad_h: 1\n",
       "    pad_w: 1\n",
       "    kernel_h: 3\n",
       "    kernel_w: 3\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"441_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"440\"\n",
       "  top: \"441\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"441\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"441\"\n",
       "  top: \"441\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"442_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"441\"\n",
       "  top: \"442\"\n",
       "}\n",
       "layer {\n",
       "  name: \"443\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"442\"\n",
       "  top: \"443\"\n",
       "  convolution_param {\n",
       "    num_output: 128\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"444_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"443\"\n",
       "  top: \"444\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"444\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"444\"\n",
       "  top: \"444\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"445\"\n",
       "  type: \"Eltwise\"\n",
       "  bottom: \"436\"\n",
       "  bottom: \"444\"\n",
       "  top: \"445\"\n",
       "  eltwise_param {\n",
       "    operation: SUM\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"446\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"445\"\n",
       "  top: \"446\"\n",
       "  convolution_param {\n",
       "    num_output: 512\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"447_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"446\"\n",
       "  top: \"447\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"447\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"447\"\n",
       "  top: \"447\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"448_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"447\"\n",
       "  top: \"448\"\n",
       "}\n",
       "layer {\n",
       "  name: \"449\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"448\"\n",
       "  top: \"449\"\n",
       "  convolution_param {\n",
       "    num_output: 512\n",
       "    bias_term: false\n",
       "    group: 512\n",
       "    pad_h: 1\n",
       "    pad_w: 1\n",
       "    kernel_h: 3\n",
       "    kernel_w: 3\n",
       "    stride_h: 2\n",
       "    stride_w: 2\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"450_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"449\"\n",
       "  top: \"450\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"450\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"450\"\n",
       "  top: \"450\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"451_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"450\"\n",
       "  top: \"451\"\n",
       "}\n",
       "layer {\n",
       "  name: \"452\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"451\"\n",
       "  top: \"452\"\n",
       "  convolution_param {\n",
       "    num_output: 128\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"453_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"452\"\n",
       "  top: \"453\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"453\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"453\"\n",
       "  top: \"453\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"454\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"453\"\n",
       "  top: \"454\"\n",
       "  convolution_param {\n",
       "    num_output: 256\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"455_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"454\"\n",
       "  top: \"455\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"455\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"455\"\n",
       "  top: \"455\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"456_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"455\"\n",
       "  top: \"456\"\n",
       "}\n",
       "layer {\n",
       "  name: \"457\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"456\"\n",
       "  top: \"457\"\n",
       "  convolution_param {\n",
       "    num_output: 256\n",
       "    bias_term: false\n",
       "    group: 256\n",
       "    pad_h: 1\n",
       "    pad_w: 1\n",
       "    kernel_h: 3\n",
       "    kernel_w: 3\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"458_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"457\"\n",
       "  top: \"458\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"458\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"458\"\n",
       "  top: \"458\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"459_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"458\"\n",
       "  top: \"459\"\n",
       "}\n",
       "layer {\n",
       "  name: \"460\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"459\"\n",
       "  top: \"460\"\n",
       "  convolution_param {\n",
       "    num_output: 128\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"461_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"460\"\n",
       "  top: \"461\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"461\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"461\"\n",
       "  top: \"461\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"462\"\n",
       "  type: \"Eltwise\"\n",
       "  bottom: \"453\"\n",
       "  bottom: \"461\"\n",
       "  top: \"462\"\n",
       "  eltwise_param {\n",
       "    operation: SUM\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"463\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"462\"\n",
       "  top: \"463\"\n",
       "  convolution_param {\n",
       "    num_output: 256\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"464_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"463\"\n",
       "  top: \"464\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"464\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"464\"\n",
       "  top: \"464\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"465_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"464\"\n",
       "  top: \"465\"\n",
       "}\n",
       "layer {\n",
       "  name: \"466\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"465\"\n",
       "  top: \"466\"\n",
       "  convolution_param {\n",
       "    num_output: 256\n",
       "    bias_term: false\n",
       "    group: 256\n",
       "    pad_h: 1\n",
       "    pad_w: 1\n",
       "    kernel_h: 3\n",
       "    kernel_w: 3\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"467_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"466\"\n",
       "  top: \"467\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"467\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"467\"\n",
       "  top: \"467\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"468_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"467\"\n",
       "  top: \"468\"\n",
       "}\n",
       "layer {\n",
       "  name: \"469\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"468\"\n",
       "  top: \"469\"\n",
       "  convolution_param {\n",
       "    num_output: 128\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"470_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"469\"\n",
       "  top: \"470\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"470\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"470\"\n",
       "  top: \"470\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"471\"\n",
       "  type: \"Eltwise\"\n",
       "  bottom: \"462\"\n",
       "  bottom: \"470\"\n",
       "  top: \"471\"\n",
       "  eltwise_param {\n",
       "    operation: SUM\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"472\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"471\"\n",
       "  top: \"472\"\n",
       "  convolution_param {\n",
       "    num_output: 512\n",
       "    bias_term: false\n",
       "    group: 1\n",
       "    pad_h: 0\n",
       "    pad_w: 0\n",
       "    kernel_h: 1\n",
       "    kernel_w: 1\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "    dilation: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"473_bn\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"472\"\n",
       "  top: \"473\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"473\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"473\"\n",
       "  top: \"473\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"474_prelu\"\n",
       "  type: \"PReLU\"\n",
       "  bottom: \"473\"\n",
       "  top: \"474\"\n",
       "}\n",
       "layer {\n",
       "  name: \"bn1\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"474\"\n",
       "  top: \"475\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"bn1_scale\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"475\"\n",
       "  top: \"475\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"fc_emb\"\n",
       "  type: \"InnerProduct\"\n",
       "  bottom: \"475\"\n",
       "  top: \"476\"\n",
       "  param {\n",
       "    lr_mult: 1.0\n",
       "    decay_mult: 1.0\n",
       "  }\n",
       "  param {\n",
       "    lr_mult: 2.0\n",
       "    decay_mult: 0.0\n",
       "  }\n",
       "  inner_product_param {\n",
       "    num_output: 512\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"bn2\"\n",
       "  type: \"BatchNorm\"\n",
       "  bottom: \"476\"\n",
       "  top: \"477\"\n",
       "  batch_norm_param {\n",
       "    use_global_stats: true\n",
       "    eps: 9.999999747378752e-06\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"bn2_scale\"\n",
       "  type: \"Scale\"\n",
       "  bottom: \"477\"\n",
       "  top: \"477\"\n",
       "  scale_param {\n",
       "    bias_term: true\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_format.Merge(net_str, net_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "334\n",
      "335_bn\n",
      "335\n",
      "336_prelu\n",
      "337\n",
      "338_bn\n",
      "338\n",
      "339_prelu\n",
      "340\n",
      "341_bn\n",
      "341\n",
      "342_prelu\n",
      "343\n",
      "344_bn\n",
      "344\n",
      "345_prelu\n",
      "346\n",
      "347_bn\n",
      "347\n",
      "348\n",
      "349_bn\n",
      "349\n",
      "350_prelu\n",
      "351\n",
      "352_bn\n",
      "352\n",
      "353_prelu\n",
      "354\n",
      "355_bn\n",
      "355\n",
      "356\n",
      "357\n",
      "358_bn\n",
      "358\n",
      "359_prelu\n",
      "360\n",
      "361_bn\n",
      "361\n",
      "362_prelu\n",
      "363\n",
      "364_bn\n",
      "364\n",
      "365\n",
      "366\n",
      "367_bn\n",
      "367\n",
      "368_prelu\n",
      "369\n",
      "370_bn\n",
      "370\n",
      "371_prelu\n",
      "372\n",
      "373_bn\n",
      "373\n",
      "374\n",
      "375\n",
      "376_bn\n",
      "376\n",
      "377_prelu\n",
      "378\n",
      "379_bn\n",
      "379\n",
      "380_prelu\n",
      "381\n",
      "382_bn\n",
      "382\n",
      "383\n",
      "384\n",
      "385_bn\n",
      "385\n",
      "386_prelu\n",
      "387\n",
      "388_bn\n",
      "388\n",
      "389_prelu\n",
      "390\n",
      "391_bn\n",
      "391\n",
      "392\n",
      "393_bn\n",
      "393\n",
      "394_prelu\n",
      "395\n",
      "396_bn\n",
      "396\n",
      "397_prelu\n",
      "398\n",
      "399_bn\n",
      "399\n",
      "400\n",
      "401\n",
      "402_bn\n",
      "402\n",
      "403_prelu\n",
      "404\n",
      "405_bn\n",
      "405\n",
      "406_prelu\n",
      "407\n",
      "408_bn\n",
      "408\n",
      "409\n",
      "410\n",
      "411_bn\n",
      "411\n",
      "412_prelu\n",
      "413\n",
      "414_bn\n",
      "414\n",
      "415_prelu\n",
      "416\n",
      "417_bn\n",
      "417\n",
      "418\n",
      "419\n",
      "420_bn\n",
      "420\n",
      "421_prelu\n",
      "422\n",
      "423_bn\n",
      "423\n",
      "424_prelu\n",
      "425\n",
      "426_bn\n",
      "426\n",
      "427\n",
      "428\n",
      "429_bn\n",
      "429\n",
      "430_prelu\n",
      "431\n",
      "432_bn\n",
      "432\n",
      "433_prelu\n",
      "434\n",
      "435_bn\n",
      "435\n",
      "436\n",
      "437\n",
      "438_bn\n",
      "438\n",
      "439_prelu\n",
      "440\n",
      "441_bn\n",
      "441\n",
      "442_prelu\n",
      "443\n",
      "444_bn\n",
      "444\n",
      "445\n",
      "446\n",
      "447_bn\n",
      "447\n",
      "448_prelu\n",
      "449\n",
      "450_bn\n",
      "450\n",
      "451_prelu\n",
      "452\n",
      "453_bn\n",
      "453\n",
      "454\n",
      "455_bn\n",
      "455\n",
      "456_prelu\n",
      "457\n",
      "458_bn\n",
      "458\n",
      "459_prelu\n",
      "460\n",
      "461_bn\n",
      "461\n",
      "462\n",
      "463\n",
      "464_bn\n",
      "464\n",
      "465_prelu\n",
      "466\n",
      "467_bn\n",
      "467\n",
      "468_prelu\n",
      "469\n",
      "470_bn\n",
      "470\n",
      "471\n",
      "472\n",
      "473_bn\n",
      "473\n",
      "474_prelu\n",
      "bn1\n",
      "bn1_scale\n",
      "fc_emb\n",
      "bn2\n",
      "bn2_scale\n"
     ]
    }
   ],
   "source": [
    "for layer in net_params.layer:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                   , type:Input\n",
      " -------------\n",
      "     from: \n",
      "     to  : 0                    \n",
      "------------- \n",
      "\n",
      "334                 , type:Convolution\n",
      " -------------     weight:(64, 3, 3, 3)\n",
      "     from: 0                    \n",
      "     to  : 334                  \n",
      "------------- \n",
      "\n",
      "335_bn              , type:BatchNorm\n",
      " -------------     weight:(64,)     weight:(64,)     weight:(1,)\n",
      "     from: 334                  \n",
      "     to  : 335                  \n",
      "------------- \n",
      "\n",
      "335                 , type:Scale\n",
      " -------------     weight:(64,)     weight:(64,)\n",
      "     from: 335                  \n",
      "     to  : 335                  \n",
      "------------- \n",
      "\n",
      "336_prelu           , type:PReLU\n",
      " -------------     weight:(64,)\n",
      "     from: 335                  \n",
      "     to  : 336                  \n",
      "------------- \n",
      "\n",
      "337                 , type:Convolution\n",
      " -------------     weight:(64, 1, 3, 3)\n",
      "     from: 336                  \n",
      "     to  : 337                  \n",
      "------------- \n",
      "\n",
      "338_bn              , type:BatchNorm\n",
      " -------------     weight:(64,)     weight:(64,)     weight:(1,)\n",
      "     from: 337                  \n",
      "     to  : 338                  \n",
      "------------- \n",
      "\n",
      "338                 , type:Scale\n",
      " -------------     weight:(64,)     weight:(64,)\n",
      "     from: 338                  \n",
      "     to  : 338                  \n",
      "------------- \n",
      "\n",
      "339_prelu           , type:PReLU\n",
      " -------------     weight:(64,)\n",
      "     from: 338                  \n",
      "     to  : 339                  \n",
      "------------- \n",
      "\n",
      "340                 , type:Convolution\n",
      " -------------     weight:(128, 64, 1, 1)\n",
      "     from: 339                  \n",
      "     to  : 340                  \n",
      "------------- \n",
      "\n",
      "341_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 340                  \n",
      "     to  : 341                  \n",
      "------------- \n",
      "\n",
      "341                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 341                  \n",
      "     to  : 341                  \n",
      "------------- \n",
      "\n",
      "342_prelu           , type:PReLU\n",
      " -------------     weight:(128,)\n",
      "     from: 341                  \n",
      "     to  : 342                  \n",
      "------------- \n",
      "\n",
      "343                 , type:Convolution\n",
      " -------------     weight:(128, 1, 3, 3)\n",
      "     from: 342                  \n",
      "     to  : 343                  \n",
      "------------- \n",
      "\n",
      "344_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 343                  \n",
      "     to  : 344                  \n",
      "------------- \n",
      "\n",
      "344                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 344                  \n",
      "     to  : 344                  \n",
      "------------- \n",
      "\n",
      "345_prelu           , type:PReLU\n",
      " -------------     weight:(128,)\n",
      "     from: 344                  \n",
      "     to  : 345                  \n",
      "------------- \n",
      "\n",
      "346                 , type:Convolution\n",
      " -------------     weight:(64, 128, 1, 1)\n",
      "     from: 345                  \n",
      "     to  : 346                  \n",
      "------------- \n",
      "\n",
      "347_bn              , type:BatchNorm\n",
      " -------------     weight:(64,)     weight:(64,)     weight:(1,)\n",
      "     from: 346                  \n",
      "     to  : 347                  \n",
      "------------- \n",
      "\n",
      "347                 , type:Scale\n",
      " -------------     weight:(64,)     weight:(64,)\n",
      "     from: 347                  \n",
      "     to  : 347                  \n",
      "------------- \n",
      "\n",
      "348                 , type:Convolution\n",
      " -------------     weight:(128, 64, 1, 1)\n",
      "     from: 347                  \n",
      "     to  : 348                  \n",
      "------------- \n",
      "\n",
      "349_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 348                  \n",
      "     to  : 349                  \n",
      "------------- \n",
      "\n",
      "349                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 349                  \n",
      "     to  : 349                  \n",
      "------------- \n",
      "\n",
      "350_prelu           , type:PReLU\n",
      " -------------     weight:(128,)\n",
      "     from: 349                  \n",
      "     to  : 350                  \n",
      "------------- \n",
      "\n",
      "351                 , type:Convolution\n",
      " -------------     weight:(128, 1, 3, 3)\n",
      "     from: 350                  \n",
      "     to  : 351                  \n",
      "------------- \n",
      "\n",
      "352_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 351                  \n",
      "     to  : 352                  \n",
      "------------- \n",
      "\n",
      "352                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 352                  \n",
      "     to  : 352                  \n",
      "------------- \n",
      "\n",
      "353_prelu           , type:PReLU\n",
      " -------------     weight:(128,)\n",
      "     from: 352                  \n",
      "     to  : 353                  \n",
      "------------- \n",
      "\n",
      "354                 , type:Convolution\n",
      " -------------     weight:(64, 128, 1, 1)\n",
      "     from: 353                  \n",
      "     to  : 354                  \n",
      "------------- \n",
      "\n",
      "355_bn              , type:BatchNorm\n",
      " -------------     weight:(64,)     weight:(64,)     weight:(1,)\n",
      "     from: 354                  \n",
      "     to  : 355                  \n",
      "------------- \n",
      "\n",
      "355                 , type:Scale\n",
      " -------------     weight:(64,)     weight:(64,)\n",
      "     from: 355                  \n",
      "     to  : 355                  \n",
      "------------- \n",
      "\n",
      "356                 , type:Eltwise\n",
      " -------------\n",
      "     from: 347                  355                  \n",
      "     to  : 356                  \n",
      "------------- \n",
      "\n",
      "357                 , type:Convolution\n",
      " -------------     weight:(128, 64, 1, 1)\n",
      "     from: 356                  \n",
      "     to  : 357                  \n",
      "------------- \n",
      "\n",
      "358_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 357                  \n",
      "     to  : 358                  \n",
      "------------- \n",
      "\n",
      "358                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 358                  \n",
      "     to  : 358                  \n",
      "------------- \n",
      "\n",
      "359_prelu           , type:PReLU\n",
      " -------------     weight:(128,)\n",
      "     from: 358                  \n",
      "     to  : 359                  \n",
      "------------- \n",
      "\n",
      "360                 , type:Convolution\n",
      " -------------     weight:(128, 1, 3, 3)\n",
      "     from: 359                  \n",
      "     to  : 360                  \n",
      "------------- \n",
      "\n",
      "361_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 360                  \n",
      "     to  : 361                  \n",
      "------------- \n",
      "\n",
      "361                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 361                  \n",
      "     to  : 361                  \n",
      "------------- \n",
      "\n",
      "362_prelu           , type:PReLU\n",
      " -------------     weight:(128,)\n",
      "     from: 361                  \n",
      "     to  : 362                  \n",
      "------------- \n",
      "\n",
      "363                 , type:Convolution\n",
      " -------------     weight:(64, 128, 1, 1)\n",
      "     from: 362                  \n",
      "     to  : 363                  \n",
      "------------- \n",
      "\n",
      "364_bn              , type:BatchNorm\n",
      " -------------     weight:(64,)     weight:(64,)     weight:(1,)\n",
      "     from: 363                  \n",
      "     to  : 364                  \n",
      "------------- \n",
      "\n",
      "364                 , type:Scale\n",
      " -------------     weight:(64,)     weight:(64,)\n",
      "     from: 364                  \n",
      "     to  : 364                  \n",
      "------------- \n",
      "\n",
      "365                 , type:Eltwise\n",
      " -------------\n",
      "     from: 356                  364                  \n",
      "     to  : 365                  \n",
      "------------- \n",
      "\n",
      "366                 , type:Convolution\n",
      " -------------     weight:(128, 64, 1, 1)\n",
      "     from: 365                  \n",
      "     to  : 366                  \n",
      "------------- \n",
      "\n",
      "367_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 366                  \n",
      "     to  : 367                  \n",
      "------------- \n",
      "\n",
      "367                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 367                  \n",
      "     to  : 367                  \n",
      "------------- \n",
      "\n",
      "368_prelu           , type:PReLU\n",
      " -------------     weight:(128,)\n",
      "     from: 367                  \n",
      "     to  : 368                  \n",
      "------------- \n",
      "\n",
      "369                 , type:Convolution\n",
      " -------------     weight:(128, 1, 3, 3)\n",
      "     from: 368                  \n",
      "     to  : 369                  \n",
      "------------- \n",
      "\n",
      "370_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 369                  \n",
      "     to  : 370                  \n",
      "------------- \n",
      "\n",
      "370                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 370                  \n",
      "     to  : 370                  \n",
      "------------- \n",
      "\n",
      "371_prelu           , type:PReLU\n",
      " -------------     weight:(128,)\n",
      "     from: 370                  \n",
      "     to  : 371                  \n",
      "------------- \n",
      "\n",
      "372                 , type:Convolution\n",
      " -------------     weight:(64, 128, 1, 1)\n",
      "     from: 371                  \n",
      "     to  : 372                  \n",
      "------------- \n",
      "\n",
      "373_bn              , type:BatchNorm\n",
      " -------------     weight:(64,)     weight:(64,)     weight:(1,)\n",
      "     from: 372                  \n",
      "     to  : 373                  \n",
      "------------- \n",
      "\n",
      "373                 , type:Scale\n",
      " -------------     weight:(64,)     weight:(64,)\n",
      "     from: 373                  \n",
      "     to  : 373                  \n",
      "------------- \n",
      "\n",
      "374                 , type:Eltwise\n",
      " -------------\n",
      "     from: 365                  373                  \n",
      "     to  : 374                  \n",
      "------------- \n",
      "\n",
      "375                 , type:Convolution\n",
      " -------------     weight:(128, 64, 1, 1)\n",
      "     from: 374                  \n",
      "     to  : 375                  \n",
      "------------- \n",
      "\n",
      "376_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 375                  \n",
      "     to  : 376                  \n",
      "------------- \n",
      "\n",
      "376                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 376                  \n",
      "     to  : 376                  \n",
      "------------- \n",
      "\n",
      "377_prelu           , type:PReLU\n",
      " -------------     weight:(128,)\n",
      "     from: 376                  \n",
      "     to  : 377                  \n",
      "------------- \n",
      "\n",
      "378                 , type:Convolution\n",
      " -------------     weight:(128, 1, 3, 3)\n",
      "     from: 377                  \n",
      "     to  : 378                  \n",
      "------------- \n",
      "\n",
      "379_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 378                  \n",
      "     to  : 379                  \n",
      "------------- \n",
      "\n",
      "379                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 379                  \n",
      "     to  : 379                  \n",
      "------------- \n",
      "\n",
      "380_prelu           , type:PReLU\n",
      " -------------     weight:(128,)\n",
      "     from: 379                  \n",
      "     to  : 380                  \n",
      "------------- \n",
      "\n",
      "381                 , type:Convolution\n",
      " -------------     weight:(64, 128, 1, 1)\n",
      "     from: 380                  \n",
      "     to  : 381                  \n",
      "------------- \n",
      "\n",
      "382_bn              , type:BatchNorm\n",
      " -------------     weight:(64,)     weight:(64,)     weight:(1,)\n",
      "     from: 381                  \n",
      "     to  : 382                  \n",
      "------------- \n",
      "\n",
      "382                 , type:Scale\n",
      " -------------     weight:(64,)     weight:(64,)\n",
      "     from: 382                  \n",
      "     to  : 382                  \n",
      "------------- \n",
      "\n",
      "383                 , type:Eltwise\n",
      " -------------\n",
      "     from: 374                  382                  \n",
      "     to  : 383                  \n",
      "------------- \n",
      "\n",
      "384                 , type:Convolution\n",
      " -------------     weight:(256, 64, 1, 1)\n",
      "     from: 383                  \n",
      "     to  : 384                  \n",
      "------------- \n",
      "\n",
      "385_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 384                  \n",
      "     to  : 385                  \n",
      "------------- \n",
      "\n",
      "385                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 385                  \n",
      "     to  : 385                  \n",
      "------------- \n",
      "\n",
      "386_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 385                  \n",
      "     to  : 386                  \n",
      "------------- \n",
      "\n",
      "387                 , type:Convolution\n",
      " -------------     weight:(256, 1, 3, 3)\n",
      "     from: 386                  \n",
      "     to  : 387                  \n",
      "------------- \n",
      "\n",
      "388_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 387                  \n",
      "     to  : 388                  \n",
      "------------- \n",
      "\n",
      "388                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 388                  \n",
      "     to  : 388                  \n",
      "------------- \n",
      "\n",
      "389_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 388                  \n",
      "     to  : 389                  \n",
      "------------- \n",
      "\n",
      "390                 , type:Convolution\n",
      " -------------     weight:(128, 256, 1, 1)\n",
      "     from: 389                  \n",
      "     to  : 390                  \n",
      "------------- \n",
      "\n",
      "391_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 390                  \n",
      "     to  : 391                  \n",
      "------------- \n",
      "\n",
      "391                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 391                  \n",
      "     to  : 391                  \n",
      "------------- \n",
      "\n",
      "392                 , type:Convolution\n",
      " -------------     weight:(256, 128, 1, 1)\n",
      "     from: 391                  \n",
      "     to  : 392                  \n",
      "------------- \n",
      "\n",
      "393_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 392                  \n",
      "     to  : 393                  \n",
      "------------- \n",
      "\n",
      "393                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 393                  \n",
      "     to  : 393                  \n",
      "------------- \n",
      "\n",
      "394_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 393                  \n",
      "     to  : 394                  \n",
      "------------- \n",
      "\n",
      "395                 , type:Convolution\n",
      " -------------     weight:(256, 1, 3, 3)\n",
      "     from: 394                  \n",
      "     to  : 395                  \n",
      "------------- \n",
      "\n",
      "396_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 395                  \n",
      "     to  : 396                  \n",
      "------------- \n",
      "\n",
      "396                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 396                  \n",
      "     to  : 396                  \n",
      "------------- \n",
      "\n",
      "397_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 396                  \n",
      "     to  : 397                  \n",
      "------------- \n",
      "\n",
      "398                 , type:Convolution\n",
      " -------------     weight:(128, 256, 1, 1)\n",
      "     from: 397                  \n",
      "     to  : 398                  \n",
      "------------- \n",
      "\n",
      "399_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 398                  \n",
      "     to  : 399                  \n",
      "------------- \n",
      "\n",
      "399                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 399                  \n",
      "     to  : 399                  \n",
      "------------- \n",
      "\n",
      "400                 , type:Eltwise\n",
      " -------------\n",
      "     from: 391                  399                  \n",
      "     to  : 400                  \n",
      "------------- \n",
      "\n",
      "401                 , type:Convolution\n",
      " -------------     weight:(256, 128, 1, 1)\n",
      "     from: 400                  \n",
      "     to  : 401                  \n",
      "------------- \n",
      "\n",
      "402_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 401                  \n",
      "     to  : 402                  \n",
      "------------- \n",
      "\n",
      "402                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 402                  \n",
      "     to  : 402                  \n",
      "------------- \n",
      "\n",
      "403_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 402                  \n",
      "     to  : 403                  \n",
      "------------- \n",
      "\n",
      "404                 , type:Convolution\n",
      " -------------     weight:(256, 1, 3, 3)\n",
      "     from: 403                  \n",
      "     to  : 404                  \n",
      "------------- \n",
      "\n",
      "405_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 404                  \n",
      "     to  : 405                  \n",
      "------------- \n",
      "\n",
      "405                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 405                  \n",
      "     to  : 405                  \n",
      "------------- \n",
      "\n",
      "406_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 405                  \n",
      "     to  : 406                  \n",
      "------------- \n",
      "\n",
      "407                 , type:Convolution\n",
      " -------------     weight:(128, 256, 1, 1)\n",
      "     from: 406                  \n",
      "     to  : 407                  \n",
      "------------- \n",
      "\n",
      "408_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 407                  \n",
      "     to  : 408                  \n",
      "------------- \n",
      "\n",
      "408                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 408                  \n",
      "     to  : 408                  \n",
      "------------- \n",
      "\n",
      "409                 , type:Eltwise\n",
      " -------------\n",
      "     from: 400                  408                  \n",
      "     to  : 409                  \n",
      "------------- \n",
      "\n",
      "410                 , type:Convolution\n",
      " -------------     weight:(256, 128, 1, 1)\n",
      "     from: 409                  \n",
      "     to  : 410                  \n",
      "------------- \n",
      "\n",
      "411_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 410                  \n",
      "     to  : 411                  \n",
      "------------- \n",
      "\n",
      "411                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 411                  \n",
      "     to  : 411                  \n",
      "------------- \n",
      "\n",
      "412_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 411                  \n",
      "     to  : 412                  \n",
      "------------- \n",
      "\n",
      "413                 , type:Convolution\n",
      " -------------     weight:(256, 1, 3, 3)\n",
      "     from: 412                  \n",
      "     to  : 413                  \n",
      "------------- \n",
      "\n",
      "414_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 413                  \n",
      "     to  : 414                  \n",
      "------------- \n",
      "\n",
      "414                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 414                  \n",
      "     to  : 414                  \n",
      "------------- \n",
      "\n",
      "415_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 414                  \n",
      "     to  : 415                  \n",
      "------------- \n",
      "\n",
      "416                 , type:Convolution\n",
      " -------------     weight:(128, 256, 1, 1)\n",
      "     from: 415                  \n",
      "     to  : 416                  \n",
      "------------- \n",
      "\n",
      "417_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 416                  \n",
      "     to  : 417                  \n",
      "------------- \n",
      "\n",
      "417                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 417                  \n",
      "     to  : 417                  \n",
      "------------- \n",
      "\n",
      "418                 , type:Eltwise\n",
      " -------------\n",
      "     from: 409                  417                  \n",
      "     to  : 418                  \n",
      "------------- \n",
      "\n",
      "419                 , type:Convolution\n",
      " -------------     weight:(256, 128, 1, 1)\n",
      "     from: 418                  \n",
      "     to  : 419                  \n",
      "------------- \n",
      "\n",
      "420_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 419                  \n",
      "     to  : 420                  \n",
      "------------- \n",
      "\n",
      "420                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 420                  \n",
      "     to  : 420                  \n",
      "------------- \n",
      "\n",
      "421_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 420                  \n",
      "     to  : 421                  \n",
      "------------- \n",
      "\n",
      "422                 , type:Convolution\n",
      " -------------     weight:(256, 1, 3, 3)\n",
      "     from: 421                  \n",
      "     to  : 422                  \n",
      "------------- \n",
      "\n",
      "423_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 422                  \n",
      "     to  : 423                  \n",
      "------------- \n",
      "\n",
      "423                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 423                  \n",
      "     to  : 423                  \n",
      "------------- \n",
      "\n",
      "424_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 423                  \n",
      "     to  : 424                  \n",
      "------------- \n",
      "\n",
      "425                 , type:Convolution\n",
      " -------------     weight:(128, 256, 1, 1)\n",
      "     from: 424                  \n",
      "     to  : 425                  \n",
      "------------- \n",
      "\n",
      "426_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 425                  \n",
      "     to  : 426                  \n",
      "------------- \n",
      "\n",
      "426                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 426                  \n",
      "     to  : 426                  \n",
      "------------- \n",
      "\n",
      "427                 , type:Eltwise\n",
      " -------------\n",
      "     from: 418                  426                  \n",
      "     to  : 427                  \n",
      "------------- \n",
      "\n",
      "428                 , type:Convolution\n",
      " -------------     weight:(256, 128, 1, 1)\n",
      "     from: 427                  \n",
      "     to  : 428                  \n",
      "------------- \n",
      "\n",
      "429_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 428                  \n",
      "     to  : 429                  \n",
      "------------- \n",
      "\n",
      "429                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 429                  \n",
      "     to  : 429                  \n",
      "------------- \n",
      "\n",
      "430_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 429                  \n",
      "     to  : 430                  \n",
      "------------- \n",
      "\n",
      "431                 , type:Convolution\n",
      " -------------     weight:(256, 1, 3, 3)\n",
      "     from: 430                  \n",
      "     to  : 431                  \n",
      "------------- \n",
      "\n",
      "432_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 431                  \n",
      "     to  : 432                  \n",
      "------------- \n",
      "\n",
      "432                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 432                  \n",
      "     to  : 432                  \n",
      "------------- \n",
      "\n",
      "433_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 432                  \n",
      "     to  : 433                  \n",
      "------------- \n",
      "\n",
      "434                 , type:Convolution\n",
      " -------------     weight:(128, 256, 1, 1)\n",
      "     from: 433                  \n",
      "     to  : 434                  \n",
      "------------- \n",
      "\n",
      "435_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 434                  \n",
      "     to  : 435                  \n",
      "------------- \n",
      "\n",
      "435                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 435                  \n",
      "     to  : 435                  \n",
      "------------- \n",
      "\n",
      "436                 , type:Eltwise\n",
      " -------------\n",
      "     from: 427                  435                  \n",
      "     to  : 436                  \n",
      "------------- \n",
      "\n",
      "437                 , type:Convolution\n",
      " -------------     weight:(256, 128, 1, 1)\n",
      "     from: 436                  \n",
      "     to  : 437                  \n",
      "------------- \n",
      "\n",
      "438_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 437                  \n",
      "     to  : 438                  \n",
      "------------- \n",
      "\n",
      "438                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 438                  \n",
      "     to  : 438                  \n",
      "------------- \n",
      "\n",
      "439_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 438                  \n",
      "     to  : 439                  \n",
      "------------- \n",
      "\n",
      "440                 , type:Convolution\n",
      " -------------     weight:(256, 1, 3, 3)\n",
      "     from: 439                  \n",
      "     to  : 440                  \n",
      "------------- \n",
      "\n",
      "441_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 440                  \n",
      "     to  : 441                  \n",
      "------------- \n",
      "\n",
      "441                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 441                  \n",
      "     to  : 441                  \n",
      "------------- \n",
      "\n",
      "442_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 441                  \n",
      "     to  : 442                  \n",
      "------------- \n",
      "\n",
      "443                 , type:Convolution\n",
      " -------------     weight:(128, 256, 1, 1)\n",
      "     from: 442                  \n",
      "     to  : 443                  \n",
      "------------- \n",
      "\n",
      "444_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 443                  \n",
      "     to  : 444                  \n",
      "------------- \n",
      "\n",
      "444                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 444                  \n",
      "     to  : 444                  \n",
      "------------- \n",
      "\n",
      "445                 , type:Eltwise\n",
      " -------------\n",
      "     from: 436                  444                  \n",
      "     to  : 445                  \n",
      "------------- \n",
      "\n",
      "446                 , type:Convolution\n",
      " -------------     weight:(512, 128, 1, 1)\n",
      "     from: 445                  \n",
      "     to  : 446                  \n",
      "------------- \n",
      "\n",
      "447_bn              , type:BatchNorm\n",
      " -------------     weight:(512,)     weight:(512,)     weight:(1,)\n",
      "     from: 446                  \n",
      "     to  : 447                  \n",
      "------------- \n",
      "\n",
      "447                 , type:Scale\n",
      " -------------     weight:(512,)     weight:(512,)\n",
      "     from: 447                  \n",
      "     to  : 447                  \n",
      "------------- \n",
      "\n",
      "448_prelu           , type:PReLU\n",
      " -------------     weight:(512,)\n",
      "     from: 447                  \n",
      "     to  : 448                  \n",
      "------------- \n",
      "\n",
      "449                 , type:Convolution\n",
      " -------------     weight:(512, 1, 3, 3)\n",
      "     from: 448                  \n",
      "     to  : 449                  \n",
      "------------- \n",
      "\n",
      "450_bn              , type:BatchNorm\n",
      " -------------     weight:(512,)     weight:(512,)     weight:(1,)\n",
      "     from: 449                  \n",
      "     to  : 450                  \n",
      "------------- \n",
      "\n",
      "450                 , type:Scale\n",
      " -------------     weight:(512,)     weight:(512,)\n",
      "     from: 450                  \n",
      "     to  : 450                  \n",
      "------------- \n",
      "\n",
      "451_prelu           , type:PReLU\n",
      " -------------     weight:(512,)\n",
      "     from: 450                  \n",
      "     to  : 451                  \n",
      "------------- \n",
      "\n",
      "452                 , type:Convolution\n",
      " -------------     weight:(128, 512, 1, 1)\n",
      "     from: 451                  \n",
      "     to  : 452                  \n",
      "------------- \n",
      "\n",
      "453_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 452                  \n",
      "     to  : 453                  \n",
      "------------- \n",
      "\n",
      "453                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 453                  \n",
      "     to  : 453                  \n",
      "------------- \n",
      "\n",
      "454                 , type:Convolution\n",
      " -------------     weight:(256, 128, 1, 1)\n",
      "     from: 453                  \n",
      "     to  : 454                  \n",
      "------------- \n",
      "\n",
      "455_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 454                  \n",
      "     to  : 455                  \n",
      "------------- \n",
      "\n",
      "455                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 455                  \n",
      "     to  : 455                  \n",
      "------------- \n",
      "\n",
      "456_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 455                  \n",
      "     to  : 456                  \n",
      "------------- \n",
      "\n",
      "457                 , type:Convolution\n",
      " -------------     weight:(256, 1, 3, 3)\n",
      "     from: 456                  \n",
      "     to  : 457                  \n",
      "------------- \n",
      "\n",
      "458_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 457                  \n",
      "     to  : 458                  \n",
      "------------- \n",
      "\n",
      "458                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 458                  \n",
      "     to  : 458                  \n",
      "------------- \n",
      "\n",
      "459_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 458                  \n",
      "     to  : 459                  \n",
      "------------- \n",
      "\n",
      "460                 , type:Convolution\n",
      " -------------     weight:(128, 256, 1, 1)\n",
      "     from: 459                  \n",
      "     to  : 460                  \n",
      "------------- \n",
      "\n",
      "461_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 460                  \n",
      "     to  : 461                  \n",
      "------------- \n",
      "\n",
      "461                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 461                  \n",
      "     to  : 461                  \n",
      "------------- \n",
      "\n",
      "462                 , type:Eltwise\n",
      " -------------\n",
      "     from: 453                  461                  \n",
      "     to  : 462                  \n",
      "------------- \n",
      "\n",
      "463                 , type:Convolution\n",
      " -------------     weight:(256, 128, 1, 1)\n",
      "     from: 462                  \n",
      "     to  : 463                  \n",
      "------------- \n",
      "\n",
      "464_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 463                  \n",
      "     to  : 464                  \n",
      "------------- \n",
      "\n",
      "464                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 464                  \n",
      "     to  : 464                  \n",
      "------------- \n",
      "\n",
      "465_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 464                  \n",
      "     to  : 465                  \n",
      "------------- \n",
      "\n",
      "466                 , type:Convolution\n",
      " -------------     weight:(256, 1, 3, 3)\n",
      "     from: 465                  \n",
      "     to  : 466                  \n",
      "------------- \n",
      "\n",
      "467_bn              , type:BatchNorm\n",
      " -------------     weight:(256,)     weight:(256,)     weight:(1,)\n",
      "     from: 466                  \n",
      "     to  : 467                  \n",
      "------------- \n",
      "\n",
      "467                 , type:Scale\n",
      " -------------     weight:(256,)     weight:(256,)\n",
      "     from: 467                  \n",
      "     to  : 467                  \n",
      "------------- \n",
      "\n",
      "468_prelu           , type:PReLU\n",
      " -------------     weight:(256,)\n",
      "     from: 467                  \n",
      "     to  : 468                  \n",
      "------------- \n",
      "\n",
      "469                 , type:Convolution\n",
      " -------------     weight:(128, 256, 1, 1)\n",
      "     from: 468                  \n",
      "     to  : 469                  \n",
      "------------- \n",
      "\n",
      "470_bn              , type:BatchNorm\n",
      " -------------     weight:(128,)     weight:(128,)     weight:(1,)\n",
      "     from: 469                  \n",
      "     to  : 470                  \n",
      "------------- \n",
      "\n",
      "470                 , type:Scale\n",
      " -------------     weight:(128,)     weight:(128,)\n",
      "     from: 470                  \n",
      "     to  : 470                  \n",
      "------------- \n",
      "\n",
      "471                 , type:Eltwise\n",
      " -------------\n",
      "     from: 462                  470                  \n",
      "     to  : 471                  \n",
      "------------- \n",
      "\n",
      "472                 , type:Convolution\n",
      " -------------     weight:(512, 128, 1, 1)\n",
      "     from: 471                  \n",
      "     to  : 472                  \n",
      "------------- \n",
      "\n",
      "473_bn              , type:BatchNorm\n",
      " -------------     weight:(512,)     weight:(512,)     weight:(1,)\n",
      "     from: 472                  \n",
      "     to  : 473                  \n",
      "------------- \n",
      "\n",
      "473                 , type:Scale\n",
      " -------------     weight:(512,)     weight:(512,)\n",
      "     from: 473                  \n",
      "     to  : 473                  \n",
      "------------- \n",
      "\n",
      "474_prelu           , type:PReLU\n",
      " -------------     weight:(512,)\n",
      "     from: 473                  \n",
      "     to  : 474                  \n",
      "------------- \n",
      "\n",
      "bn1                 , type:BatchNorm\n",
      " -------------     weight:(512,)     weight:(512,)     weight:(1,)\n",
      "     from: 474                  \n",
      "     to  : 475                  \n",
      "------------- \n",
      "\n",
      "bn1_scale           , type:Scale\n",
      " -------------     weight:(512,)     weight:(512,)\n",
      "     from: 475                  \n",
      "     to  : 475                  \n",
      "------------- \n",
      "\n",
      "fc_emb              , type:InnerProduct\n",
      " -------------     weight:(512, 25088)     weight:(512,)\n",
      "     from: 475                  \n",
      "     to  : 476                  \n",
      "------------- \n",
      "\n",
      "bn2                 , type:BatchNorm\n",
      " -------------     weight:(512,)     weight:(512,)     weight:(1,)\n",
      "     from: 476                  \n",
      "     to  : 477                  \n",
      "------------- \n",
      "\n",
      "bn2_scale           , type:Scale\n",
      " -------------     weight:(512,)     weight:(512,)\n",
      "     from: 477                  \n",
      "     to  : 477                  \n",
      "------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "network = {}\n",
    "for layer in net_params.layer:\n",
    "    bottoms = layer.bottom\n",
    "    tops = layer.top\n",
    "    network[layer.name] = {}\n",
    "    network[layer.name]['config'] = layer\n",
    "    network[layer.name]['weights'] = []\n",
    "    \n",
    "    msg = \"{:20}, type:{}\\n \".format(layer.name, layer.type)\n",
    "    msg += \"-------------\"\n",
    "    if layer.name in net.params:\n",
    "        for param in net.params[layer.name]:\n",
    "            msg += \"     weight:{}\".format(param.data[...].shape)\n",
    "            network[layer.name]['weights'].append(param.data[...])\n",
    "    msg += \"\\n     from: \"\n",
    "    for bottom in bottoms:\n",
    "        msg += \"{:20} \".format(bottom)\n",
    "    msg += \"\\n     to  : \"\n",
    "    for top in tops:\n",
    "        msg += \"{:20} \".format(top)\n",
    "    msg += \"\\n------------- \\n\"\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"0\"\n",
       "type: \"Input\"\n",
       "top: \"0\"\n",
       "input_param {\n",
       "  shape {\n",
       "    dim: 1\n",
       "    dim: 3\n",
       "    dim: 112\n",
       "    dim: 112\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'layer {\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.readlines()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['334']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.top_names['334']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(net.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__instance_size__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'append',\n",
       " 'extend']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(net.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.blobs['0'].data[...] = img\n",
    "caffe_output = net.forward()['334']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 3.0455356 ,  6.6713    ,  9.257795  ,  9.0808735 ],\n",
       "         [ 4.7247915 , 10.154223  , 11.703827  , 12.463874  ],\n",
       "         [ 6.3956337 , 10.578259  , 10.696621  , 11.026845  ],\n",
       "         [ 5.384305  ,  7.3364925 ,  6.520999  ,  7.229371  ]],\n",
       "\n",
       "        [[ 1.7485619 ,  2.4639575 ,  2.4639575 ,  1.2879406 ],\n",
       "         [ 2.5677435 ,  3.4708602 ,  3.4708602 ,  1.556403  ],\n",
       "         [ 2.5677435 ,  3.4708602 ,  3.4708602 ,  1.556403  ],\n",
       "         [ 1.8574286 ,  2.4864588 ,  2.4864588 ,  0.86808157]],\n",
       "\n",
       "        [[ 1.2458037 ,  2.8920863 ,  3.8225572 ,  3.4955497 ],\n",
       "         [ 3.200762  ,  6.6234217 ,  8.80938   ,  7.373701  ],\n",
       "         [ 3.6095207 ,  7.0121665 ,  7.730293  ,  6.9637175 ],\n",
       "         [ 3.7317743 ,  5.521199  ,  5.784136  ,  4.962623  ]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caffe_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
